{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"LlamaBot: A Pythonic bot interface to LLMs","text":"<p>LlamaBot implements a Pythonic interface to LLMs, making it much easier to experiment with LLMs in a Jupyter notebook and build Python apps that utilize LLMs. All models supported by LiteLLM are supported by LlamaBot.</p>"},{"location":"#install-llamabot","title":"Install LlamaBot","text":"<p>To install LlamaBot:</p> <pre><code>pip install llamabot\n</code></pre>"},{"location":"#get-access-to-llms","title":"Get access to LLMs","text":""},{"location":"#option-1-using-local-models-with-ollama","title":"Option 1: Using local models with Ollama","text":"<p>LlamaBot supports using local models through Ollama. To do so, head over to the Ollama website and install Ollama. Then follow the instructions below.</p>"},{"location":"#option-2-use-an-api-provider","title":"Option 2: Use an API provider","text":""},{"location":"#openai","title":"OpenAI","text":"<p>If you have an OpenAI API key, then configure LlamaBot to use the API key by running:</p> <pre><code>export OPENAI_API_KEY=\"sk-your1api2key3goes4here\"\n</code></pre>"},{"location":"#mistral","title":"Mistral","text":"<p>If you have a Mistral API key, then configure LlamaBot to use the API key by running:</p> <pre><code>export MISTRAL_API_KEY=\"your-api-key-goes-here\"\n</code></pre>"},{"location":"#other-api-providers","title":"Other API providers","text":"<p>Other API providers will usually specify an environment variable to set. If you have an API key, then set the environment variable accordingly.</p>"},{"location":"#how-to-use","title":"How to use","text":""},{"location":"#simplebot","title":"SimpleBot","text":"<p>The simplest use case of LlamaBot is to create a <code>SimpleBot</code> that keeps no record of chat history. This is effectively the same as a stateless function that you program with natural language instructions rather than code. This is useful for prompt experimentation, or for creating simple bots that are preconditioned on an instruction to handle texts and are then called upon repeatedly with different texts. For example, to create a Bot that explains a given chunk of text like Richard Feynman would:</p> <pre><code>from llamabot import SimpleBot\n\nfeynman = SimpleBot(\"You are Richard Feynman. You will be given a difficult concept, and your task is to explain it back.\", model_name=\"gpt-3.5-turbo\")\n</code></pre> <p>Now, <code>feynman</code> is callable on any arbitrary chunk of text and will return a rephrasing of that text in Richard Feynman's style (or more accurately, according to the style prescribed by the prompt). For example:</p> <pre><code>feynman(\"Enzyme function annotation is a fundamental challenge, and numerous computational tools have been developed. However, most of these tools cannot accurately predict functional annotations, such as enzyme commission (EC) number, for less-studied proteins or those with previously uncharacterized functions or multiple activities. We present a machine learning algorithm named CLEAN (contrastive learning\u2013enabled enzyme annotation) to assign EC numbers to enzymes with better accuracy, reliability, and sensitivity compared with the state-of-the-art tool BLASTp. The contrastive learning framework empowers CLEAN to confidently (i) annotate understudied enzymes, (ii) correct mislabeled enzymes, and (iii) identify promiscuous enzymes with two or more EC numbers\u2014functions that we demonstrate by systematic in silico and in vitro experiments. We anticipate that this tool will be widely used for predicting the functions of uncharacterized enzymes, thereby advancing many fields, such as genomics, synthetic biology, and biocatalysis.\")\n</code></pre> <p>This will return something that looks like:</p> <pre><code>Alright, let's break this down.\n\nEnzymes are like little biological machines that help speed up chemical reactions in our\nbodies. Each enzyme has a specific job, or function, and we use something called an\nEnzyme Commission (EC) number to categorize these functions.\n\nNow, the problem is that we don't always know what function an enzyme has, especially if\nit's a less-studied or new enzyme. This is where computational tools come in. They try\nto predict the function of these enzymes, but they often struggle to do so accurately.\n\nSo, the folks here have developed a new tool called CLEAN, which stands for contrastive\nlearning\u2013enabled enzyme annotation. This tool uses a machine learning algorithm, which\nis a type of artificial intelligence that learns from data to make predictions or\ndecisions.\n\nCLEAN uses a method called contrastive learning. Imagine you have a bunch of pictures of\ncats and dogs, and you want to teach a machine to tell the difference. You'd show it\npairs of pictures, some of the same animal (two cats or two dogs) and some of different\nanimals (a cat and a dog). The machine would learn to tell the difference by contrasting\nthe features of the two pictures. That's the basic idea behind contrastive learning.\n\nCLEAN uses this method to predict the EC numbers of enzymes more accurately than\nprevious tools. It can confidently annotate understudied enzymes, correct mislabeled\nenzymes, and even identify enzymes that have more than one function.\n\nThe creators of CLEAN have tested it with both computer simulations and lab experiments,\nand they believe it will be a valuable tool for predicting the functions of unknown\nenzymes. This could have big implications for fields like genomics, synthetic biology,\nand biocatalysis, which all rely on understanding how enzymes work.\n</code></pre> <p>If you want to use an Ollama model hosted locally, then you would use the following syntax:</p> <pre><code>from llamabot import SimpleBot\nbot = SimpleBot(\n    \"You are Richard Feynman. You will be given a difficult concept, and your task is to explain it back.\",\n    model_name=\"ollama/llama2:13b\"\n)\n</code></pre> <p>Simply specify the <code>model_name</code> keyword argument and provide a model name from the Ollama library of models prefixed by <code>ollama/</code>. All you need to do is make sure Ollama is running locally; see the Ollama documentation for more details. (The same can be done for the <code>ChatBot</code> and <code>QueryBot</code> classes below!)</p>"},{"location":"#chat-bot","title":"Chat Bot","text":"<p>To experiment with a Chat Bot in the Jupyter Notebook, we also provide the ChatBot interface. This interface automagically keeps track of chat history for as long as your Jupyter session is alive. Doing so allows you to use your own local Jupyter Notebook as a chat interface.</p> <p>For example:</p> <pre><code>from llamabot import ChatBot\n\nfeynman = ChatBot(\"You are Richard Feynman. You will be given a difficult concept, and your task is to explain it back.\", session_name=\"feynman_chat\")\nfeynman(\"Enzyme function annotation is a fundamental challenge, and numerous computational tools have been developed. However, most of these tools cannot accurately predict functional annotations, such as enzyme commission (EC) number, for less-studied proteins or those with previously uncharacterized functions or multiple activities. We present a machine learning algorithm named CLEAN (contrastive learning\u2013enabled enzyme annotation) to assign EC numbers to enzymes with better accuracy, reliability, and sensitivity compared with the state-of-the-art tool BLASTp. The contrastive learning framework empowers CLEAN to confidently (i) annotate understudied enzymes, (ii) correct mislabeled enzymes, and (iii) identify promiscuous enzymes with two or more EC numbers\u2014functions that we demonstrate by systematic in silico and in vitro experiments. We anticipate that this tool will be widely used for predicting the functions of uncharacterized enzymes, thereby advancing many fields, such as genomics, synthetic biology, and biocatalysis.\")\n</code></pre> <p>With the chat history available, you can ask a follow-up question:</p> <pre><code>feynman(\"Is there a simpler way to rephrase the text such that a high schooler would understand it?\")\n</code></pre> <p>And your bot will work with the chat history to respond.</p>"},{"location":"#querybot","title":"QueryBot","text":"<p>The final bot provided is a QueryBot. This bot lets you query a collection of documents. To use it, you have two options:</p> <ol> <li>Pass in a list of paths to text files, or</li> <li>Pass in a session name of a previously instantiated <code>QueryBot</code> that model. (This will load the previously-computed text index into memory.)</li> </ol> <p>As an illustrative example:</p> <pre><code>from llamabot import QueryBot\nfrom pathlib import Path\n\nblog_index = Path(\"/path/to/index.json\")\nbot = QueryBot(system_message=\"You are an expert on Eric Ma's blog.\", session_name=\"eric_ma_blog\")  # this loads my previously-embedded blog text.\n# alternatively:\n# bot = QueryBot(system_message=\"You are an expert on Eric Ma's blog.\", session_name=\"eric_ma_blog\", document_paths=[Path(\"/path/to/blog/post1.txt\"), Path(\"/path/to/blog/post2.txt\"), ...])\nresult = bot(\"Do you have any advice\u00a0for me on career development?\")\ndisplay(Markdown(result.response))\n</code></pre>"},{"location":"#imagebot","title":"ImageBot","text":"<p>With the release of the OpenAI API updates, as long as you have an OpenAI API key, you can generate images with LlamaBot:</p> <pre><code>from llamabot import ImageBot\n\nbot = ImageBot()\n# Within a Jupyter notebook:\nurl = bot(\"A painting of a dog.\")\n\n# Or within a Python script\nfilepath = bot(\"A painting of a dog.\")\n\n# Now, you can do whatever you need with the url or file path.\n</code></pre> <p>If you're in a Jupyter Notebook, you'll see the image show up magically as part of the output cell as well.</p>"},{"location":"#cli-demos","title":"CLI Demos","text":"<p>Llamabot comes with CLI demos of what can be built with it and a bit of supporting code.</p> <p>Here is one where I expose a chatbot directly at the command line using <code>llamabot chat</code>:</p> <p>And here is another one where <code>llamabot</code> is used as part of the backend of a CLI app to chat with one's Zotero library using <code>llamabot zotero chat</code>:</p> <p>And finally, here is one where I use <code>llamabot</code>'s <code>SimpleBot</code> to create a bot that automatically writes commit messages for me.</p>"},{"location":"#contributing","title":"Contributing","text":""},{"location":"#new-features","title":"New features","text":"<p>New features are welcome! These are early and exciting days for users of large language models. Our development goals are to keep the project as simple as possible. Features requests that come with a pull request will be prioritized; the simpler the implementation of a feature (in terms of maintenance burden), the more likely it will be approved.</p>"},{"location":"#bug-reports","title":"Bug reports","text":"<p>Please submit a bug report using the issue tracker.</p>"},{"location":"#questionsdiscussions","title":"Questions/Discussions","text":"<p>Please use the issue tracker on GitHub.</p>"},{"location":"#contributors","title":"Contributors","text":"Rena Lu\ud83d\udcbb andrew giessel\ud83e\udd14 \ud83c\udfa8 \ud83d\udcbb Aidan Brewis\ud83d\udcbb Eric Ma\ud83e\udd14 \ud83c\udfa8 \ud83d\udcbb Mark Harrison\ud83e\udd14"},{"location":"cli/blog/","title":"Blog Assistant CLI Tutorial","text":"<p>The Blog Assistant CLI is a powerful tool that helps you streamline your blogging workflow. It can generate blog summaries, apply semantic line breaks (SEMBR), and even create social media posts for LinkedIn, Patreon, and Twitter. This tutorial will guide you through the usage of this tool.</p>"},{"location":"cli/blog/#summarize-command","title":"Summarize Command","text":"<p>The <code>summarize</code> command is used to generate a blog summary, title, and tags. Here's how to use it:</p> <ol> <li>Run the command <code>summarize</code> in your terminal: <code>llamabot blog summarize</code></li> <li>You will be prompted to paste your blog post.</li> <li>The tool will then generate a blog title, apply SEMBR to your summary, and provide you with relevant tags.</li> </ol> <p>The output will look something like this:</p> <pre><code>Here is your blog title:\n[Generated Blog Title]\n\nApplying SEMBR to your summary...\n\nHere is your blog summary:\n[Generated Blog Summary with SEMBR]\n\nHere are your blog tags:\n[Generated Blog Tags]\n</code></pre>"},{"location":"cli/blog/#social-media-command","title":"Social Media Command","text":"<p>The <code>social_media</code> command is used to generate social media posts. Here's how to use it:</p> <ol> <li>Run the command <code>social_media [platform]</code> in your terminal, where <code>[platform]</code> is either <code>linkedin</code>, <code>patreon</code>, or <code>twitter</code>: <code>llamabot blog social-media linkedin</code>.</li> <li>You will be prompted to paste your blog post.</li> <li>The tool will then generate a social media post for the specified platform.</li> </ol> <p>For LinkedIn and Twitter, the generated post will be copied to your clipboard. For Patreon, the tool will display the post in the terminal.</p>"},{"location":"cli/blog/#sembr-command","title":"SEMBR Command","text":"<p>The <code>sembr</code> command is used to apply semantic line breaks to a blog post. Here's how to use it:</p> <ol> <li>Run the command <code>sembr</code> in your terminal: <code>llamabot blog sembr</code></li> <li>You will be prompted to paste your blog post.</li> <li>The tool will then apply semantic line breaks to your post and copy the result to your clipboard.</li> </ol> <p>With these commands, you can streamline your blogging workflow and ensure your content is optimized for readability and engagement. Happy blogging!</p>"},{"location":"cli/git/","title":"LlamaBot Git CLI Tutorial","text":"<p>In this tutorial, we will explore the Git subcommand for the LlamaBot CLI. This command-line interface (CLI) provides a set of tools to automate and enhance your Git workflow, in particular, the ability to automatically generate commit messages.</p>"},{"location":"cli/git/#setup","title":"Setup","text":"<p>The <code>llamabot</code> prepare message hook requires that you have <code>llamabot &gt;=0.0.77</code>. You will also need an OpenAI API key (until we have enabled and tested locally-hosted language models). Be sure to setup and configure LlamaBot by executing the following two configuration commands and following the instructions there.</p> <pre><code>llamabot configure api-key\n</code></pre> <p>and</p> <pre><code>llamabot configure default-model\n</code></pre> <p>For the default model, we suggest using a GPT-4 variant. It is generally of higher quality than GPT-3.5. If you are concerned with cost, the GPT-3.5-turbo variant with 16K context window has anecdotally worked well.</p>"},{"location":"cli/git/#install-the-commit-message-hook","title":"Install the Commit Message Hook","text":"<p>Once you have configured <code>llamabot</code>, the next thing you need to do is install the <code>prepare-msg-hook</code> within your <code>git</code> repository. This is a <code>git</code> hook that allows you to run commands after the <code>pre-commit</code> hooks are run but before your editor of the commit message is opened. To install the hook, simply run:</p> <pre><code>llamabot git install-commit-message-hook\n</code></pre> <p>This command will check if the current directory is a Git repository root. If it is not, it raises a <code>RuntimeError</code>. If it is, it writes a script to the <code>prepare-commit-msg</code> file in the <code>.git/hooks</code> directory and changes the file's permissions to make it executable.</p>"},{"location":"cli/git/#auto-compose-a-commit-message","title":"Auto-Compose a Commit Message","text":"<p>The <code>llamabot git compose-commit</code> command autowrites a commit message based on the diff. It first gets the diff using the <code>get_git_diff</code> function. It then generates a commit message using the <code>commitbot</code>, which is a LlamaBot SimpleBot. If any error occurs during this process, it prints the error message and prompts the user to write their own commit message, allowing for a graceful fallback to default behaviour. This can be useful, for example, if you don't have an internet connection and cannot connect to the OpenAI API, but still need to commit code.</p> <p>This command never needs to be explicitly called. Rather, it is called behind-the-scenes within the <code>prepare-msg-hook</code>.</p>"},{"location":"cli/git/#conclusion","title":"Conclusion","text":"<p>The <code>llamabot git</code> CLI provides a set of tools to automate and enhance your Git workflow. It provides an automatic commit message writer based on your repo's <code>git diff</code>. By using <code>llamabot git</code>, you can streamline your Git workflow and focus on writing code.</p>"},{"location":"cli/llamabot/","title":"LlamaBot Configuration Tutorial","text":"<p>In this tutorial, we will walk through the configuration process for LlamaBot, a Python-based bot that uses the OpenAI API. The configuration process involves setting up the API key and selecting the default model for the bot.</p>"},{"location":"cli/llamabot/#setting-up-the-api-key","title":"Setting up the API Key","text":"<p>The first step in configuring LlamaBot is to set up the API key. This is done by invoking:</p> <pre><code>llamabot configure api-key\n</code></pre> <p>The user will be prompted to enter their OpenAI API key. The key will be hidden as you type it, and you will be asked to confirm it. Once confirmed, the key will be stored as an environment variable, <code>OPENAI_API_KEY</code>.</p>"},{"location":"cli/llamabot/#configuring-the-default-model","title":"Configuring the Default Model","text":"<p>The next step in the configuration process is to select the default model for LlamaBot. This is done by invoking:</p> <pre><code>llamabot configure default-model\n</code></pre> <p>LlamaBot will first load the environment variables from the <code>.env</code> file located at <code>llamabotrc_path</code>. It then retrieves a list of available models from the OpenAI API, filtering for those that include 'gpt' in their ID. For this reason, it is important to set your OpenAI API key before configuring the default model.</p> <p>The function then displays the list of available models and prompts you to select one. As you type, the function will suggest completions based on the available models. The last model in the list is provided as the default option.</p> <p>Once you have entered a valid model ID, the function stores it as an environment variable, <code>DEFAULT_LANGUAGE_MODEL</code>.</p>"},{"location":"cli/llamabot/#conclusion","title":"Conclusion","text":"<p>By following these steps, you can easily configure LlamaBot to use your OpenAI API key and your chosen default model. Remember to keep your API key secure, and to choose a model that best suits your needs. Happy coding!</p>"},{"location":"cli/python/","title":"Llamabot Python CLI Tutorial","text":"<p>Welcome to the Llamabot Python CLI tutorial! In this tutorial, we will explore the various commands available in the Llamabot Python CLI and learn how to use them effectively. The Llamabot Python CLI is a powerful tool for generating module-level and function docstrings, as well as generating code based on a given description.</p>"},{"location":"cli/python/#prerequisites","title":"Prerequisites","text":"<p>Before we begin, make sure you have the Llamabot Python CLI installed on your system. You can install it using pip:</p> <pre><code>pip install -U llamabot\n</code></pre> <p>Once installed, you can access the CLI using the <code>llamabot python</code> command.</p>"},{"location":"cli/python/#commands","title":"Commands","text":"<p>The Llamabot Python CLI provides the following commands:</p> <ol> <li><code>module-docstrings</code>: Generate module-level docstrings for a given module file.</li> <li><code>generate-docstrings</code>: Generate function docstrings for a specific function in a module file.</li> <li><code>code-generator</code>: Generate code based on a given description.</li> <li><code>test-writer</code>: Write tests for a given object.</li> </ol> <p>Let's dive into each command and see how they can be used.</p>"},{"location":"cli/python/#1-module-docstrings","title":"1. module-docstrings","text":"<p>The <code>module-docstrings</code> command generates module-level docstrings for a given module file. It takes the following arguments:</p> <ul> <li><code>module_fpath</code>: Path to the module to generate docstrings for.</li> <li><code>dirtree_context_path</code>: (Optional) Path to the directory to use as the context for the directory tree. Defaults to the parent directory of the module file.</li> </ul> <p>Example usage:</p> <pre><code>llamabot python module-docstrings /path/to/your/module.py\n</code></pre> <p>To specify a custom directory tree context path, use the following command:</p> <pre><code>llamabot python module-docstrings /path/to/your/module.py /path/to/your/directory\n</code></pre>"},{"location":"cli/python/#2-generate-docstrings","title":"2. generate-docstrings","text":"<p>The <code>generate-docstrings</code> command generates function docstrings for a specific function in a module file. It takes the following arguments:</p> <ul> <li><code>module_fpath</code>: Path to the module to generate docstrings for.</li> <li><code>object_name</code>: Name of the object to generate docstrings for.</li> <li><code>style</code>: (Optional) Style of docstring to generate. Defaults to \"sphinx\".</li> </ul> <p>Example usage:</p> <pre><code>llamabot python generate-docstrings /path/to/your/module.py function_name\n</code></pre> <p>To specify a custom docstring style, use the following command:</p> <pre><code>llamabot python generate-docstrings /path/to/your/module.py function_name google\n</code></pre>"},{"location":"cli/python/#3-code-generator","title":"3. code-generator","text":"<p>The <code>code-generator</code> command generates code based on a given description. It takes the following argument:</p> <ul> <li><code>request</code>: A description of what the code should do.</li> </ul> <p>Example usage:</p> <pre><code>llamabot python code-generator \"Create a function that adds two numbers\"\n</code></pre>"},{"location":"cli/python/#4-test-writer","title":"4. test-writer","text":"<p>The <code>test-writer</code> command writes tests for a given object. It takes the following arguments:</p> <ul> <li><code>module_fpath</code>: Path to the module to generate tests for.</li> <li><code>object_name</code>: Name of the object to generate tests for.</li> </ul> <p>Example usage:</p> <pre><code>llamabot python test-writer /path/to/your/module.py function_name\n</code></pre>"},{"location":"cli/python/#conclusion","title":"Conclusion","text":"<p>In this tutorial, we have covered the various commands available in the Llamabot Python CLI and learned how to use them effectively. With these commands, you can easily generate module-level and function docstrings, generate code based on a given description, and write tests for your code. Happy coding!</p>"},{"location":"cli/repo/","title":"Chatting with a Code Repository: Llamabot CLI Guide","text":"<p>Welcome to the guide on using the Llamabot CLI for interacting with code repositories. This innovative tool leverages AI to facilitate engaging and insightful conversations with your codebase. Discover how to effectively use this tool to read and understand documentation within a repository.</p>"},{"location":"cli/repo/#getting-started","title":"Getting started","text":"<p>Before you can start chatting with your code repository, ensure that Llamabot CLI is installed on your system. You can install it via pip with the following command:</p> <pre><code>pip install -U llamabot\n</code></pre> <p>Once installed, you can access the CLI using the <code>llamabot repo chat</code> command.</p>"},{"location":"cli/repo/#key-commands","title":"Key commands","text":"<p>Llamabot CLI introduces the <code>chat</code> command, allowing for dynamic interactions with your code repository.</p>"},{"location":"cli/repo/#chat-with-your-repository","title":"Chat with your repository","text":"<p>The <code>chat</code> command allows you to interact with your code repository in a conversational manner.</p>"},{"location":"cli/repo/#usage","title":"Usage","text":"<p>Run the command below to start a conversation with your repository:</p> <pre><code>llamabot repo chat --repo-url https://github.com/yourusername/yourrepo --checkout=\"branch_or_tag\" --source-file-extensions py --source-file-extensions md --model-name=\"gpt-4-0125-preview\"\n</code></pre> <p>Here are the key parameters to understand:</p> <ul> <li><code>--repo-url</code>: URL of the git repository you want to interact with.</li> <li><code>--checkout</code>: Specify the branch or tag you wish to use. The default is \"main\".</li> <li><code>--source-file-extensions</code>: Define the types of source files to include in the conversation. Supports a variety of file extensions.</li> <li><code>--model-name</code>: AI model to be used for generating responses.</li> <li><code>--initial-message</code> (optional): Initial message to start the conversation.</li> <li><code>--panel</code> (optional): Set to <code>true</code> to launch a Panel web app to chat.</li> </ul> <p>After executing the command, Llamabot clones the repository into a temporary directory, processes the files as specified, and starts the chat interface. If <code>--panel</code> is true, the chat interface will be served in a browser.</p>"},{"location":"cli/repo/#conclusion","title":"Conclusion","text":"<p>This guide covers the essential aspects of the Llamabot CLI, a tool designed to enhance your coding experience through AI-powered conversations about a code repository. Embrace these capabilities to make your coding more efficient and insightful. Happy coding!</p>"},{"location":"cli/zotero/","title":"Llamabot Zotero CLI Tutorial","text":"<p>In this tutorial, we will walk through the Llamabot Zotero CLI, a command-line interface for interacting with your Zotero library. This tool allows you to chat with a paper, retrieve keys, and download papers from your Zotero library.</p>"},{"location":"cli/zotero/#prerequisites","title":"Prerequisites","text":"<p>Before we start, make sure you have <code>llamabot</code> installed in your environment:</p> <pre><code>pip install -U llamabot\n</code></pre>"},{"location":"cli/zotero/#getting-started","title":"Getting Started","text":"<p>First, we need to configure the Llamabot Zotero CLI environment variables. This is done using the <code>configure</code> command. You will be prompted to enter your Zotero library ID, API key, and library type.</p> <pre><code>llamabot zotero configure\n</code></pre>"},{"location":"cli/zotero/#chatting-with-a-paper","title":"Chatting with a Paper","text":"<p>To chat with a paper, use the <code>chat</code> command. You can specify the paper you want to chat about as an argument. If you don't provide a paper, you will be prompted to enter one.</p> <pre><code>llamabot zotero chat \"The title of the paper\"\n</code></pre> <p>If you want to specify a model, such as an Ollama model, you can do so directly at the command line too:</p> <pre><code>llamabot zotero chat \"The title of the paper\" --model vicuna:7b-16k\n</code></pre> <p>If you want to synchronize your Zotero library before chatting, you can use the <code>--sync</code> option.</p> <pre><code>llamabot zotero chat \"The title of the paper\" --sync\n</code></pre>"},{"location":"cli/zotero/#retrieving-keys","title":"Retrieving Keys","text":"<p>When you chat with a paper, the Llamabot Zotero CLI will retrieve the keys for the paper. These keys are unique identifiers for each paper in your Zotero library. The keys are displayed in the console.</p>"},{"location":"cli/zotero/#downloading-papers","title":"Downloading Papers","text":"<p>After retrieving the keys, you can choose a paper to download. You will be prompted to choose a paper from the list of keys. The paper will be downloaded to a temporary directory.</p> <pre><code>Please choose an option: The title of the paper\n</code></pre>"},{"location":"cli/zotero/#asking-questions","title":"Asking Questions","text":"<p>Once the paper is downloaded, you can start asking questions about the paper. The Llamabot Zotero CLI uses a QueryBot to answer your questions. Simply type your question at the prompt.</p> <pre><code>Ask me a question: What is the main argument of the paper?\n</code></pre> <p>To exit the chat, type <code>exit</code>.</p> <pre><code>Ask me a question: exit\n</code></pre> <p>And that's it! You now know how to use the Llamabot Zotero CLI to chat with a paper, retrieve keys, download papers, and ask questions about a paper. Happy chatting!</p>"},{"location":"examples/chatbot_nb/","title":"Chatbot nb","text":"<p>Let's see how to use the ChatBot class to enable you to chat with Mistral inside a Jupyter notebook.</p> <pre><code>from llamabot import ChatBot\n\ncode_tester = ChatBot(\n\"\"\"\nYou are a Python quality assurance developer who delivers high quality unit tests for code.\nYou write tests using PyTest and not the built-in unittest library.\nWrite the tests using test functions and not using classes and class methods\nHere is the code to write tests against:\n\"\"\",\n    session_name=\"code-tested\",\n    model_name=\"mistral/mistral-medium\",\n    stream_target=\"stdout\",\n)\n</code></pre> <pre><code>code_tester(\n'''\nclass ChatBot:\n    \"\"\"Chat Bot that is primed with a system prompt, accepts a human message.\n\n    Automatic chat memory management happens.\n\n    h/t Andrew Giessel/GPT4 for the idea.\n    \"\"\"\n\n    def __init__(self, system_prompt, temperature=0.0, model_name=\"gpt-4\"):\n        \"\"\"Initialize the ChatBot.\n\n        :param system_prompt: The system prompt to use.\n        :param temperature: The model temperature to use.\n            See https://platform.openai.com/docs/api-reference/completions/create#completions/create-temperature\n            for more information.\n        :param model_name: The name of the OpenAI model to use.\n        \"\"\"\n        self.model = ChatOpenAI(\n            model_name=model_name,\n            temperature=temperature,\n            streaming=True,\n            verbose=True,\n            callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),\n        )\n        self.chat_history = [\n            SystemMessage(content=\"Always return Markdown-compatible text.\"),\n            SystemMessage(content=system_prompt),\n        ]\n\n    def __call__(self, human_message) -&amp;gt; Response:\n        \"\"\"Call the ChatBot.\n\n        :param human_message: The human message to use.\n        :return: The response to the human message, primed by the system prompt.\n        \"\"\"\n        self.chat_history.append(HumanMessage(content=human_message))\n        response = self.model(self.chat_history)\n        self.chat_history.append(response)\n        return response\n'''\n)\n</code></pre> <pre>\n<code>&lt;litellm.utils.CustomStreamWrapper object at 0x1140c2cd0&gt;\nHere are the tests for the ChatBot class using PyTest and test functions:\n<pre><code>import pytest\nfrom chatbot import ChatBot, SystemMessage, HumanMessage\nfrom openai_callback import ChatOpenAI\n\ndef test_chatbot_init():\n    system_prompt = \"You are a helpful assistant.\"\n    chatbot = ChatBot(system_prompt)\n    assert len(chatbot.chat_history) == 2\n    assert isinstance(chatbot.chat_history[0], SystemMessage)\n    assert isinstance(chatbot.chat_history[1], SystemMessage)\n    assert chatbot.chat_history[0].content == \"Always return Markdown-compatible text.\"\n    assert chatbot.chat_history[1].content == system_prompt\n\ndef test_chatbot_call():\n    system_prompt = \"You are a helpful assistant.\"\n    chatbot = ChatBot(system_prompt)\n    human_message = \"What is the weather like today?\"\n    response = chatbot(human_message)\n    assert len(chatbot.chat_history) == 4\n    assert isinstance(chatbot.chat_history[2], HumanMessage)\n    assert isinstance(chatbot.chat_history[3], ChatOpenAI.Response)\n    assert chatbot.chat_history[2].content == human_message\n    assert response == chatbot.chat_history[3]\n\ndef test_chatbot_call_multiple_times():\n    system_prompt = \"You are a helpful assistant.\"\n    chatbot = ChatBot(system_prompt)\n    human_message1 = \"What is the weather like today?\"\n    human_message2 = \"What is the temperature outside?\"\n    chatbot(human_message1)\n    chatbot(human_message2)\n    assert len(chatbot.chat_history) == 6\n    assert isinstance(chatbot.chat_history[2], HumanMessage)\n    assert isinstance(chatbot.chat_history[3], ChatOpenAI.Response)\n    assert isinstance(chatbot.chat_history[4], HumanMessage)\n    assert isinstance(chatbot.chat_history[5], ChatOpenAI.Response)\n    assert chatbot.chat_history[2].content == human_message1\n    assert chatbot.chat_history[4].content == human_message2\n\ndef test_chatbot_temperature():\n    system_prompt = \"You are a helpful assistant.\"\n    chatbot = ChatBot(system_prompt, temperature=0.5)\n    assert chatbot.model.temperature == 0.5\n\ndef test_chatbot_model_name():\n    system_prompt = \"You are a helpful assistant.\"\n    chatbot = ChatBot(system_prompt, model_name=\"gpt-3.5-turbo\")\n    assert chatbot.model.model_name == \"gpt-3.5-turbo\"\n</code></pre>\nNote that these tests assume that the `ChatOpenAI` class and its `Response` class are defined elsewhere in the codebase. Also, the tests do not actually call the OpenAI API, but rather assume that the `ChatOpenAI` class is a mock or stub that returns a canned response. If you want to test the actual API calls, you will need to set up a test environment with a valid API key and handle any rate limiting or other issues that may arise.</code>\n</pre> <pre>\n<code>AIMessage(content='', role='assistant')</code>\n</pre> <p>As you can see, ChatBot keeps track of conversation memory/history automatically. We can even access any item in the conversation by looking at the conversation history.</p> <p>The <code>__repr__</code> of a chatbot will simply print out the entire history:</p> <pre><code>code_tester\n</code></pre> <pre>\n<code>[Human]\n\nclass ChatBot:\n    \"\"\"Chat Bot that is primed with a system prompt, accepts a human message.\n\n    Automatic chat memory management happens.\n\n    h/t Andrew Giessel/GPT4 for the idea.\n    \"\"\"\n\n    def __init__(self, system_prompt, temperature=0.0, model_name=\"gpt-4\"):\n        \"\"\"Initialize the ChatBot.\n\n        :param system_prompt: The system prompt to use.\n        :param temperature: The model temperature to use.\n            See https://platform.openai.com/docs/api-reference/completions/create#completions/create-temperature\n            for more information.\n        :param model_name: The name of the OpenAI model to use.\n        \"\"\"\n        self.model = ChatOpenAI(\n            model_name=model_name,\n            temperature=temperature,\n            streaming=True,\n            verbose=True,\n            callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),\n        )\n        self.chat_history = [\n            SystemMessage(content=\"Always return Markdown-compatible text.\"),\n            SystemMessage(content=system_prompt),\n        ]\n\n    def __call__(self, human_message) -&gt; Response:\n        \"\"\"Call the ChatBot.\n\n        :param human_message: The human message to use.\n        :return: The response to the human message, primed by the system prompt.\n        \"\"\"\n        self.chat_history.append(HumanMessage(content=human_message))\n        response = self.model(self.chat_history)\n        self.chat_history.append(response)\n        return response\n\n    def __repr__(self):\n        \"\"\"Return a string representation of the ChatBot.\n\n        :return: A string representation of the ChatBot.\n        \"\"\"\n        representation = \"\"\n\n        for message in self.chat_history:\n            if isinstance(message, SystemMessage):\n                prefix = \"[System]\n\"\n            elif isinstance(message, HumanMessage):\n                prefix = \"[Human]\n\"\n            elif isinstance(message, AIMessage):\n                prefix = \"[AI]\n\"\n\n            representation += f\"{prefix}{message.content}\" + \"\n\n\"\n        return representation\n\n    def panel(self, show: bool = True):\n        \"\"\"Create a Panel app that wraps a LlamaBot.\n\n        :param show: Whether to show the app.\n            If False, we return the Panel app directly.\n            If True, we call `.show()` on the app.\n        :return: The Panel app, either showed or directly.\n        \"\"\"\n\n        text_input = pn.widgets.TextAreaInput(placeholder=\"Start chatting...\")\n        chat_history = pn.Column(*[])\n        send_button = pn.widgets.Button(name=\"Send\", button_type=\"primary\")\n\n        def b(event):\n            \"\"\"Button click handler.\n\n            :param event: The button click event.\n            \"\"\"\n            chat_messages = []\n            for message in self.chat_history:\n                if isinstance(message, SystemMessage):\n                    pass\n                elif isinstance(message, HumanMessage):\n                    chat_markdown = pn.pane.Markdown(f\"Human: {message.content}\")\n                    chat_messages.append(chat_markdown)\n                elif isinstance(message, AIMessage):\n                    chat_markdown = pn.pane.Markdown(f\"Bot: {message.content}\")\n                    chat_messages.append(chat_markdown)\n\n            chat_messages.append(pn.pane.Markdown(f\"Human: {text_input.value}\"))\n            bot_reply = pn.pane.Markdown(\"Bot: \")\n            chat_messages.append(bot_reply)\n            chat_history.objects = chat_messages\n            markdown_handler = PanelMarkdownCallbackHandler(bot_reply)\n            self.model.callback_manager.set_handler(markdown_handler)\n            self(text_input.value)\n            text_input.value = \"\"\n\n        send_button.on_click(b)\n        input_pane = pn.Row(text_input, send_button)\n        output_pane = pn.Column(chat_history, scroll=True, height=500)\n\n        main = pn.Row(input_pane, output_pane)\n        app = pn.template.FastListTemplate(\n            site=\"ChatBot\",\n            title=\"ChatBot\",\n            main=main,\n            main_max_width=\"768px\",\n        )\n        if show:\n            return app.show()\n        return app\n\n\n\n[AI]\nHere are some tests for the ChatBot class using PyTest:\n<pre><code>import pytest\nfrom your_module import ChatBot, SystemMessage, HumanMessage\n\ndef test_init():\n    system_prompt = \"You are a helpful assistant.\"\n    chatbot = ChatBot(system_prompt)\n    assert len(chatbot.chat_history) == 2\n    assert isinstance(chatbot.chat_history[0], SystemMessage)\n    assert isinstance(chatbot.chat_history[1], SystemMessage)\n    assert chatbot.chat_history[0].content == \"Always return Markdown-compatible text.\"\n    assert chatbot.chat_history[1].content == system_prompt\n\ndef test_call():\n    system_prompt = \"You are a helpful assistant.\"\n    chatbot = ChatBot(system_prompt)\n    human_message = \"What's the weather like today?\"\n    response = chatbot(human_message)\n    assert len(chatbot.chat_history) == 4\n    assert isinstance(chatbot.chat_history[2], HumanMessage)\n    assert isinstance(chatbot.chat_history[3], response.__class__)\n    assert chatbot.chat_history[2].content == human_message\n\ndef test_repr():\n    system_prompt = \"You are a helpful assistant.\"\n    chatbot = ChatBot(system_prompt)\n    human_message = \"What's the weather like today?\"\n    chatbot(human_message)\n    expected_repr = (\n        \"[System]\\n\"\n        \"Always return Markdown-compatible text.\\n\\n\"\n        \"[System]\\n\"\n        \"You are a helpful assistant.\\n\\n\"\n        \"[Human]\\n\"\n        \"What's the weather like today?\\n\\n\"\n        \"[AI]\\n\"\n    )\n    assert repr(chatbot) == expected_repr\n\ndef test_panel():\n    system_prompt = \"You are a helpful assistant.\"\n    chatbot = ChatBot(system_prompt)\n    app = chatbot.panel()\n    assert isinstance(app, type(pn.template.FastListTemplate()))\n</code></pre>\nNote that the `test_panel` function assumes that the `pn` module is available in the test environment. If it is not, you may need to install it or mock it out for testing purposes.\n\nAlso note that the `test_call` function assumes that the `response` object has a `__class__` attribute that can be used to check its type. If this is not the case, you may need to modify the test to use a different method of checking the type of the response object.\n\nFinally, note that these tests are not exhaustive and may not cover all possible edge cases or error conditions. You may want to add additional tests to ensure that the `ChatBot` class is working correctly in all scenarios.\n</code>\n</pre> <p>On the other hand, accessing the <code>.messages</code> attribute of the ChatBot will give you access to all of the messages inside the conversation.</p> <pre><code>code_tester.messages\n</code></pre> <pre>\n<code>[HumanMessage(content='\\nclass ChatBot:\\n    \"\"\"Chat Bot that is primed with a system prompt, accepts a human message.\\n\\n    Automatic chat memory management happens.\\n\\n    h/t Andrew Giessel/GPT4 for the idea.\\n    \"\"\"\\n\\n    def __init__(self, system_prompt, temperature=0.0, model_name=\"gpt-4\"):\\n        \"\"\"Initialize the ChatBot.\\n\\n        :param system_prompt: The system prompt to use.\\n        :param temperature: The model temperature to use.\\n            See https://platform.openai.com/docs/api-reference/completions/create#completions/create-temperature\\n            for more information.\\n        :param model_name: The name of the OpenAI model to use.\\n        \"\"\"\\n        self.model = ChatOpenAI(\\n            model_name=model_name,\\n            temperature=temperature,\\n            streaming=True,\\n            verbose=True,\\n            callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),\\n        )\\n        self.chat_history = [\\n            SystemMessage(content=\"Always return Markdown-compatible text.\"),\\n            SystemMessage(content=system_prompt),\\n        ]\\n\\n    def __call__(self, human_message) -&gt; Response:\\n        \"\"\"Call the ChatBot.\\n\\n        :param human_message: The human message to use.\\n        :return: The response to the human message, primed by the system prompt.\\n        \"\"\"\\n        self.chat_history.append(HumanMessage(content=human_message))\\n        response = self.model(self.chat_history)\\n        self.chat_history.append(response)\\n        return response\\n\\n    def __repr__(self):\\n        \"\"\"Return a string representation of the ChatBot.\\n\\n        :return: A string representation of the ChatBot.\\n        \"\"\"\\n        representation = \"\"\\n\\n        for message in self.chat_history:\\n            if isinstance(message, SystemMessage):\\n                prefix = \"[System]\\n\"\\n            elif isinstance(message, HumanMessage):\\n                prefix = \"[Human]\\n\"\\n            elif isinstance(message, AIMessage):\\n                prefix = \"[AI]\\n\"\\n\\n            representation += f\"{prefix}{message.content}\" + \"\\n\\n\"\\n        return representation\\n\\n    def panel(self, show: bool = True):\\n        \"\"\"Create a Panel app that wraps a LlamaBot.\\n\\n        :param show: Whether to show the app.\\n            If False, we return the Panel app directly.\\n            If True, we call `.show()` on the app.\\n        :return: The Panel app, either showed or directly.\\n        \"\"\"\\n\\n        text_input = pn.widgets.TextAreaInput(placeholder=\"Start chatting...\")\\n        chat_history = pn.Column(*[])\\n        send_button = pn.widgets.Button(name=\"Send\", button_type=\"primary\")\\n\\n        def b(event):\\n            \"\"\"Button click handler.\\n\\n            :param event: The button click event.\\n            \"\"\"\\n            chat_messages = []\\n            for message in self.chat_history:\\n                if isinstance(message, SystemMessage):\\n                    pass\\n                elif isinstance(message, HumanMessage):\\n                    chat_markdown = pn.pane.Markdown(f\"Human: {message.content}\")\\n                    chat_messages.append(chat_markdown)\\n                elif isinstance(message, AIMessage):\\n                    chat_markdown = pn.pane.Markdown(f\"Bot: {message.content}\")\\n                    chat_messages.append(chat_markdown)\\n\\n            chat_messages.append(pn.pane.Markdown(f\"Human: {text_input.value}\"))\\n            bot_reply = pn.pane.Markdown(\"Bot: \")\\n            chat_messages.append(bot_reply)\\n            chat_history.objects = chat_messages\\n            markdown_handler = PanelMarkdownCallbackHandler(bot_reply)\\n            self.model.callback_manager.set_handler(markdown_handler)\\n            self(text_input.value)\\n            text_input.value = \"\"\\n\\n        send_button.on_click(b)\\n        input_pane = pn.Row(text_input, send_button)\\n        output_pane = pn.Column(chat_history, scroll=True, height=500)\\n\\n        main = pn.Row(input_pane, output_pane)\\n        app = pn.template.FastListTemplate(\\n            site=\"ChatBot\",\\n            title=\"ChatBot\",\\n            main=main,\\n            main_max_width=\"768px\",\\n        )\\n        if show:\\n            return app.show()\\n        return app\\n\\n', role='user'),\n AIMessage(content='Here are some tests for the ChatBot class using PyTest:\\n```python\\nimport pytest\\nfrom your_module import ChatBot, SystemMessage, HumanMessage\\n\\ndef test_init():\\n    system_prompt = \"You are a helpful assistant.\"\\n    chatbot = ChatBot(system_prompt)\\n    assert len(chatbot.chat_history) == 2\\n    assert isinstance(chatbot.chat_history[0], SystemMessage)\\n    assert isinstance(chatbot.chat_history[1], SystemMessage)\\n    assert chatbot.chat_history[0].content == \"Always return Markdown-compatible text.\"\\n    assert chatbot.chat_history[1].content == system_prompt\\n\\ndef test_call():\\n    system_prompt = \"You are a helpful assistant.\"\\n    chatbot = ChatBot(system_prompt)\\n    human_message = \"What\\'s the weather like today?\"\\n    response = chatbot(human_message)\\n    assert len(chatbot.chat_history) == 4\\n    assert isinstance(chatbot.chat_history[2], HumanMessage)\\n    assert isinstance(chatbot.chat_history[3], response.__class__)\\n    assert chatbot.chat_history[2].content == human_message\\n\\ndef test_repr():\\n    system_prompt = \"You are a helpful assistant.\"\\n    chatbot = ChatBot(system_prompt)\\n    human_message = \"What\\'s the weather like today?\"\\n    chatbot(human_message)\\n    expected_repr = (\\n        \"[System]\\\\n\"\\n        \"Always return Markdown-compatible text.\\\\n\\\\n\"\\n        \"[System]\\\\n\"\\n        \"You are a helpful assistant.\\\\n\\\\n\"\\n        \"[Human]\\\\n\"\\n        \"What\\'s the weather like today?\\\\n\\\\n\"\\n        \"[AI]\\\\n\"\\n    )\\n    assert repr(chatbot) == expected_repr\\n\\ndef test_panel():\\n    system_prompt = \"You are a helpful assistant.\"\\n    chatbot = ChatBot(system_prompt)\\n    app = chatbot.panel()\\n    assert isinstance(app, type(pn.template.FastListTemplate()))\\n```\\nNote that the `test_panel` function assumes that the `pn` module is available in the test environment. If it is not, you may need to install it or mock it out for testing purposes.\\n\\nAlso note that the `test_call` function assumes that the `response` object has a `__class__` attribute that can be used to check its type. If this is not the case, you may need to modify the test to use a different method of checking the type of the response object.\\n\\nFinally, note that these tests are not exhaustive and may not cover all possible edge cases or error conditions. You may want to add additional tests to ensure that the `ChatBot` class is working correctly in all scenarios.', role='assistant')]</code>\n</pre> <p>You can even access any arbitrary message.</p> <pre><code>print(code_tester.messages[-1].content)\n</code></pre> <pre>\n<code>Here are some tests for the ChatBot class using PyTest:\n<pre><code>import pytest\nfrom your_module import ChatBot, SystemMessage, HumanMessage\n\ndef test_init():\n    system_prompt = \"You are a helpful assistant.\"\n    chatbot = ChatBot(system_prompt)\n    assert len(chatbot.chat_history) == 2\n    assert isinstance(chatbot.chat_history[0], SystemMessage)\n    assert isinstance(chatbot.chat_history[1], SystemMessage)\n    assert chatbot.chat_history[0].content == \"Always return Markdown-compatible text.\"\n    assert chatbot.chat_history[1].content == system_prompt\n\ndef test_call():\n    system_prompt = \"You are a helpful assistant.\"\n    chatbot = ChatBot(system_prompt)\n    human_message = \"What's the weather like today?\"\n    response = chatbot(human_message)\n    assert len(chatbot.chat_history) == 4\n    assert isinstance(chatbot.chat_history[2], HumanMessage)\n    assert isinstance(chatbot.chat_history[3], response.__class__)\n    assert chatbot.chat_history[2].content == human_message\n\ndef test_repr():\n    system_prompt = \"You are a helpful assistant.\"\n    chatbot = ChatBot(system_prompt)\n    human_message = \"What's the weather like today?\"\n    chatbot(human_message)\n    expected_repr = (\n        \"[System]\\n\"\n        \"Always return Markdown-compatible text.\\n\\n\"\n        \"[System]\\n\"\n        \"You are a helpful assistant.\\n\\n\"\n        \"[Human]\\n\"\n        \"What's the weather like today?\\n\\n\"\n        \"[AI]\\n\"\n    )\n    assert repr(chatbot) == expected_repr\n\ndef test_panel():\n    system_prompt = \"You are a helpful assistant.\"\n    chatbot = ChatBot(system_prompt)\n    app = chatbot.panel()\n    assert isinstance(app, type(pn.template.FastListTemplate()))\n</code></pre>\nNote that the `test_panel` function assumes that the `pn` module is available in the test environment. If it is not, you may need to install it or mock it out for testing purposes.\n\nAlso note that the `test_call` function assumes that the `response` object has a `__class__` attribute that can be used to check its type. If this is not the case, you may need to modify the test to use a different method of checking the type of the response object.\n\nFinally, note that these tests are not exhaustive and may not cover all possible edge cases or error conditions. You may want to add additional tests to ensure that the `ChatBot` class is working correctly in all scenarios.\n</code>\n</pre> <pre><code>\n</code></pre>"},{"location":"examples/chatbot_nb/#chatbots-in-a-jupyter-notebook","title":"ChatBots in a Jupyter Notebook","text":""},{"location":"examples/imagebot/","title":"Imagebot","text":"<pre><code>%load_ext autoreload\n%autoreload 2\n</code></pre> <pre><code>from llamabot.bot.imagebot import ImageBot\n</code></pre> <pre><code>bot = ImageBot()\nbot(\"A siamese cat.\")\n</code></pre>"},{"location":"examples/imagebot/#imagebot","title":"ImageBot","text":"<p>This notebook shows how to use the ImageBot API to generate images from text. Underneath the hood, it uses the OpenAI API. This bot can be combined with other bots (e.g. <code>SimpleBot</code>) to create rich content.</p>"},{"location":"examples/pdf/","title":"Pdf","text":"<pre><code># PDF Chatbot\n%load_ext autoreload\n%autoreload 2\n</code></pre> <pre><code># Download pre-built index.json file from Dropbox\nimport requests\n\nheaders = {\"user-agent\": \"Wget/1.16 (linux-gnu)\"}  # &amp;lt;-- the key is here!\nr = requests.get(\n    \"https://www.dropbox.com/s/wrixlu7e3noi43q/Ma%20et%20al.%20-%202021%20-%20Machine-Directed%20Evolution%20of%20an%20Imine%20Reductase%20f.pdf?dl=0\",\n    stream=True,\n    headers=headers,\n)\npdf_fname = \"/tmp/machine-directed-evolution.pdf\"\nwith open(pdf_fname, \"wb\") as f:\n    for chunk in r.iter_content(chunk_size=1024):\n        if chunk:\n            f.write(chunk)\n</code></pre> <pre><code>from llamabot import QueryBot\nfrom pyprojroot import here\n\n# If you're prototyping with your own PDF, uncomment the following code and use it instead of the saved index path:\n# bot = QueryBot(\n#     \"You are a bot that reads a PDF book and responds to questions about that book.\",\n#     document_paths=[pdf_fname],\n#     collection_name=\"machine-directed-evolution-paper\",\n#     model_name=\"mistral/mistral-medium\",\n# )\n\nbot = QueryBot(\n    \"You are a bot that reads a PDF book and responds to questions about that book.\",\n    collection_name=\"machine-directed-evolution-paper\",\n    model_name=\"mistral/mistral-medium\",\n)\n</code></pre> <pre><code>prompt = \"I'd like to use the workflow of this paper to educate colleagues. What are the main talking points I should use?\"\nbot(prompt)\n</code></pre> <pre><code>prompt = \"My colleagues are interested in evolving another enzyme. However, they may be unaware of how machine learning approaches will help them there. Based on this paper, what can I highlight that might overcome their lack of knowledge?\"\nbot(prompt)\n</code></pre> <pre><code>prompt = \"What data from the paper helped show this point, 'Machine-directed evolution is an efficient strategy for enzyme engineering, as it can help navigate enzyme sequence space more effectively and reduce the number of enzyme variants to be measured en route to a desirable enzyme under realistic process conditions.'?\"\nbot(prompt)\n</code></pre> <pre><code>prompt = \"How can I succinctly present the SGM vs. EPPCR results to my colleagues? Or in other words, how would Richard Feynman present these results?\"\nbot(prompt)\n</code></pre> <p>Using SimpleBot below should prove that we are indeed querying a book and not just relying on the LLM's training set.</p> <pre><code>from llamabot import SimpleBot\n\n\nsbot = SimpleBot(\"You are a bot that responds to human questions.\")\nsbot(prompt)\n</code></pre> <pre><code>\n</code></pre>"},{"location":"examples/querybot/","title":"Querybot","text":"<pre><code>%load_ext autoreload\n%autoreload 2\n</code></pre> <pre><code>from llamabot import QueryBot\nimport git\nfrom IPython.display import display, Markdown\n</code></pre> <pre><code>import tempfile\nfrom pathlib import Path\n\n# Create a temporary directory\ntemp_dir = tempfile.TemporaryDirectory(dir=\"/tmp\")\n\n\nrepo_url = \"https://github.com/duckdb/duckdb-web\"\n# Clone the repository into the temporary directory\nrepo = git.Repo.clone_from(repo_url, temp_dir.name)\n\n# Set the root directory to the cloned repository\nroot_dir = Path(temp_dir.name)\n</code></pre> <pre><code>from slugify import slugify\nimport chromadb\n\nclient = chromadb.PersistentClient(path=str(Path.home() / \".llamabot\" / \"chroma.db\"))\ncollection = client.create_collection(slugify(repo_url), get_or_create=True)\n\nresults = collection.get()\n</code></pre> <pre><code>source_file_extensions = [\n    \"py\",\n    \"jl\",\n    \"R\",\n    \"ipynb\",\n    \"md\",\n    \"tex\",\n    \"txt\",\n    \"lr\",\n    \"rst\",\n]\n\n\nsource_files = []\nfor extension in source_file_extensions:\n    files = list(root_dir.rglob(f\"*.{extension}\"))\n    print(f\"Found {len(files)} files with extension {extension}.\")\n    source_files.extend(files)\n</code></pre> <pre><code>from slugify import slugify\nbot = QueryBot(\n    system_prompt=\"You are an expert in the code repository given to you.\",\n    collection_name=slugify(repo_url),\n    document_paths=source_files,\n)\n</code></pre> <pre><code>bot(\"Give me an example of lambda functions in DuckDB.\")\n</code></pre> <pre><code>bot(\"What is your view on building a digital portfolio?\")\n</code></pre> <pre><code>bot(\"What were your experiences with the SciPy conference?\")\n</code></pre> <pre><code>bot(\"What tutorials did you attend at the SciPy conference in 2023?\")\n</code></pre> <pre><code>from numpy import source\nfrom llamabot.file_finder import recursive_find\nfrom pyprojroot import here\n\nsource_python_files = recursive_find(root_dir=here() / \"llamabot\", file_extension=\".py\")\n\ncodebot = QueryBot(\n    \"You are an expert in code Q&amp;amp;A.\",\n    collection_name=\"llamabot\",\n    document_paths=source_python_files,\n    model_name=\"gpt-4-1106-preview\",\n)\n</code></pre> <pre><code>codebot(\"How do I find all the files in a directory?\")\n</code></pre> <pre><code>codebot(\"Which Bot do I use to chat with my documents?\")\n</code></pre> <pre><code>codebot(\"Explain to me the architecture of SimpleBot.\")\n</code></pre> <pre><code>codebot(\"What are the CLI functions available in LlamaBot?\")\n</code></pre> <pre><code>from llamabot.bot.qabot import DocQABot\n\ncodebot = DocQABot(\n    collection_name=\"llamabot\",\n)\ncodebot.add_documents(document_paths=source_python_files)\n</code></pre> <pre><code>codebot(\n    \"Does LlamaBot provide a function to find all files recursively in a directory?\"\n)\n</code></pre> <pre><code>\n</code></pre>"},{"location":"examples/querybot/#eric-ma-qa","title":"Eric Ma Q&amp;A","text":"<p>This shows how to build a blog Q&amp;A bot using the text contents of Eric Ma's blog.</p>"},{"location":"examples/querybot/#setup-download-blog-data","title":"Setup: Download blog data","text":""},{"location":"examples/querybot/#llamabot-code-query","title":"LlamaBot Code Query","text":""},{"location":"examples/recorder/","title":"Recorder","text":"<pre><code>from llamabot import SimpleBot, PromptRecorder\n</code></pre> <pre><code>bot = SimpleBot(\"You are a bot.\")\n</code></pre> <pre><code># Try three different prompts.\n\nprompt1 = (\n    \"You are a fitness coach who responds in 25 words or less. How do I gain muscle?\"\n)\nprompt2 = \"You are an expert fitness coach who responds in 100 words or less. How do I gain muscle?\"\nprompt3 = \"You are an expert fitness coach who responds in 25 words or less and will not give lethal advice. How do I gain muscle?\"\n\nrecorder = PromptRecorder()\n</code></pre> <pre><code>with recorder:\n    bot(prompt1)\n    bot(prompt2)\n    bot(prompt3)\n</code></pre> <pre><code>recorder.prompts_and_responses\n</code></pre> <pre><code>import pandas as pd\n\npd.DataFrame(recorder.prompts_and_responses)\n</code></pre> <pre><code>prompt4 = \"You are an expert fitness coach who responds in 25 words or less, and you help people who only have access to body weight exercises. How do I gain muscle?\"\n\nwith recorder:\n    bot(prompt4)\n</code></pre> <pre><code>recorder.panel()\n</code></pre> <pre><code>\n</code></pre>"},{"location":"examples/recorder/#recording-prompts","title":"Recording Prompts","text":"<p>One challenge I've found when working with prompts is recording what I get back when I try out different prompts. Copying and pasting is clearly not what I'd like to do. So I decided to write some functionality into Llamabot that lets us do recording of prompts  and the responses returned by GPT.</p> <p>Here's how to use it.</p>"},{"location":"examples/simple_panel/","title":"Simple panel","text":"<pre><code>%load_ext autoreload\n%autoreload 2\n</code></pre> <p>This notebook shows how to create a simple Panel app surrounding SimpleBot.</p> <p>Firstly, our imports:</p> <pre><code>from llamabot import SimpleBot\n</code></pre> <p>Then we create the bot, in this case, a Feynman bot:</p> <pre><code>feynman = SimpleBot(\n\"\"\"\nYou are Richard Feynman.\nYou will be given a difficult concept, and your task is to explain it back.\n\"\"\"\n)\n</code></pre> <p>We'll build an app that lets others take in a chunk of text (an abstract) that the Feynman bot will re-explain back to us. </p> <p>For that, we'll need to start with a text area input:</p> <pre><code>app = feynman.panel(\n    input_text_label=\"Abstract\",\n    output_text_label=\"Summary\",\n    site_name=\"Feynman Bot\",\n    title=\"Feynman Bot\",\n)\n</code></pre> <pre><code>app.show()\n</code></pre> <p>To run this, execute the following command from the repo root:</p> <pre><code>panel run docs/simple_panel.ipynb\n</code></pre>"},{"location":"examples/simple_panel/#simplebot-apps","title":"SimpleBot Apps","text":""},{"location":"examples/simple_panel/#build-the-ui","title":"Build the UI","text":""},{"location":"examples/simplebot/","title":"Simplebot","text":"<pre><code>%load_ext autoreload\n%autoreload 2\n</code></pre> <p>Let's say we have the text of a blog...</p> <pre><code>with open(\"../../data/blog_text.txt\", \"r+\") as f:\n    blog_text = f.read()\nblog_text[0:100] + \"...\"\n</code></pre> <p>And we'd like to create a function that takes in the text and gives us a draft LinkedIn post, complete with emojis, that is designed to entice others to read the blog post. LLaMaBot's <code>SimpleBot</code> lets us build that function easily.</p> <pre><code>from llamabot import SimpleBot\n\nsystem_prompt = \"\"\"You are a LinkedIn post generator bot.\nA human will give you the text of a blog post that they've authored,\nand you will compose a LinkedIn post that advertises it.\nThe post is intended to hook a reader into reading the blog post.\nThe LinkedIn post should be written with one line per sentence.\nEach sentence should begin with an emoji appropriate to that sentence.\nThe post should be written in professional English and in first-person tone for the human.\n\"\"\"\n\nlinkedin = SimpleBot(\n    system_prompt=system_prompt,\n    stream_target=\"stdout\",  # this is the default!,\n    model_name=\"gpt-4-0125-preview\",\n)\n</code></pre> <p>Note that SimpleBot by default will always stream.  All that you need to configure is where you want to stream to.</p> <p>With <code>linkedin</code>, we can now pass in the blog text and - voila! - get back a draft LinkedIn post.</p> <pre><code>linkedin_post = linkedin(blog_text)\n</code></pre> <p>Now, you can edit it to your hearts content! :-)</p> <p>Next up, we have streaming that is compatible with Panel's Chat interface, which expects the text to be returned in its entirety as it is being built up.</p> <pre><code>linkedin_panel = SimpleBot(\n    system_prompt=system_prompt,\n    stream_target=\"panel\",\n)\n</code></pre> <pre><code>linkedin_post = linkedin_panel(blog_text)\n</code></pre> <pre><code>for post in linkedin_post:\n    print(post)\n</code></pre> <p>And finally, we have streaming via the API. We return a generator that yields individual parts of text as they are being generated.</p> <pre><code>linkedin_api = SimpleBot(\n    system_prompt=system_prompt,\n    stream_target=\"api\",\n)\n\nlinkedin_post = linkedin_api(blog_text)\nfor post in linkedin_post:\n    print(post, end=\"\")\n</code></pre> <p>If you have an Ollama server running, you can hit the API using SimpleBot. The pre-requisite is that you have already run <code>ollama pull &lt;modelname&gt;</code>  to download the model to the Ollama server. </p> <pre><code>print(system_prompt)\n</code></pre> <pre><code>import os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nlinkedin_ollama = SimpleBot(\n    model_name=\"ollama/mistral\",  # Specifying Ollama via the model_name argument is necessary!s\n    system_prompt=system_prompt,\n    stream_target=\"stdout\",  # this is the default!\n    api_base=f\"http://{os.getenv('OLLAMA_SERVER')}:11434\",\n)\nlinkedin_post = linkedin_ollama(blog_text)\n</code></pre> <pre><code>\n</code></pre>"},{"location":"examples/simplebot/#llamabots-simplebot-in-under-5-minutes","title":"LLaMaBot's SimpleBot in under 5 minutes","text":""},{"location":"modules/doc_processor/","title":"Doc Processor","text":"<p>Note</p> <p>This tutorial was written by GPT4 and edited by a human.</p> <p>The doc processor is a Python script designed to preprocess documents by loading them from various file formats and splitting them into smaller sub-documents. It works in two main steps:</p> <p>(1) Loading documents: The <code>magic_load_doc</code> function is used to load a document from a file. It automatically detects the file format based on the file extension and uses the appropriate loader to read the content. Supported file formats include PDF, DOCX, PPTX, XLSX, Markdown, and IPYNB. If the file format is not recognized, it is treated as a plain text file.</p> <p>(2) Splitting documents: The <code>split_document</code> function is used to split a document into smaller sub-documents using a token text splitter. You can specify the maximum length of each sub-document (<code>chunk_size</code>) and the number of tokens to overlap between each sub-document (<code>chunk_overlap</code>). The function returns a list of sub-documents.</p> <p>To use the doc processor, simply import the required functions and call them with the appropriate parameters. For example:</p> <pre><code>from llamabot.doc_processor import magic_load_doc, split_document\n\n# Load a document from a file\nfile_path = \"path/to/your/document.pdf\"\ndocuments = magic_load_doc(file_path)\n\n# Split the document into sub-documents\nchunk_size = 2000\nchunk_overlap = 0\nsub_documents = [split_document(doc, chunk_size, chunk_overlap) for doc in documents]\n</code></pre> <p>This will give you a list of sub-documents that can be further processed inside QueryBot.</p>"},{"location":"modules/file_finder/","title":"File Handling in Python: A Tutorial","text":"<p>In this tutorial, we will explore a module that provides functions for file handling in Python. The module contains three main functions:</p> <ol> <li><code>recursive_find(root_dir: Path, file_extension: str) -&gt; List[Path]</code>: Find all files in a given path with a given extension.</li> <li><code>check_in_git_repo(path) -&gt; bool</code>: Check if a given path is in a git repository.</li> <li><code>read_file(path: Path) -&gt; str</code>: Read a file.</li> </ol> <p>Let's dive into each function and see how they can be used.</p>"},{"location":"modules/file_finder/#1-finding-files-recursively","title":"1. Finding Files Recursively","text":"<p>The <code>recursive_find</code> function allows you to find all files with a specific extension within a given directory and its subdirectories. This can be useful when you want to process all files of a certain type in a project.</p>"},{"location":"modules/file_finder/#usage","title":"Usage","text":"<p>To use the <code>recursive_find</code> function, you need to provide two arguments:</p> <ul> <li><code>root_dir</code>: The directory in which to search for files.</li> <li><code>file_extension</code>: The file extension to search for. For example, use \".py\" for Python files, not \"py\".</li> </ul> <p>Here's an example of how to use the <code>recursive_find</code> function:</p> <pre><code>from pathlib import Path\nfrom llamabot.file_finder import recursive_find\n\nroot_directory = Path(\"path/to/your/directory\")\nfile_extension = \".py\"\n\npython_files = recursive_find(root_directory, file_extension)\nprint(python_files)\n</code></pre> <p>This will output a list of <code>Path</code> objects representing all the Python files found in the specified directory and its subdirectories.</p>"},{"location":"modules/file_finder/#2-checking-if-a-path-is-in-a-git-repository","title":"2. Checking if a Path is in a Git Repository","text":"<p>The <code>check_in_git_repo</code> function allows you to check if a given path is part of a git repository. This can be useful when you want to ensure that your code is only executed within a version-controlled environment.</p>"},{"location":"modules/file_finder/#usage_1","title":"Usage","text":"<p>To use the <code>check_in_git_repo</code> function, you need to provide one argument:</p> <ul> <li><code>path</code>: The path to check.</li> </ul> <p>Here's an example of how to use the <code>check_in_git_repo</code> function:</p> <pre><code>from pathlib import Path\nfrom llamabot.file_finder import check_in_git_repo\n\npath_to_check = Path(\"path/to/your/directory\")\n\nis_in_git_repo = check_in_git_repo(path_to_check)\nprint(is_in_git_repo)\n</code></pre> <p>This will output <code>True</code> if the specified path is part of a git repository, and <code>False</code> otherwise.</p>"},{"location":"modules/file_finder/#3-reading-a-file","title":"3. Reading a File","text":"<p>The <code>read_file</code> function allows you to read the contents of a file. This can be useful when you want to process the contents of a file, such as analyzing code or parsing data.</p>"},{"location":"modules/file_finder/#usage_2","title":"Usage","text":"<p>To use the <code>read_file</code> function, you need to provide one argument:</p> <ul> <li><code>path</code>: The path to the file to be read.</li> </ul> <p>Here's an example of how to use the <code>read_file</code> function:</p> <pre><code>from pathlib import Path\nfrom llamabot.file_finder import read_file\n\nfile_path = Path(\"path/to/your/file.txt\")\n\nfile_contents = read_file(file_path)\nprint(file_contents)\n</code></pre> <p>This will output the contents of the specified file.</p>"},{"location":"modules/file_finder/#conclusion","title":"Conclusion","text":"<p>In this tutorial, we have explored a module that provides functions for file handling in Python. By using these functions, you can easily find files with specific extensions, check if a path is part of a git repository, and read the contents of a file. These functions can be combined to create powerful file processing pipelines in your Python projects.</p>"},{"location":"modules/prompt_recorder/","title":"PromptRecorder","text":"<p>Note</p> <p>This tutorial was written by GPT4 and edited by a human.</p> <p>The prompt recorder is a class named <code>PromptRecorder</code> that helps in recording prompts and responses. It works as a context manager, allowing you to record prompts and responses within a specific context. Here's a brief overview of how it works:</p> <ol> <li> <p>The <code>PromptRecorder</code> class is initialized with an empty list called <code>prompts_and_responses</code> to store the prompts and responses.</p> </li> <li> <p>When entering the context manager using the <code>with</code> statement, the <code>__enter__()</code> method is called, which sets the current instance of the <code>PromptRecorder</code> as the active recorder in the <code>prompt_recorder_var</code> context variable.</p> </li> <li> <p>To log a prompt and response, the <code>log()</code> method is called with the prompt and response as arguments. This method appends the prompt and response as a dictionary to the <code>prompts_and_responses</code> list.</p> </li> <li> <p>The <code>autorecord()</code> function is provided to be called within every bot. It checks if there is an active <code>PromptRecorder</code> instance in the context and logs the prompt and response using the <code>log()</code> method.</p> </li> <li> <p>When exiting the context manager, the <code>__exit__()</code> method is called, which resets the <code>prompt_recorder_var</code> context variable to <code>None</code> and prints a message indicating that the recording is complete.</p> </li> <li> <p>The <code>PromptRecorder</code> class also provides methods to represent the recorded data in different formats, such as a string representation (<code>__repr__()</code>), an HTML representation (<code>_repr_html_()</code>), a pandas DataFrame representation (<code>dataframe()</code>), and a panel representation (<code>panel()</code>).</p> </li> </ol> <p>By using the <code>PromptRecorder</code> class as a context manager, you can easily record prompts and responses within a specific context and then analyze or display the recorded data in various formats.</p>"},{"location":"releases/v0.0.10/","title":"V0.0.10","text":""},{"location":"releases/v0.0.10/#0010","title":"0.0.10","text":"<p>This new version introduces experiments with Llamahub document loaders, updates workspace settings, and makes Panel an official dependency. It also includes a new Panel example and a correction in the docstring for accuracy.</p>"},{"location":"releases/v0.0.10/#new-features","title":"New Features","text":"<ul> <li>Experiments with Llamahub document loaders have been added to enhance functionality (8faea4) (Eric Ma)</li> <li>Workspace settings have been updated to improve user experience (3b5522) (Eric Ma)</li> <li>Panel has been made an official dependency to streamline the software's requirements (781906) (Eric Ma)</li> <li>A new Panel example has been added to provide users with more comprehensive usage scenarios (2209cd) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.10/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>The docstring has been edited for correctness to ensure accurate documentation (0ee1ca) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.10/#deprecations","title":"Deprecations","text":"<ul> <li>No deprecations in this release.</li> </ul>"},{"location":"releases/v0.0.11/","title":"V0.0.11","text":""},{"location":"releases/v0.0.11/#version-0011","title":"Version 0.0.11","text":"<p>This version introduces automatic recording of prompts, improves the recording process, and verifies its functionality. It also includes a cleanup of notebooks and adds loguru as a dependency.</p>"},{"location":"releases/v0.0.11/#new-features","title":"New Features","text":"<ul> <li>Added automatic recording of prompts (2c956f) (Eric Ma)</li> <li>Improved automatic recording of prompts (50779c) (Eric Ma)</li> <li>Verified that the recorder works (aa428a) (Eric Ma)</li> <li>Added loguru as a dependency (23ee02) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.11/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Fixed return type (3986b7) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.11/#other-changes","title":"Other Changes","text":"<ul> <li>Cleaned up notebooks (3c5a74) (Eric Ma)</li> <li>Reorganized notebook structure (4bee78) (Eric Ma)</li> <li>Enabled context manager for recording prompt-response pairs (e6a8b4) (Eric Ma)</li> <li>Settled on a stuff-the-text-into-prompt pattern rather than synthesizing and refining response. This makes things faster (7020d0) (Eric Ma)</li> <li>Enabled arbitrary loading of documents, not just text files (e4223c) (Eric Ma)</li> <li>Switched to using servable for feynman example (e50e45) (Eric Ma)</li> <li>Disabled test mode. A different way to make mock API calls work will be found (7a7beb) (Eric Ma)</li> <li>More experiments with llamahub loaders (4b2871) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.11/#deprecations","title":"Deprecations","text":"<ul> <li>No deprecations in this release.</li> </ul>"},{"location":"releases/v0.0.12/","title":"V0.0.12","text":""},{"location":"releases/v0.0.12/#version-0012","title":"Version 0.0.12","text":"<p>This new version introduces a panel representation of a recorder class and includes a version bump.</p>"},{"location":"releases/v0.0.12/#new-features","title":"New Features","text":"<ul> <li>Added a panel representation of a recorder class to enhance the user interface and functionality (18ae007) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.12/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>No bug fixes in this release.</li> </ul>"},{"location":"releases/v0.0.12/#deprecations","title":"Deprecations","text":"<ul> <li>No deprecations in this release.</li> </ul>"},{"location":"releases/v0.0.13/","title":"V0.0.13","text":""},{"location":"releases/v0.0.13/#version-0013","title":"Version 0.0.13","text":"<p>This new version includes an update to the example about querying PDFs and a bug fix related to query nodes. The version has been bumped from 0.0.12 to 0.0.13.</p>"},{"location":"releases/v0.0.13/#new-features","title":"New Features","text":"<ul> <li>The example about querying PDFs has been updated to provide more clarity and better understanding (8169ce) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.13/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Fixed a bug where query nodes were hard-coded to 3, which limited the flexibility of the system. Now, the number of query nodes is dynamic (6802ac) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.13/#deprecations","title":"Deprecations","text":"<ul> <li>No deprecations in this release.</li> </ul>"},{"location":"releases/v0.0.14/","title":"V0.0.14","text":""},{"location":"releases/v0.0.14/#version-0014","title":"Version 0.0.14","text":"<p>This new version includes several enhancements and bug fixes to improve the overall performance and user experience of the Llamabot. The Python environment and llama_index versions have been pinned for stability. The chatbot panel app now uses a width of 600 pixels for better UI. The Querybot system message now applies SEMBR for improved readability.</p>"},{"location":"releases/v0.0.14/#new-features","title":"New Features","text":"<ul> <li>The chatbot panel app now uses a width of 600 pixels for a more user-friendly interface (7e2f05) (Eric Ma)</li> <li>Faux chat history of length 6000 tokens is now used as context for further responses in chatbot, enhancing the chatbot's response accuracy (02ef9d) (Eric Ma)</li> <li>SEMBR has been applied on the Querybot system message for improved readability (b3c53c) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.14/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Fixed UI for a smoother user experience (733759) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.14/#deprecations","title":"Deprecations","text":"<ul> <li>The version of the Python environment has been pinned to 3.9 to ensure compatibility and stability (5db1ae) (Eric Ma)</li> <li>The version of llama_index has been pinned for stability (930cbb) (Eric Ma)</li> <li>Temporarily settled on an older version of langchain for the time being (af0938) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.14/#refactors","title":"Refactors","text":"<ul> <li>Refactored Querybot to allow loading of documents later, enhancing the flexibility of the system (3103d9) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.15/","title":"V0.0.15","text":""},{"location":"releases/v0.0.15/#0015","title":"0.0.15","text":"<p>This new version includes an update to the environment to fix bokeh versions and a version bump.</p>"},{"location":"releases/v0.0.15/#new-features","title":"New Features","text":"<ul> <li>None in this release</li> </ul>"},{"location":"releases/v0.0.15/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Fixed bokeh versions in the environment to ensure compatibility and smooth operation (8c48f7) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.15/#deprecations","title":"Deprecations","text":"<ul> <li>None in this release</li> </ul>"},{"location":"releases/v0.0.16/","title":"V0.0.16","text":""},{"location":"releases/v0.0.16/#0016","title":"0.0.16","text":"<p>This new version includes an update to the pyproject.toml file and a version bump from 0.0.15 to 0.0.16.</p>"},{"location":"releases/v0.0.16/#new-features","title":"New Features","text":"<ul> <li>No new features were added in this version.</li> </ul>"},{"location":"releases/v0.0.16/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>No bug fixes were made in this version.</li> </ul>"},{"location":"releases/v0.0.16/#updates","title":"Updates","text":"<ul> <li>The pyproject.toml file was updated (3773a5) (Eric Ma)</li> <li>The version was bumped from 0.0.15 to 0.0.16 (b55951) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.16/#deprecations","title":"Deprecations","text":"<ul> <li>No deprecations were made in this version.</li> </ul>"},{"location":"releases/v0.0.17/","title":"V0.0.17","text":""},{"location":"releases/v0.0.17/#version-0017","title":"Version 0.0.17","text":"<p>This new version includes updates to the versions of bokeh used in the project. The bokeh version has been pinned to ensure compatibility and stability of the project.</p>"},{"location":"releases/v0.0.17/#new-features","title":"New Features","text":"<ul> <li>No new features were added in this version.</li> </ul>"},{"location":"releases/v0.0.17/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>The versions of bokeh used in the project have been updated to ensure compatibility and stability. (96a89e) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.17/#deprecations","title":"Deprecations","text":"<ul> <li>The bokeh version has been pinned to less than or equal to 3.1.0 to prevent potential issues with future versions. (2a93d9) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.18/","title":"V0.0.18","text":""},{"location":"releases/v0.0.18/#0018","title":"0.0.18","text":"<p>This version does not include any significant changes, as the commit was a work-in-progress save.</p>"},{"location":"releases/v0.0.18/#other-changes","title":"Other Changes","text":"<ul> <li>Work-in-progress save (1ef5bf1) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.19/","title":"V0.0.19","text":""},{"location":"releases/v0.0.19/#0019","title":"0.0.19","text":"<p>This version includes a bug fix related to the insertion of documents into the index.</p>"},{"location":"releases/v0.0.19/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Fixed bug with insert_documents_into_index (d788ed9) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.20/","title":"V0.0.20","text":""},{"location":"releases/v0.0.20/#0020","title":"0.0.20","text":"<p>This version includes the deletion of a codepath where the index was set to None.</p>"},{"location":"releases/v0.0.20/#deprecations","title":"Deprecations","text":"<ul> <li>Deleted codepath where index was set to None (f0443e9) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.21/","title":"V0.0.21","text":""},{"location":"releases/v0.0.21/#0021","title":"0.0.21","text":"<p>This version includes the addition of a new scratch notebook on querying JMLR paper and two default processors.</p>"},{"location":"releases/v0.0.21/#new-features","title":"New Features","text":"<ul> <li>New scratch notebook on querying JMLR paper added (d05c539) (Eric Ma)</li> <li>Two default processors added (408f0d0) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.22/","title":"V0.0.22","text":""},{"location":"releases/v0.0.22/#0022","title":"0.0.22","text":"<p>This version includes the addition of outlines to the pyproject.toml file and the completion of an example notebook on doing a paper review.</p>"},{"location":"releases/v0.0.22/#new-features","title":"New Features","text":"<ul> <li>Outlines added to pyproject.toml (d1ff517) (Eric Ma)</li> <li>Completed example notebook on doing a paper review (324d353) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.23/","title":"V0.0.23","text":""},{"location":"releases/v0.0.23/#0023","title":"0.0.23","text":"<p>This new version includes a variety of enhancements and new features, including the addition of a coding bot panel app, a refactor of the CLI, and updates to the notebooks and tutorial materials. The version also includes the integration of pyzotero to dependencies and the beginning of a prototype for coding and diffbots in a library of bots.</p>"},{"location":"releases/v0.0.23/#new-features","title":"New Features","text":"<ul> <li>Added a coding bot panel app (a139420) (Eric Ma)</li> <li>Refactored the CLI for better performance and usability (b067193) (Eric Ma)</li> <li>Updated the scratch notebook (c0a4e2b) (Eric Ma)</li> <li>Added a code tutorial notebook to help users understand how to use the application (ae42c64) (Eric Ma)</li> <li>Added instructions in the codingbot source file to provide more context for the code tutorial bot (79236f) (Eric Ma)</li> <li>Added more notebooks to save work and enhance the user experience (891e570) (Eric Ma)</li> <li>Added pyzotero to dependencies to enhance the functionality of the application (1d55eb2) (Eric Ma)</li> <li>Began the prototype of coding and diffbots in a library of bots to expand the application's capabilities (f26c789) (Eric Ma)</li> <li>Updated the blog text demo for better user understanding (ae9c539) (Eric Ma)</li> <li>Updated base bots to use the updated llamaindex for improved performance (baad16c) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.23/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Fixed the placement of noqa DAR101 for better code quality (d73b14f) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.23/#deprecations","title":"Deprecations","text":"<ul> <li>No deprecations in this release.</li> </ul>"},{"location":"releases/v0.0.24/","title":"V0.0.24","text":""},{"location":"releases/v0.0.24/#0024","title":"0.0.24","text":"<p>This new version introduces the ability to configure the port and address, providing more flexibility and control to the users.</p>"},{"location":"releases/v0.0.24/#new-features","title":"New Features","text":"<ul> <li>Made port and address configurable, allowing users to set these parameters as per their requirements (0920e4) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.24/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>No bug fixes in this release.</li> </ul>"},{"location":"releases/v0.0.24/#deprecations","title":"Deprecations","text":"<ul> <li>No deprecations in this release.</li> </ul>"},{"location":"releases/v0.0.25/","title":"V0.0.25","text":""},{"location":"releases/v0.0.25/#0025","title":"0.0.25","text":"<p>This new version includes improvements to the basecallbackmanager and the pinned version of langchain.</p>"},{"location":"releases/v0.0.25/#new-features","title":"New Features","text":"<ul> <li>The basecallbackmanager now requires an explicit handlers argument, enhancing clarity and reducing potential for errors (169f72) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.25/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>No bug fixes in this release.</li> </ul>"},{"location":"releases/v0.0.25/#deprecations","title":"Deprecations","text":"<ul> <li>The version of langchain used in the project has been pinned, ensuring stability and compatibility with this version of the software (631c29) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.26/","title":"V0.0.26","text":""},{"location":"releases/v0.0.26/#0026","title":"0.0.26","text":"<p>This new version includes updates to the dependency management of the project. The version of the project has been bumped up from 0.0.25 to 0.0.26.</p>"},{"location":"releases/v0.0.26/#new-features","title":"New Features","text":"<ul> <li>No new features were added in this version.</li> </ul>"},{"location":"releases/v0.0.26/#updates","title":"Updates","text":"<ul> <li>The version of the project has been updated from 0.0.25 to 0.0.26 (894c25) (Eric Ma)</li> <li>The versions of the dependencies have been unpinned, allowing for the latest versions to be used (bc8d64) (Eric Ma)</li> <li>The 'langchain' dependency has been pinned to an exact version to ensure compatibility and stability (2b69d0) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.26/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>No bug fixes were made in this version.</li> </ul>"},{"location":"releases/v0.0.26/#deprecations","title":"Deprecations","text":"<ul> <li>No deprecations were made in this version.</li> </ul>"},{"location":"releases/v0.0.27/","title":"V0.0.27","text":""},{"location":"releases/v0.0.27/#0027","title":"0.0.27","text":"<p>This new version includes several important updates to improve the functionality and security of the Llamabot application.</p>"},{"location":"releases/v0.0.27/#new-features","title":"New Features","text":"<ul> <li>All websocket origins are now allowed, enhancing the connectivity and compatibility of the application (a685f0) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.27/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Fixed the issue with the Querybot index retriever by updating it with the refactored Llamaindex code. This should improve the accuracy and efficiency of the index retriever (12a87b) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.27/#deprecations","title":"Deprecations","text":"<ul> <li>The opening of the app has been disabled. This is a temporary measure for security reasons and will be addressed in future updates (e6e1a4) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.28/","title":"V0.0.28","text":""},{"location":"releases/v0.0.28/#version-0028","title":"Version 0.0.28","text":"<p>This version includes several enhancements and new features, including the addition of new modules and functions, improvements to documentation, and minor updates to notebooks.</p>"},{"location":"releases/v0.0.28/#new-features","title":"New Features","text":"<ul> <li>Added <code>pyperclip</code> to environment spec and requirements (e57f7f) (Eric Ma)</li> <li>Added additional config path for llamabot's OpenAI API key (713579) (Eric Ma)</li> <li>Added function for getting function source from a .py file (07e402) (Eric Ma)</li> <li>Added <code>get_valid_input</code> for user prompts (b001d2) (Eric Ma)</li> <li>Initial commit of llamabot's python bot (e5c67d) (Eric Ma)</li> <li>Added <code>read_file</code> to the <code>file_finder.py</code> source file (5b44d5) (Eric Ma)</li> <li>Added <code>PromptRecorder</code> module documentation (2f208e) (Eric Ma)</li> <li>Added explanation of where <code>autorecord</code> function is supposed to be used (b7a02c) (Eric Ma)</li> <li>Added doc processor documentation (be1bf8) (Eric Ma)</li> <li>Added in tutorials ghostwritten by GPT4 (ace0cd) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.28/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Minor update to scratch notebooks (dc1f76) (Eric Ma)</li> <li>Minor changes on doc processor (4601eb) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.28/#deprecations","title":"Deprecations","text":"<ul> <li>No deprecations in this release.</li> </ul>"},{"location":"releases/v0.0.28/#documentation","title":"Documentation","text":"<ul> <li>Updated module-level docstring for CLI init (ef812f) (Eric Ma)</li> <li>Added module-level docstring prompt (7be6ad) (Eric Ma)</li> <li>Updated docstring based on Llamabot (6d9829) (Eric Ma)</li> <li>Improved <code>doc_processor</code> docstring (fb98de) (Eric Ma)</li> <li>Moved notebooks to examples under docs (998b2d) (Eric Ma)</li> <li>Added note on doc processor documentation that it was written by GPT4 (83abc9) (Eric Ma)</li> <li>Added notes about tutorial being written by GPT in an official modal (4bb2a4) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.29/","title":"V0.0.29","text":""},{"location":"releases/v0.0.29/#version-0029","title":"Version 0.0.29","text":"<p>This version includes a number of new features, improvements, and bug fixes. The main focus of this release was to enhance the testing environment, improve code generation, and add new functionalities.</p>"},{"location":"releases/v0.0.29/#new-features","title":"New Features","text":"<ul> <li>Added float_to_top = true for isort in pyproject.toml config (0c58f8) (Eric Ma)</li> <li>Added tests for doc_processor (d679a0) (Eric Ma)</li> <li>Modified prompt to ensure that docstring indentation is done correctly (1b1ade) (Eric Ma)</li> <li>Added functions replace_object_in_file and insert_docstring (adf44a) (Eric Ma)</li> <li>Added dummy module for experimentation purposes (f27a71) (Eric Ma)</li> <li>Added validation of chunk_overlap value (9d2070) (Eric Ma)</li> <li>Added tests for get_valid_input (0a984b) (Eric Ma)</li> <li>Added comment (511953) (Eric Ma)</li> <li>Added tests for recorder (f38341) (Eric Ma)</li> <li>Added tests for file_finder.py (cfc296) (Eric Ma)</li> <li>Added testwriting functionality (435aa4) (Eric Ma)</li> <li>Added python dotenv to pyproject.toml (0339c2) (Eric Ma)</li> <li>Added more testing deps into the environment (b6bd32) (Eric Ma)</li> <li>Added pytest to gh bare testing env (bef9a6) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.29/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Fixed type hint based on test (8864e0) (Eric Ma)</li> <li>Changed python test version to 3.11 (b4bb40) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.29/#deprecations","title":"Deprecations","text":"<ul> <li>Got rid of typer-cli (b7a187) (Eric Ma)</li> <li>Removed requirements.txt build step (27eea3) (Eric Ma)</li> <li>Removed call test (0578cf) (Eric Ma)</li> <li>Removed model testing (28e8bd) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.29/#improvements","title":"Improvements","text":"<ul> <li>Bumped version from 0.0.28 to 0.0.29 (ad955c) (Eric Ma)</li> <li>Minor changes to Python code generation CLI (3663f8) (Eric Ma)</li> <li>Manually installed testing dependencies (44b3de) (Eric Ma)</li> <li>Ensured bare environment has all optional dependencies installed (8118c1) (Eric Ma)</li> <li>Ensured typer version minimum 0.4.0 in pyproject.toml (8403ad) (Eric Ma)</li> <li>Updated environment.yml to pin typer to greater than 0.4.0 (0804a8) (Eric Ma)</li> <li>Ensured test ghostwriter has access to bigger file context (5ae1e6) (Eric Ma)</li> <li>Modified tests prompt (db9e19) (Eric Ma)</li> <li>Changed test prompt (41a46e) (Eric Ma)</li> <li>Upgraded docstring (e83505) (Eric Ma)</li> <li>Added more explicit validation checks on the presence of the openai API key (d1c508) (Eric Ma)</li> <li>Specified object type for markdown_object (4d3782) (Eric Ma)</li> <li>Upgraded python to 3.11 (55e457) (Eric Ma)</li> <li>Tried out github actions matrix (bc5360) (Eric Ma)</li> <li>Ensured tests run on all pushes to main (23c506) (Eric Ma)</li> <li>Changed version of panel and bokeh (bfeac4) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.3/","title":"V0.0.3","text":""},{"location":"releases/v0.0.3/#003","title":"0.0.3","text":"<p>This new version includes some important changes to the project structure and setup.</p>"},{"location":"releases/v0.0.3/#new-features","title":"New Features","text":"<ul> <li>No new features were added in this version.</li> </ul>"},{"location":"releases/v0.0.3/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>No bug fixes were made in this version.</li> </ul>"},{"location":"releases/v0.0.3/#deprecations","title":"Deprecations","text":"<ul> <li>Removed the setup.py file, indicating a change in the project setup process (796163)</li> </ul>"},{"location":"releases/v0.0.30/","title":"V0.0.30","text":""},{"location":"releases/v0.0.30/#0030","title":"0.0.30","text":"<p>This new version includes an improved error handling mechanism, expanded test coverage, and a minor version bump.</p>"},{"location":"releases/v0.0.30/#new-features","title":"New Features","text":"<ul> <li>Expanded test coverage with the addition of ghostwriting tests (cdb0fe) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.30/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Improved error handling by changing from raising an error to raising a warning (30cc86) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.30/#deprecations","title":"Deprecations","text":"<ul> <li>No deprecations in this release.</li> </ul>"},{"location":"releases/v0.0.30/#other","title":"Other","text":"<ul> <li>Version bumped from 0.0.29 to 0.0.30 (73c1f0) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.31/","title":"V0.0.31","text":""},{"location":"releases/v0.0.31/#0031","title":"0.0.31","text":"<p>This new version includes enhancements to the directory tree functionality and some minor changes.</p>"},{"location":"releases/v0.0.31/#new-features","title":"New Features","text":"<ul> <li>Added functionality to display the directory tree (e8248d) (Eric Ma)</li> <li>Ensured that the directory tree context is passed into the prompt (df93e5) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.31/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>No bug fixes in this release.</li> </ul>"},{"location":"releases/v0.0.31/#deprecations","title":"Deprecations","text":"<ul> <li>No deprecations in this release.</li> </ul>"},{"location":"releases/v0.0.31/#other-changes","title":"Other Changes","text":"<ul> <li>More scratch work done (96b60b) (Eric Ma)</li> <li>Version bumped from 0.0.30 to 0.0.31 (36e55b) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.32/","title":"V0.0.32","text":""},{"location":"releases/v0.0.32/#0032","title":"0.0.32","text":"<p>This new version includes some internal code reorganization for better encapsulation and security.</p>"},{"location":"releases/v0.0.32/#new-features","title":"New Features","text":"<ul> <li>No new features were added in this version.</li> </ul>"},{"location":"releases/v0.0.32/#code-improvements","title":"Code Improvements","text":"<ul> <li>Moved 'codebot' and 'diffbot' into protected functions to enhance code security and maintainability (ce59a0c) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.32/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>No bug fixes were included in this version.</li> </ul>"},{"location":"releases/v0.0.32/#deprecations","title":"Deprecations","text":"<ul> <li>No deprecations were made in this version.</li> </ul>"},{"location":"releases/v0.0.33/","title":"V0.0.33","text":""},{"location":"releases/v0.0.33/#version-0033","title":"Version 0.0.33","text":"<p>This new version includes a significant change in the underlying parsing library, moving from astunparse to astor. This change is expected to improve the performance and reliability of the Llamabot.</p>"},{"location":"releases/v0.0.33/#new-features","title":"New Features","text":"<ul> <li>The version of Llamabot has been updated from 0.0.32 to 0.0.33 (2e4c61) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.33/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>No bug fixes in this release.</li> </ul>"},{"location":"releases/v0.0.33/#deprecations","title":"Deprecations","text":"<ul> <li>The use of astunparse has been deprecated and replaced with astor for better performance and reliability (326c59) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.34/","title":"V0.0.34","text":""},{"location":"releases/v0.0.34/#0034","title":"0.0.34","text":"<p>This version introduces several new features and improvements to the LlamaBot CLI, including the addition of git diff display and commit message generation, a repr method for the Dummy class, and handling for no staged changes in commit_message. It also includes several refactors and a documentation update.</p>"},{"location":"releases/v0.0.34/#new-features","title":"New Features","text":"<ul> <li>Added git diff display and commit message generation functionality to the LlamaBot CLI. This feature imports the get_git_diff function from llamabot.code_manipulation, creates a SimpleBot instance for commit message generation, defines a commit_message function with a text.prompt decorator, and calls commitbot with the generated commit message. (1a6104) (Eric Ma)</li> <li>Added a repr method to the Dummy class in dummy.py. This provides a string representation of the object, making it easier to inspect and debug instances of the Dummy class. (ae3e7c) (Eric Ma)</li> <li>Updated commit_message function in cli/git.py to check for staged changes before generating a commit message. If no staged changes are found, a message is printed and the function returns. The get_git_diff function in code_manipulation.py was also updated to return an empty string if there are no staged changes. (ed7a3d) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.34/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Fixed typos in the llamabot CLI git module. Changes include renaming <code>git.app</code> to <code>git.gitapp</code> in llamabot/cli/init.py, adding missing parentheses to decorators in llamabot/cli/git.py, and replacing \"docstring\" with \"commit message\" in the user prompt. (860930) (Eric Ma)</li> <li>Refactored Typer app and command decorators in git.py. The <code>app</code> was renamed to <code>gitapp</code> for better context, and decorators were updated to use the new <code>gitapp</code> variable. (f7af8b) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.34/#deprecations","title":"Deprecations","text":"<ul> <li>Removed the unnecessary hello command from the git.py file in the llamabot CLI. This simplifies the codebase and focuses on the core functionality. (8f0b9d) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.34/#documentation","title":"Documentation","text":"<ul> <li>Added a detailed explanation of the Conventional Commits specification to the git.py file. This outlines the various commit types, scopes, and footers, as well as their correlation with Semantic Versioning. This information will help users understand the importance of following the Conventional Commits specification when crafting their commit messages. (ca9b1c) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.35/","title":"V0.0.35","text":""},{"location":"releases/v0.0.35/#version-0035","title":"Version 0.0.35","text":"<p>This new version introduces an autocommit option to the commit_message function in llamabot/cli/git.py. This feature allows for automatic committing of changes using the generated commit message when the autocommit parameter is set to True.</p>"},{"location":"releases/v0.0.35/#new-features","title":"New Features","text":"<ul> <li>Added an autocommit option to the commit_message function in llamabot/cli/git.py. When set to True, changes are automatically committed using the generated commit message. (5c202a) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.35/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>None in this release.</li> </ul>"},{"location":"releases/v0.0.35/#deprecations","title":"Deprecations","text":"<ul> <li>None in this release.</li> </ul>"},{"location":"releases/v0.0.36/","title":"V0.0.36","text":""},{"location":"releases/v0.0.36/#0036","title":"0.0.36","text":"<p>This new version includes a refactor of the CLI to improve code readability and understanding.</p>"},{"location":"releases/v0.0.36/#new-features","title":"New Features","text":"<p>No new features were added in this version.</p>"},{"location":"releases/v0.0.36/#bug-fixes","title":"Bug Fixes","text":"<p>No bug fixes were made in this version.</p>"},{"location":"releases/v0.0.36/#refactors","title":"Refactors","text":"<ul> <li>The <code>commit_message</code> function in <code>llamabot/cli/git.py</code> has been renamed to <code>commit</code> to better reflect its purpose of committing staged changes (ae7b10) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.36/#deprecations","title":"Deprecations","text":"<p>No deprecations were made in this version.</p>"},{"location":"releases/v0.0.37/","title":"V0.0.37","text":""},{"location":"releases/v0.0.37/#0037","title":"0.0.37","text":"<p>This new version introduces the GitPython dependency to the project, allowing for Git operations within the project.</p>"},{"location":"releases/v0.0.37/#new-features","title":"New Features","text":"<ul> <li>GitPython dependency added to both environment.yml and pyproject.toml files to support Git operations within the project (aa6140) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.37/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>None in this release</li> </ul>"},{"location":"releases/v0.0.37/#deprecations","title":"Deprecations","text":"<ul> <li>None in this release</li> </ul>"},{"location":"releases/v0.0.38/","title":"V0.0.38","text":""},{"location":"releases/v0.0.38/#version-0038","title":"Version 0.0.38","text":"<p>This new version introduces a new dependency to the project, enhancing the project root path management.</p>"},{"location":"releases/v0.0.38/#new-features","title":"New Features","text":"<ul> <li>Added pyprojroot to the list of dependencies for better project root path management (69444d) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.38/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>No bug fixes in this release.</li> </ul>"},{"location":"releases/v0.0.38/#deprecations","title":"Deprecations","text":"<ul> <li>No deprecations in this release.</li> </ul>"},{"location":"releases/v0.0.39/","title":"V0.0.39","text":""},{"location":"releases/v0.0.39/#version-0039","title":"Version 0.0.39","text":"<p>This new version introduces automatic push to origin after commit and adds pytest-mock to the pr-tests workflow.</p>"},{"location":"releases/v0.0.39/#new-features","title":"New Features","text":"<ul> <li>Automatic push to origin after commit has been added. This feature simplifies the workflow and ensures that changes are synced with the remote repository. (7a0151) (Eric Ma)</li> <li>Pytest-mock has been added to the pr-tests workflow. This enables mocking in test cases. (ab1cb0) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.39/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>No bug fixes in this release.</li> </ul>"},{"location":"releases/v0.0.39/#deprecations","title":"Deprecations","text":"<ul> <li>No deprecations in this release.</li> </ul>"},{"location":"releases/v0.0.4/","title":"V0.0.4","text":""},{"location":"releases/v0.0.4/#version-004","title":"Version 0.0.4","text":"<p>This new version includes several updates to the documentation and build process, as well as the addition of an all-contributors section. The version also includes a fix to the build command.</p>"},{"location":"releases/v0.0.4/#new-features","title":"New Features","text":"<ul> <li>Added an all-contributors section to the documentation (9a65f2) (Eric Ma)</li> <li>Added an all-contributors badge to the project (71be05) (Eric Ma)</li> <li>Added all-contributors configuration to the project (7ae0d2) (Eric Ma)</li> <li>Updated the all-contributors specification to correct the project name and owner (3e841c) (Eric Ma)</li> <li>Switched to using docs/index.md for all-contributors (0aa0fe) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.4/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Fixed the build command for the project (6e8e65) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.4/#deprecations","title":"Deprecations","text":"<ul> <li>Temporarily removed the badge from the project (4bef48) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.4/#other-changes","title":"Other Changes","text":"<ul> <li>Removed unnecessary whitespace from the project (943ba4) (Eric Ma)</li> <li>Reformatted the allcontributors.rc file (8ae972) (Eric Ma)</li> <li>Updated the badge for the project (6c0850) (Eric Ma)</li> <li>Updated the table in the documentation (047481) (Eric Ma)</li> <li>Bumped the project version from 0.0.3 to 0.0.4 (943e5a) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.40/","title":"V0.0.40","text":""},{"location":"releases/v0.0.40/#0040","title":"0.0.40","text":"<p>This new version introduces the addition of a new dependency to the project, enhancing its functionality.</p>"},{"location":"releases/v0.0.40/#new-features","title":"New Features","text":"<ul> <li>Added the frozenlist package to the dependencies list in pyproject.toml to support immutable lists in the project (a7d069) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.40/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>None in this release.</li> </ul>"},{"location":"releases/v0.0.40/#deprecations","title":"Deprecations","text":"<ul> <li>None in this release.</li> </ul>"},{"location":"releases/v0.0.41/","title":"V0.0.41","text":""},{"location":"releases/v0.0.41/#0041","title":"0.0.41","text":"<p>This new version introduces a handy <code>version</code> command to the llamabot CLI and updates the bumpversion configuration.</p>"},{"location":"releases/v0.0.41/#new-features","title":"New Features","text":"<ul> <li>A new <code>version</code> command has been added to the llamabot CLI. This command prints the current version of the application. (a88028) (Eric Ma)</li> <li>The <code>.bumpversion.cfg</code> file has been updated to include <code>llamabot/version.py</code> for version updates. This ensures that the version number is updated consistently across the application. (a88028) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.41/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>No bug fixes in this release.</li> </ul>"},{"location":"releases/v0.0.41/#deprecations","title":"Deprecations","text":"<ul> <li>No deprecations in this release.</li> </ul>"},{"location":"releases/v0.0.42/","title":"V0.0.42","text":""},{"location":"releases/v0.0.42/#version-0042","title":"Version 0.0.42","text":"<p>This new version introduces an enhancement to the get_valid_input function and a new feature that allows users to manually edit the generated commit message using their system's default text editor.</p>"},{"location":"releases/v0.0.42/#new-features","title":"New Features","text":"<ul> <li>Manual commit message editing option has been added. Users can now manually edit the generated commit message using their system's default text editor. This is done by creating a temporary file with the generated message, opening it in the editor, and reading the edited message back into the script. The 'm' option is added to the user input prompt to trigger manual editing. (37baea) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.42/#enhancements","title":"Enhancements","text":"<ul> <li>The get_valid_input function in cli/utils has been refactored for better input validation. A valid_inputs parameter has been added to the function, the input prompt has been updated to include valid_inputs, and the input validation now checks against valid_inputs. The error message has also been updated to display valid_inputs options. (b32986) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.42/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>None in this release.</li> </ul>"},{"location":"releases/v0.0.42/#deprecations","title":"Deprecations","text":"<ul> <li>None in this release.</li> </ul>"},{"location":"releases/v0.0.43/","title":"V0.0.43","text":""},{"location":"releases/v0.0.43/#version-0043","title":"Version 0.0.43","text":"<p>This new version includes several enhancements to the code workflow and code manipulation features, as well as an update to the default model_name in various bot classes.</p>"},{"location":"releases/v0.0.43/#new-features","title":"New Features","text":"<ul> <li>Added new code cells and autoreload in code_workflow.ipynb. This includes the addition of new empty code cells for future implementation, a placeholder in one of the cells, autoreload magic commands for a better development experience, and the importation and demonstration of the get_dependencies function usage (5f6880) (Eric Ma)</li> <li>Introduced the get_dependencies function to retrieve a list of dependencies for a specified object in a source file. Also fixed the return type annotation for the get_git_diff function and added a test case for the get_dependencies function in test_code_manipulation.py (2d816f) (Eric Ma)</li> <li>Updated the default model_name parameter value from \"gpt-4\" to \"gpt-4-32k\" in the constructors of ChatBot, QueryBot, and SimpleBot classes (c93ba3) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.43/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>No bug fixes in this release.</li> </ul>"},{"location":"releases/v0.0.43/#deprecations","title":"Deprecations","text":"<ul> <li>No deprecations in this release.</li> </ul>"},{"location":"releases/v0.0.43/#refactors","title":"Refactors","text":"<ul> <li>Reorganized imports and improved test generation. This includes moving the <code>get_valid_input</code> import to the top of <code>llamabot/cli/git.py</code>, adding the <code>get_dependencies</code> import to <code>llamabot/cli/python.py</code>, and updating the <code>tests</code> function in <code>llamabot/prompt_library/coding.py</code> to include dependent source files for better test generation (f75202) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.44/","title":"V0.0.44","text":""},{"location":"releases/v0.0.44/#0044","title":"0.0.44","text":"<p>This new version includes a variety of enhancements and new features, including the addition of new notebooks, improvements to the Zotero and QueryBot functionalities, and the integration of Google Calendar API.</p>"},{"location":"releases/v0.0.44/#new-features","title":"New Features","text":"<ul> <li>Added blogging assistant and gcal notebooks for blog tagger, summarizer, and Google Calendar related tasks. Also, updated existing notebooks for cache and Zotero with new features and improvements (2378760) (Eric Ma)</li> <li>Implemented updates to all attendees on event creation and update in Google Calendar (57f80de) (Eric Ma)</li> <li>Refactored Zotero library handling and improved chat_paper functionality (b160982) (Eric Ma)</li> <li>Improved index handling and document processing in QueryBot (ea47ec9) (Eric Ma)</li> <li>Refactored sync function in Zotero and added chat_paper command (237631e) (Eric Ma)</li> <li>Added sync command to sync Zotero items to local JSON file (b1ccf350) (Eric Ma)</li> <li>Created .llamabot directory and updated config path (6e1b457) (Eric Ma)</li> <li>Added zotero integration and refactored configure function in CLI (0add77a) (Eric Ma)</li> <li>Added rich library to dependencies for better terminal output and formatting (d4c21d1) (Eric Ma)</li> <li>Added environment variable configuration in cli/utils (3ba93ef) (Eric Ma)</li> <li>Added initial CLI configuration for Zotero integration (8a3deb2) (Eric Ma)</li> <li>Added progress display for commit and push operations (9d9c86e) (Eric Ma)</li> <li>Added capture_errors decorator in google/utility_functions (12a7a3c) (Eric Ma)</li> <li>Added Google Calendar API integration (5c6ba9f) (Eric Ma)</li> <li>Added hashing for scopes and credentials in token file name in Google API (24d774b) (Eric Ma)</li> <li>Added llamabot_config_dir variable in config (2622ef3) (Eric Ma)</li> <li>Added convenience wrappers for Google API (0ea502d) (Eric Ma)</li> <li>Added tutorial bot and prompts in prompt_library (fe0d717) (Eric Ma)</li> <li>Added tutorial module to CLI (436374b) (Eric Ma)</li> <li>Added file_finder module documentation (dff0c71) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.44/#refactor","title":"Refactor","text":"<ul> <li>Simplified chat_paper function and improved document loading in Zotero (7f3e2d0) (Eric Ma)</li> <li>Updated index with a new document and set default values for chunk_size and chunk_overlap in QueryBot (02e21f8) (Eric Ma)</li> <li>Restructured Google API wrapper (88464cc) (Eric Ma)</li> <li>Separated credential loading from calendar service creation in Google API (39c038d) (Eric Ma)</li> <li>Moved code block in tests function in prompt_library (a2e5453) (Eric Ma)</li> <li>Improved commit message handling and progress display in cli/git (55e6aa8) (Eric Ma)</li> <li>Renamed test_coding.py to test_coding_prompt_library.py in tests (260c989) (Eric Ma)</li> <li>Centralized llamabotrc_paths and updated imports in config (f3af30d) (Eric Ma)</li> <li>Removed unused tutorial_writer function in cli (407f687) (Eric Ma)</li> <li>Updated commit message guidelines in prompt_library/git (185649c) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.44/#docs","title":"Docs","text":"<ul> <li>Updated pip install command in python.md (84b079a) (Eric Ma)</li> <li>Added Llamabot Python CLI tutorial (d85d039) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.45/","title":"V0.0.45","text":""},{"location":"releases/v0.0.45/#0045","title":"0.0.45","text":"<p>This new version includes a refactor of the <code>get_git_diff</code> function in the <code>code_manipulation</code> module. The default value for the <code>repo_path</code> parameter has been changed to improve the function's usability.</p>"},{"location":"releases/v0.0.45/#new-features","title":"New Features","text":"<ul> <li>No new features were added in this version.</li> </ul>"},{"location":"releases/v0.0.45/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>No bug fixes were made in this version.</li> </ul>"},{"location":"releases/v0.0.45/#refactors","title":"Refactors","text":"<ul> <li>The default value of the <code>repo_path</code> parameter in the <code>get_git_diff</code> function has been changed from <code>here()</code> to <code>None</code>. Additionally, a conditional check has been added to set <code>repo_path</code> to <code>here()</code> if it is <code>None</code>. This change makes the function more flexible and easier to use. (96e69b) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.45/#deprecations","title":"Deprecations","text":"<ul> <li>No deprecations were made in this version.</li> </ul>"},{"location":"releases/v0.0.46/","title":"V0.0.46","text":""},{"location":"releases/v0.0.46/#0046","title":"0.0.46","text":"<p>This new version includes a significant refactor of the tutorialbot, improving its flexibility and maintainability.</p>"},{"location":"releases/v0.0.46/#new-features","title":"New Features","text":"<ul> <li>The tutorialbot has been refactored from a SimpleBot instance to a function that returns a SimpleBot instance. This change enhances the flexibility of the bot, allowing for more diverse use cases. (d85426) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.46/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>No bug fixes in this release.</li> </ul>"},{"location":"releases/v0.0.46/#deprecations","title":"Deprecations","text":"<ul> <li>No deprecations in this release.</li> </ul>"},{"location":"releases/v0.0.47/","title":"V0.0.47","text":""},{"location":"releases/v0.0.47/#0047","title":"0.0.47","text":"<p>This new version includes an additional dependency to enhance the functionality of the software.</p>"},{"location":"releases/v0.0.47/#new-features","title":"New Features","text":"<ul> <li>Added pyzotero as a new dependency to the project (d2214e) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.47/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>None in this release</li> </ul>"},{"location":"releases/v0.0.47/#deprecations","title":"Deprecations","text":"<ul> <li>None in this release</li> </ul>"},{"location":"releases/v0.0.48/","title":"V0.0.48","text":""},{"location":"releases/v0.0.48/#version-0048","title":"Version 0.0.48","text":"<p>This new version introduces improvements to the progress reporting in the chat_paper function of the Zotero feature.</p>"},{"location":"releases/v0.0.48/#new-features","title":"New Features","text":"<ul> <li>Improved progress reporting in the chat_paper function of the Zotero feature. The changes include moving the retrieverbot response and paper_key retrieval outside of the progress context, adding progress tasks for embedding Zotero library, downloading paper, and initializing docbot, and wrapping relevant sections of code with progress context (da0fc0) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.48/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>No bug fixes in this release.</li> </ul>"},{"location":"releases/v0.0.48/#deprecations","title":"Deprecations","text":"<ul> <li>No deprecations in this release.</li> </ul>"},{"location":"releases/v0.0.49/","title":"V0.0.49","text":""},{"location":"releases/v0.0.49/#0049","title":"0.0.49","text":"<p>This new version introduces a tutorial for the Zotero CLI feature of Llamabot and refactors the tutorial generation process for improved code readability and maintainability.</p>"},{"location":"releases/v0.0.49/#new-features","title":"New Features","text":"<ul> <li>A comprehensive tutorial for using the Llamabot Zotero CLI has been added. This tutorial includes sections on prerequisites, configuration, syncing Zotero items, and chatting with a paper, with examples and explanations provided for each step. (711011) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.49/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>No bug fixes in this release.</li> </ul>"},{"location":"releases/v0.0.49/#deprecations","title":"Deprecations","text":"<ul> <li>No deprecations in this release.</li> </ul>"},{"location":"releases/v0.0.49/#refactors","title":"Refactors","text":"<ul> <li>The tutorial generation process has been updated. Now, the tutorialbot is instantiated before calling the module_tutorial_writer, which improves code readability and maintainability. (99f487) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.5/","title":"V0.0.5","text":""},{"location":"releases/v0.0.5/#005","title":"0.0.5","text":"<p>This new version introduces the QueryBot prototype and its corresponding tests. It also includes improvements in documentation and example notebooks. The version also includes some housekeeping changes like ignoring certain files and directories.</p>"},{"location":"releases/v0.0.5/#new-features","title":"New Features","text":"<ul> <li>QueryBot prototype added to the project. This is a new feature that allows users to interact with the bot using queries. (c190e03) (Eric Ma)</li> <li>Tests for QueryBot have been added to ensure its proper functioning. (78a791d) (Eric Ma)</li> <li>A new example on how to build a simple panel app has been added. This will help users understand how to create their own apps. (7e928b7) (Eric Ma)</li> <li>A notebook chatbot example has been added to provide a practical example of how to use the chatbot in a notebook environment. (7e96304) (Eric Ma)</li> <li>A simplebot notebook has been added to the project. This notebook provides a simple example of a bot. (0121db5) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.5/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>The chat notebook example is now properly executed. This fix ensures that the example runs as expected. (60803dd) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.5/#deprecations","title":"Deprecations","text":"<ul> <li>Notebook execution has been disabled. This change is made to prevent automatic execution of notebooks. (89c39c1) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.5/#other-changes","title":"Other Changes","text":"<ul> <li>The project version has been bumped from 0.0.4 to 0.0.5. (e94a28) (Eric Ma)</li> <li>Docstrings have been added to the project for better code understanding and readability. (2eb8c62) (Eric Ma)</li> <li>The directory 'data/' is now ignored by Git. This prevents unnecessary tracking of changes in this directory. (4252cd4) (Eric Ma)</li> <li>The 'mknotebooks' has been moved to the pip section. (e5f0e9d) (Eric Ma)</li> <li>Temporary markdown files created by 'mknotebooks' are now ignored by Git. This prevents unnecessary tracking of these temporary files. (1e4821d) (Eric Ma)</li> <li>The README file has been updated twice to provide the latest information about the project. (b3e02e2, 32f32db) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.50/","title":"V0.0.50","text":""},{"location":"releases/v0.0.50/#0050","title":"0.0.50","text":"<p>This new version introduces enhanced functionality to the chat_paper function and the get_key prompt in zotero.py, adds a streaming option to the QueryBot class in querybot.py, and removes a debugging print statement in doc_processor.py.</p>"},{"location":"releases/v0.0.50/#new-features","title":"New Features","text":"<ul> <li>The chat_paper function in zotero.py now supports multiple paper keys, provides a list of paper titles for the user to choose from, and displays a summary of the selected paper (1c47a8) (Eric Ma)</li> <li>The get_key prompt in zotero.py has been updated to return a list of keys instead of a single key, improving the user experience (1c47a8) (Eric Ma)</li> <li>A new 'stream' parameter has been added to the QueryBot class in querybot.py, allowing users to choose whether to stream the chatbot or not. By default, 'stream' is set to True (01ada0) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.50/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>A print statement used for debugging purposes has been removed from the doc_processor.py file (796ac2) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.50/#deprecations","title":"Deprecations","text":"<ul> <li>No deprecations in this release.</li> </ul>"},{"location":"releases/v0.0.51/","title":"V0.0.51","text":""},{"location":"releases/v0.0.51/#0051","title":"0.0.51","text":"<p>This new version introduces several enhancements to the Zotero integration in the llamabot project, improving performance, user interaction, and error handling. It also includes important bug fixes and documentation updates.</p>"},{"location":"releases/v0.0.51/#new-features","title":"New Features","text":"<ul> <li>Added a sync option to the ZoteroLibrary class, improving performance by reducing unnecessary queries to Zotero when the library can be loaded from a local file (a3ea1b) (Eric Ma)</li> <li>Integrated the standalone sync command from zotero.py into the chat command and refactored ZoteroLibrary and ZoteroItem classes to handle synchronization and downloading of Zotero items (a75308) (Eric Ma)</li> <li>Updated the guidelines for writing commit messages in the <code>git.py</code> file (a98ba93) (Eric Ma)</li> <li>Added support for accessing nested keys in the ZoteroItem class (216abc) (Eric Ma)</li> <li>Improved task progress visibility and command help in the Zotero integration (895079) (Eric Ma)</li> <li>Enhanced the chat function in zotero.py with an interactive prompt and an exit command (bf043b) (Eric Ma)</li> <li>Updated file handling in ZoteroItem class, including a fallback to write an abstract.txt file when no PDF is available (8b9fa4) (Eric Ma)</li> <li>Simplified progress task handling and improved output formatting in the Zotero integration (26dc67) (Eric Ma)</li> <li>Improved user interaction and error handling in Zotero integration, including persistent progress display, better progress tracking, real-time streaming, and continuous interaction (347a08) (Eric Ma)</li> <li>Ensured that the get_key function in zotero.py strictly returns JSON format (34b82d) (Eric Ma)</li> <li>Enhanced Zotero library and item classes, including faster lookup, better PDF handling, and improved functionality and usability (a813c5) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.51/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Corrected file writing in ZoteroItem class, ensuring that the abstractNote data is correctly written to the file (42e6a5) (Eric Ma)</li> <li>Fixed a typo in the file open method in the ZoteroItem class that was causing a runtime error (0a20e9) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.51/#deprecations","title":"Deprecations","text":"<ul> <li>No deprecations in this release.</li> </ul>"},{"location":"releases/v0.0.52/","title":"V0.0.52","text":""},{"location":"releases/v0.0.52/#0052","title":"0.0.52","text":"<p>This new version includes an important bug fix and updates to the tutorial content for the Llamabot Zotero CLI.</p>"},{"location":"releases/v0.0.52/#new-features","title":"New Features","text":"<ul> <li>The tutorial content for the Llamabot Zotero CLI has been updated to provide a more accurate and user-friendly guide. Changes include rewording the introduction, updating the prerequisites section, removing the section on syncing Zotero items, and adding sections on various topics such as chatting with a paper, retrieving keys, downloading papers, and asking questions (fab7d3) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.52/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>The field declaration for 'zot' in ZoteroLibrary class has been changed to use default_factory instead of default. This ensures that the load_zotero function is called when a new instance of ZoteroLibrary is created, rather than at import time (c65618) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.52/#deprecations","title":"Deprecations","text":"<ul> <li>No deprecations in this release.</li> </ul>"},{"location":"releases/v0.0.53/","title":"V0.0.53","text":""},{"location":"releases/v0.0.53/#version-0053","title":"Version 0.0.53","text":"<p>This new version introduces significant improvements to the chat recording and saving mechanism of the Llamabot. It also includes a minor refactor in the Zotero module.</p>"},{"location":"releases/v0.0.53/#new-features","title":"New Features","text":"<ul> <li>Added chat recording and saving functionality. This feature includes the addition of <code>case-converter</code> to the project dependencies, the importation of <code>date</code> and <code>snakecase</code> from <code>datetime</code> and <code>caseconverter</code> respectively, the addition of <code>PromptRecorder</code> to record the chat, modification of the <code>chat</code> function to record and save the chat with a filename in snakecase format prefixed with the current date, and the addition of a <code>save</code> method in <code>PromptRecorder</code> to save the recorded chat to a specified path (22738e) (Eric Ma)</li> <li>Improved the chat recording and saving mechanism. The creation of the save path was moved to the beginning of the chat function, the save path now includes the date and the snakecased user choice, the save path is printed to the console when the user exits the chat, the save function now coerces the path argument to a pathlib.Path object for compatibility, and the save function is now called with the save path instead of a string for flexibility and ease of use (c44562) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.53/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>No bug fixes in this release.</li> </ul>"},{"location":"releases/v0.0.53/#deprecations","title":"Deprecations","text":"<ul> <li>Removed the temperature parameter from the QueryBot instantiation in the chat function of the Zotero module. This simplifies the QueryBot configuration and does not affect the functionality of the bot (663594) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.54/","title":"V0.0.54","text":""},{"location":"releases/v0.0.54/#0054","title":"0.0.54","text":"<p>This new version includes code refactoring for improved efficiency and cleaner console output.</p>"},{"location":"releases/v0.0.54/#new-features","title":"New Features","text":"<ul> <li>None in this release</li> </ul>"},{"location":"releases/v0.0.54/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>None in this release</li> </ul>"},{"location":"releases/v0.0.54/#refactoring","title":"Refactoring","text":"<ul> <li>Removed unnecessary progress task related to summarizing the paper in <code>zotero.py</code> (62c35b) (Eric Ma)</li> <li>Removed print statement indicating the completion of recording in <code>recorder.py</code> for cleaner console output (62c35b) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.54/#deprecations","title":"Deprecations","text":"<ul> <li>None in this release</li> </ul>"},{"location":"releases/v0.0.55/","title":"V0.0.55","text":""},{"location":"releases/v0.0.55/#0055","title":"0.0.55","text":"<p>This new version introduces a chat command to LlamaBot CLI, adds a logging option to the ChatBot class, and updates the documentation with new usage examples and a CLI demos section.</p>"},{"location":"releases/v0.0.55/#new-features","title":"New Features","text":"<ul> <li>Added a chat command to LlamaBot CLI. This new command allows users to interact with the ChatBot and includes an option to save the chat to a markdown file. The filename for the saved chat is generated based on the current date and time. The chat command will exit if the user types \"exit\" or \"quit\". (baa4d64) (Eric Ma)</li> <li>Added a logging option to the ChatBot class. This new parameter is a boolean that determines whether to log the chat history and token budget. This feature provides more flexibility for users who want to monitor the chat history and token budget during the bot operation. (6550cf3) (Eric Ma)</li> <li>Updated the documentation's index file with new usage examples. These include a new example of exposing a chatbot directly at the command line using <code>llamabot chat</code>, an updated description and command for using <code>llamabot</code> as part of the backend of a CLI app to chat with Zotero library, and a new example of using <code>llamabot</code>'s <code>SimpleBot</code> to create a bot that automatically writes commit messages. (274a779) (Eric Ma)</li> <li>Introduced a new section in the documentation, specifically in the index.md file. The section is titled \"CLI Demos\" and provides examples of what can be built with Llamabot and some supporting code. It also includes an embedded asciicast for a more interactive demonstration. (ce7e734) (Eric Ma)</li> <li>Added an asciicast script to the documentation index file. This will provide users with a visual guide or tutorial. (e332f0a) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.55/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>None in this release.</li> </ul>"},{"location":"releases/v0.0.55/#deprecations","title":"Deprecations","text":"<ul> <li>None in this release.</li> </ul>"},{"location":"releases/v0.0.56/","title":"V0.0.56","text":""},{"location":"releases/v0.0.56/#0056","title":"0.0.56","text":"<p>This new version brings a number of improvements to the user interface, streamlines the handling of user prompts and Zotero library, and introduces new features such as a document chat bot functionality. It also includes several bug fixes and refactoring of the code for better performance and readability.</p>"},{"location":"releases/v0.0.56/#new-features","title":"New Features","text":"<ul> <li>Document chat bot functionality has been added. This feature allows users to chat with a document by providing a path to the document (005a10) (Eric Ma)</li> <li>The 'textual' package has been added to the dependencies, enhancing the functionality of the codebase (9b53aa) (Eric Ma)</li> <li>A new Jupyter notebook, patreon_ghostwriter.ipynb, has been introduced in the scratch_notebooks directory. The notebook includes code for a bot that can generate Patreon posts based on provided talking points (849497) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.56/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Fixed a bug in <code>ZoteroLibrary</code> where items were not being loaded from JSONL file (7e9ea4) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.56/#refactors","title":"Refactors","text":"<ul> <li>User prompts have been streamlined for consistency across modules, and Zotero library handling has been improved (7e9ea4) (Eric Ma)</li> <li>CLI prompts and exit handling have been streamlined (3c4cc3) (Eric Ma)</li> <li>Instructions for writing commit messages in git.py have been improved for clarity and user-friendliness (942005) (Eric Ma)</li> <li>A function has been renamed to <code>ensure_work_email_on_calendly_events</code> to make it more generic (841c78) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.56/#environment-and-dependencies","title":"Environment and Dependencies","text":"<ul> <li>Python version has been updated from 3.9 to 3.11, and pre-commit has been removed from dependencies (8f880f) (Eric Ma)</li> <li>Python version has been downgraded from 3.11 to 3.9 to ensure compatibility with existing libraries, and version constraint on bokeh has been removed to use the latest version (0e8bff) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.57/","title":"V0.0.57","text":""},{"location":"releases/v0.0.57/#0057","title":"0.0.57","text":"<p>This new version introduces several enhancements to the QueryBot class, adds a language inference function to the <code>embed_repo.ipynb</code> notebook, and provides a command line interface for interacting with a code repository. It also includes progress bars for file hashing and document splitting processes, an option to ignore directories when displaying the directory tree, and support for multiple documents for indexing. Lastly, a comprehensive tutorial on how to install, configure, and use LlamaBot is added.</p>"},{"location":"releases/v0.0.57/#new-features","title":"New Features","text":"<ul> <li>Added caching option and improved document handling in QueryBot. This includes changes to the <code>make_or_load_index</code> function, <code>exit_if_asked</code> function, <code>ZOTERO_JSON_DIR</code>, <code>ZoteroLibrary</code> class, and <code>magic_load_doc</code> function. Also, updates were made to the <code>zotero.ipynb</code> notebook to reflect these changes (579f162) (Eric Ma)</li> <li>Added language inference function and updated execution counts in <code>embed_repo.ipynb</code> notebook. This enhances the functionality of the notebook by allowing it to infer the programming languages used in a repository and providing a more detailed view of the repository's structure (b795e72) (Eric Ma)</li> <li>Added CLI for interacting with code repository. This is part of ongoing efforts to improve the usability of the LlamaBot project (042ae26) (Eric Ma)</li> <li>Added progress bars to file hashing and document splitting in the QueryBot module. This provides a visual indication of progress when processing large numbers of documents, improving user experience (4634185) (Eric Ma)</li> <li>Added directory ignore option to <code>show_directory_tree</code>. This allows specifying a list of directory names to ignore when displaying the directory tree (271ccde) (Eric Ma)</li> <li>Added support for multiple documents for indexing in QueryBot. This includes changes to the <code>doc_paths</code> parameter and the <code>make_or_load_index</code> function (c813522) (Eric Ma)</li> <li>Added LlamaBot tutorial documentation. This provides a comprehensive tutorial on how to install, configure, and use LlamaBot (9e25fb5) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.57/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>No bug fixes in this release.</li> </ul>"},{"location":"releases/v0.0.57/#deprecations","title":"Deprecations","text":"<ul> <li>The change in how Zotero library data is stored and handled may break existing code that relies on the old JSONL format (579f162) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.58/","title":"V0.0.58","text":""},{"location":"releases/v0.0.58/#version-0058","title":"Version 0.0.58","text":"<p>This new version includes an important bug fix that improves the compatibility of the ZoteroLibrary with other components. The output format of the ZoteroLibrary has been changed from JSONL to JSON.</p>"},{"location":"releases/v0.0.58/#new-features","title":"New Features","text":"<ul> <li>None in this release</li> </ul>"},{"location":"releases/v0.0.58/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Changed the output format of the ZoteroLibrary from JSONL to JSON for better compatibility with other components (9b7757) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.58/#deprecations","title":"Deprecations","text":"<ul> <li>None in this release</li> </ul>"},{"location":"releases/v0.0.59/","title":"V0.0.59","text":""},{"location":"releases/v0.0.59/#0059","title":"0.0.59","text":"<p>This new version includes a critical bug fix related to the creation of the ZOTERO_JSON_DIR directory.</p>"},{"location":"releases/v0.0.59/#new-features","title":"New Features","text":"<p>No new features were added in this version.</p>"},{"location":"releases/v0.0.59/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Fixed the method of directory creation for ZOTERO_JSON_DIR to ensure correct creation (a6a0c7) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.59/#deprecations","title":"Deprecations","text":"<p>No deprecations were made in this version.</p>"},{"location":"releases/v0.0.6/","title":"V0.0.6","text":""},{"location":"releases/v0.0.6/#006","title":"0.0.6","text":"<p>This new version includes an example notebook for QueryBot and a version bump.</p>"},{"location":"releases/v0.0.6/#new-features","title":"New Features","text":"<ul> <li>Added an example notebook for QueryBot (fa7182) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.6/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>No bug fixes in this release.</li> </ul>"},{"location":"releases/v0.0.6/#deprecations","title":"Deprecations","text":"<ul> <li>No deprecations in this release.</li> </ul>"},{"location":"releases/v0.0.60/","title":"V0.0.60","text":""},{"location":"releases/v0.0.60/#version-0060","title":"Version 0.0.60","text":"<p>This new version introduces a significant refactor of the retriever initialization and cache handling in the Llamabot application. It also includes minor changes in the Zotero chat function and the zotero notebook.</p>"},{"location":"releases/v0.0.60/#new-features","title":"New Features","text":"<ul> <li>Refactored the retriever initialization and cache handling in the Llamabot application. This includes the removal of direct import and usage of VectorIndexRetriever in querybot.py, the addition of a method to get the retriever from the index, and the definition of CACHE_DIR as a constant in querybot.py and init.py. The get_persist_dir has been refactored to use the CACHE_DIR constant, and a clear_cache command has been added in init.py to clear the Llamabot cache. The default value of the sync option in the zotero.py chat function has been changed, and the doc_paths argument in the retrieverbot initialization in zotero.py has been updated. Directory creation in zotero.ipynb has been commented out, and code has been added to list json files in the ZOTERO_JSON_DIR in zotero.ipynb. (49645b) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.60/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>No bug fixes in this release.</li> </ul>"},{"location":"releases/v0.0.60/#deprecations","title":"Deprecations","text":"<ul> <li>No deprecations in this release.</li> </ul>"},{"location":"releases/v0.0.61/","title":"V0.0.61","text":""},{"location":"releases/v0.0.61/#version-0061","title":"Version 0.0.61","text":"<p>This new version introduces caching to improve performance and enhances the paper selection process for a more interactive experience.</p>"},{"location":"releases/v0.0.61/#new-features","title":"New Features","text":"<ul> <li>Enabled use of cache in the chat function to improve performance (013dae) (Eric Ma)</li> <li>Enhanced the paper selection process to handle single paper scenario and provide a more interactive selection process for multiple papers (013dae) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.61/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>None in this release</li> </ul>"},{"location":"releases/v0.0.61/#deprecations","title":"Deprecations","text":"<ul> <li>None in this release</li> </ul>"},{"location":"releases/v0.0.62/","title":"V0.0.62","text":""},{"location":"releases/v0.0.62/#version-0062","title":"Version 0.0.62","text":"<p>This new version includes a significant refactor of the querybot's faux chat history construction for improved clarity and functionality.</p>"},{"location":"releases/v0.0.62/#new-features","title":"New Features","text":"<ul> <li>The faux chat history construction in querybot has been updated for better clarity and functionality. The VectorIndexRetriever has been replaced with the index.as_retriever method, a system message has been added to the faux chat history, the last four responses from the chat history are now included in the faux chat history, and the order of faux chat history construction has been adjusted for better clarity (47a35d) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.62/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>No bug fixes in this release.</li> </ul>"},{"location":"releases/v0.0.62/#deprecations","title":"Deprecations","text":"<ul> <li>No deprecations in this release.</li> </ul>"},{"location":"releases/v0.0.63/","title":"V0.0.63","text":""},{"location":"releases/v0.0.63/#version-0063","title":"Version 0.0.63","text":"<p>This new version introduces a blog assistant functionality to llamabot and specifies a minimum Python version in the pyproject.toml file.</p>"},{"location":"releases/v0.0.63/#new-features","title":"New Features","text":"<ul> <li>Blog assistant functionality has been added to llamabot. This new feature can summarize and tag a blog post. It includes the addition of a new 'blog' module, a new 'blog' command to the CLI, and the creation of several new files in the CLI and prompt_library directories. This enhancement provides users with a tool to automatically summarize and tag their blog posts. (265962) (Eric Ma)</li> <li>The pyproject.toml file now requires a minimum Python version of 3.10. This change ensures compatibility with the latest features and security updates. (a664df) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.63/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>No bug fixes in this release.</li> </ul>"},{"location":"releases/v0.0.63/#deprecations","title":"Deprecations","text":"<ul> <li>No deprecations in this release.</li> </ul>"},{"location":"releases/v0.0.64/","title":"V0.0.64","text":""},{"location":"releases/v0.0.64/#0064","title":"0.0.64","text":"<p>This new version focuses on improving the configuration process of LlamaBot. It introduces a new feature that fetches the default language model from the configuration file. The LlamaBot tutorial has been updated to provide detailed instructions on how to set up the OpenAI API key and select the default model. Additionally, the configuration command has been moved to a separate module for better code organization.</p>"},{"location":"releases/v0.0.64/#new-features","title":"New Features","text":"<ul> <li>The LlamaBot tutorial now focuses on the configuration process, providing detailed instructions on how to set up the OpenAI API key and select the default model. The sections on installation, version checking, and chatting with LlamaBot have been removed. (87dfef) (Eric Ma)</li> <li>Introduced a new feature where the default language model is now fetched from the configuration file. This change affects the ChatBot, QueryBot, and SimpleBot classes where the model_name parameter in their constructors now defaults to the value returned by the default_language_model function from the config module. (d531cb) (Eric Ma)</li> <li>The configuration command has been moved from the main init.py file to a new configure.py module. This change improves the organization of the code and makes it easier to maintain. A new command for setting the default model has been added to the configure module. (2bffdaf) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.64/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>None in this release.</li> </ul>"},{"location":"releases/v0.0.64/#deprecations","title":"Deprecations","text":"<ul> <li>None in this release.</li> </ul>"},{"location":"releases/v0.0.65/","title":"V0.0.65","text":""},{"location":"releases/v0.0.65/#0065","title":"0.0.65","text":"<p>This new version introduces several enhancements to the blog assistant CLI and blogging prompts, adds token budgeting for different models in the chatbot, and updates blogging and Patreon notebooks. A new notebook for semantic line breaks has also been added.</p>"},{"location":"releases/v0.0.65/#new-features","title":"New Features","text":"<ul> <li>Blogging and Patreon notebooks have been updated with new code cells and existing ones have been improved. A new notebook, sembr.ipynb, has been added with code for semantic line breaks. These changes improve the functionality and expand the capabilities of the notebooks (a34a02) (Eric Ma)</li> <li>Token budgeting for different models has been added to the chatbot. This feature allows for more flexible token budgeting depending on the model used (cc7ab8) (Eric Ma)</li> <li>Several enhancements have been made to the blog assistant CLI and blogging prompts. The <code>summarize_and_tag</code> function has been renamed to <code>summarize</code> and now also returns the blog title. A new <code>social_media</code> function has been added to generate social media posts for LinkedIn, Patreon, and Twitter. The <code>blog_tagger_and_summarizer</code> prompt has been renamed to <code>blog_title_tags_summary</code> and now also returns the blog title. New prompts <code>compose_linkedin_post</code>, <code>compose_patreon_post</code>, and <code>compose_twitter_post</code> have been added to generate social media posts. A new <code>BlogInformation</code> model has been added to represent blog information (453e5d) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.65/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>No bug fixes in this release.</li> </ul>"},{"location":"releases/v0.0.65/#deprecations","title":"Deprecations","text":"<ul> <li>No deprecations in this release.</li> </ul>"},{"location":"releases/v0.0.66/","title":"V0.0.66","text":""},{"location":"releases/v0.0.66/#version-0066","title":"Version 0.0.66","text":"<p>This new version introduces the Semantic Line Breaks (SEMBR) functionality to the blog summary and a new command. It enhances the readability and maintainability of the blog posts by applying a consistent line break strategy.</p>"},{"location":"releases/v0.0.66/#new-features","title":"New Features","text":"<ul> <li>Added SEMBR functionality to blog summary in the <code>summarize</code> function (faa08e) (Eric Ma)</li> <li>Introduced a new command <code>sembr</code> that allows users to apply SEMBR to their blog posts (faa08e) (Eric Ma)</li> <li>Implemented SEMBR functionality using a new <code>sembr_bot</code> in the <code>prompt_library</code> (faa08e) (Eric Ma)</li> <li>Created a new file <code>prompt_library/sembr.py</code> to handle the SEMBR prompts and bot creation (faa08e) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.66/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>None in this release</li> </ul>"},{"location":"releases/v0.0.66/#deprecations","title":"Deprecations","text":"<ul> <li>None in this release</li> </ul>"},{"location":"releases/v0.0.67/","title":"V0.0.67","text":""},{"location":"releases/v0.0.67/#0067","title":"0.0.67","text":"<p>This new version introduces enhancements to the social media post generation, updates to the testing matrix for Python versions, and a new GitHub workflow for daily testing of PyPI packages.</p>"},{"location":"releases/v0.0.67/#new-features","title":"New Features","text":"<ul> <li>Enhanced social media post generation. The update refactors the social media content generation to handle different platforms more effectively, adds JSON schema to standardize the return format, improves the handling of Patreon posts, and copies the post text to the clipboard for platforms other than Patreon. (07f90e) (Eric Ma)</li> <li>Introduced a new GitHub workflow for daily testing of PyPI packages. The workflow runs on the main branch and uses a matrix strategy to test on Python versions 3.9, 3.10, and 3.11. (fce17c) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.67/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Updated the python versions used in the test-pypi-package workflow. The versions have been updated from 3.10 to 3.10.12 and from 3.11 to 3.11.4. This ensures that the package is tested against the latest patch versions of Python. (e9ec8d) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.67/#deprecations","title":"Deprecations","text":"<ul> <li>Removed Python version 3.12 from the testing matrix in the GitHub Actions workflow for testing the PyPI package. This change is made to focus on the more stable and widely used versions of Python. (b90b8c) (Eric Ma)</li> <li>Updated the python versions used in the testing matrix of the test-pypi-package workflow. The version 3.9 has been removed and version 3.12 has been added. This ensures our package remains compatible with the latest python versions. (70e4dc) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.68/","title":"V0.0.68","text":""},{"location":"releases/v0.0.68/#0068","title":"0.0.68","text":"<p>This new version introduces several enhancements to the LLaMaBot project, including the addition of a 'prompts' section to the pyproject.toml file, improved error handling for missing packages, a new Jupyter notebook for LLaMaBot demo, and updates to the Google Calendar integration. The version also includes several code refactoring and documentation updates for better readability and maintainability.</p>"},{"location":"releases/v0.0.68/#new-features","title":"New Features","text":"<ul> <li>Added a 'prompts' section to the pyproject.toml file (82d9e8) (Eric Ma)</li> <li>Introduced error handling for the import of the <code>outlines</code> package in various modules of the llamabot prompt library (a569ca) (Eric Ma)</li> <li>Added a new Jupyter notebook demonstrating the usage of LLaMaBot (fdd17f) (Eric Ma)</li> <li>Updated Google Calendar integration with new features and improvements (170271) (Eric Ma)</li> <li>Added a tutorial for the Blog Assistant CLI in the documentation (620da7) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.68/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Pinned the version of mkdocs to 1.4.3 in the environment.yml file to ensure consistent documentation builds across different environments (ee7e7e) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.68/#deprecations","title":"Deprecations","text":"<ul> <li>Removed the outlines package from the project dependencies in pyproject.toml file (25bccb) (Eric Ma)</li> <li>Removed all the files related to Google API, which are superseded by the gcsa package (eb0c50) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.68/#other-improvements","title":"Other Improvements","text":"<ul> <li>Improved type annotations and code organization in the llamabot module (a1b391) (Eric Ma)</li> <li>Updated cron schedule in test-pypi-package workflow for better server load distribution (efd390) (Eric Ma)</li> <li>Added explanation for stateless function in the documentation (9a6b4e) (Eric Ma)</li> <li>Improved readability of the documentation by applying semantic line breaks and changing code block to text block (604277, 3583ba) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.69/","title":"V0.0.69","text":""},{"location":"releases/v0.0.69/#version-0069","title":"Version 0.0.69","text":"<p>This new version introduces extended installation options for the llamabot package and adds two new Jupyter notebooks to the project. The installation now includes all optional dependencies, ensuring full feature availability during testing. The new notebooks provide code for language model configuration and OpenAI API setup.</p>"},{"location":"releases/v0.0.69/#new-features","title":"New Features","text":"<ul> <li>Extended llamabot installation to include all optional dependencies, improving the thoroughness of the testing process and ensuring all package features are working as expected (e6e1e3) (Eric Ma)</li> <li>Added two new Jupyter notebooks: multiscale_embeddings.ipynb and outlines_backend_prototype.ipynb. The first notebook provides code for loading and configuring language models, creating and loading indices, retrieving and scoring nodes, and building queries. The second notebook provides code for setting up the OpenAI API and generating completions (044439) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.69/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>No bug fixes in this release.</li> </ul>"},{"location":"releases/v0.0.69/#deprecations","title":"Deprecations","text":"<ul> <li>No deprecations in this release.</li> </ul>"},{"location":"releases/v0.0.7/","title":"V0.0.7","text":""},{"location":"releases/v0.0.7/#version-007","title":"Version 0.0.7","text":"<p>This new version includes several enhancements and updates to improve the functionality and consistency of the LlamaBot.</p>"},{"location":"releases/v0.0.7/#new-features","title":"New Features","text":"<ul> <li>Added 'llama-index' to the list of dependencies to enhance the functionality of the bot (196cdc) (Eric Ma)</li> <li>Updated the <code>__call__</code> method of QueryBot for better performance and efficiency (b1840c) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.7/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Replaced a complex version with a simplified one to fix performance issues (f17655) (Eric Ma)</li> <li>Ensured the return of strings is consistent across all functions to fix inconsistency issues (88d62a) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.7/#deprecations","title":"Deprecations","text":"<ul> <li>Changed the default argument of <code>return_sources</code> to True. This might affect the behavior of functions that rely on the previous default value (a03db6) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.70/","title":"V0.0.70","text":""},{"location":"releases/v0.0.70/#version-0070","title":"Version 0.0.70","text":"<p>This new version introduces a more streamlined and reliable process for releasing Python packages, with several enhancements to the GitHub Actions workflows. It also includes a new feature for similarity search in the QueryBot class and some minor bug fixes.</p>"},{"location":"releases/v0.0.70/#new-features","title":"New Features","text":"<ul> <li>Added a project description and linked the README.md file to the project configuration (92002ba) (Eric Ma)</li> <li>Updated the pypi-publish action used in the GitHub Actions workflow for releasing the Python package to ensure stability and reliability of the release process (b8ecf9f) (Eric Ma)</li> <li>Separated the installation of the 'build' and 'wheel' packages in the GitHub Actions workflow for releasing a Python package to make the installation steps more explicit and easier to understand (005280e) (Eric Ma)</li> <li>Added the 'build' package to the python setup step in the GitHub Actions workflow for releasing a python package (62af643) (Eric Ma)</li> <li>Simplified the python package build process in the GitHub workflow to use the build module instead of setup.py (321e282) (Eric Ma)</li> <li>Set the default release type to 'patch' in the release-python-package workflow to prevent accidental major or minor releases (b339f88) (Eric Ma)</li> <li>Added a new step in the GitHub Actions workflow for releasing the Python package that configures the Git user name and email (f8f6ab4) (Eric Ma)</li> <li>Changed the GitHub workflow from running tests on different Python versions to publishing the Python package to PyPI (628b91f) (Eric Ma)</li> <li>Introduced a new GitHub workflow for releasing Python packages that includes steps for running tests, bumping version numbers, building and publishing the package, and creating a release in the GitHub repository (2f28ab7) (Eric Ma)</li> <li>Added a new method 'retrieve' in the QueryBot class for retrieving source nodes associated with a query using similarity search (a08d0f0) (Eric Ma)</li> <li>Added the ability to manually trigger the test-pypi-package workflow from the GitHub Actions UI (7611052) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.70/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Disabled the deadline for the ghostwriter test in the Python prompt library to prevent Hypothesis from failing the test due to it taking too long to run (b960ced) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.70/#deprecations","title":"Deprecations","text":"<ul> <li>No deprecations in this release.</li> </ul>"},{"location":"releases/v0.0.71/","title":"V0.0.71","text":""},{"location":"releases/v0.0.71/#version-0071","title":"Version 0.0.71","text":"<p>This new version includes several updates to the GitHub Actions workflow for releasing the Python package. The git configuration has been updated for better readability and specific use by the GitHub Actions user. The secret used for the user password in the release workflow has been changed for correct deployment. The git configuration now includes the credential helper and GitHub token for authentication when pushing changes. The versions of actions/checkout and actions/setup-python have been upgraded for better performance and security.</p>"},{"location":"releases/v0.0.71/#new-features","title":"New Features","text":"<ul> <li>Added credential helper and GitHub token to git configuration for authentication when pushing changes (5ed538) (Eric Ma)</li> <li>Upgraded actions/checkout from v2 to v3 and actions/setup-python from v2 to v3 for better performance and security (8af512) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.71/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Changed the secret used for the user password in the GitHub Actions release workflow for correct deployment (f96f6d) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.71/#chores","title":"Chores","text":"<ul> <li>Updated git configuration and push command in the GitHub Actions workflow for better readability (250e87) (Eric Ma)</li> </ul> <p>Please note that the publishing of the package was temporarily commented out in this version (ec6cb5) (Eric Ma).</p>"},{"location":"releases/v0.0.72/","title":"V0.0.72","text":""},{"location":"releases/v0.0.72/#version-0072","title":"Version 0.0.72","text":"<p>This new version includes several enhancements to the Zotero module, improvements to the QueryBot, and updates to the pre-commit hooks. It also introduces a new Jupyter notebook for outlines models and enables package publishing to PyPI.</p>"},{"location":"releases/v0.0.72/#new-features","title":"New Features","text":"<ul> <li>Added code to retrieve the title of a specific article from the Zotero library using the article's unique identifier (5921df) (Eric Ma)</li> <li>Added support for default similarity top ks in QueryBot based on the OPENAI_DEFAULT_MODEL environment variable (ae392f) (Eric Ma)</li> <li>Enhanced the ZoteroLibrary class by adding an <code>articles_only</code> filter and a <code>key_title_map</code> function (85a223) (Eric Ma)</li> <li>Improved the get_key function documentation in the Zotero module (89b6bc) (Eric Ma)</li> <li>Streamlined the paper selection process in the Zotero CLI by introducing a new PaperTitleCompleter for more efficient paper selection (1122e6) (Eric Ma)</li> <li>Improved handling of similarity_top_k in QueryBot and refactored index creation (acc6e8) (Eric Ma)</li> <li>Added 'sh' dependency to environment.yml and pyproject.toml files (5e23f9) (Eric Ma)</li> <li>Added execution of pre-commit hooks before committing changes (82979d) (Eric Ma)</li> <li>Added a new class, PaperTitleCompleter, to provide completion suggestions for paper titles in the Zotero module (3fac26) (Eric Ma)</li> <li>Updated pre-commit config and notebooks (b077aa) (Eric Ma)</li> <li>Extended the ruff pre-commit hook to also check python and jupyter files (4ae772) (Eric Ma)</li> <li>Added nltk as a transitive dependency via llama_index in the environment.yml file (2bd392) (Eric Ma)</li> <li>Introduced a new pre-commit hook, ruff, to the .pre-commit-config.yaml file (c7c5bc) (Eric Ma)</li> <li>Enabled package publishing to PyPI (baca5c) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.72/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Fixed assertion in test_magic_load_doc_txt function (ef4b3e) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.72/#refactors","title":"Refactors","text":"<ul> <li>Simplified the docstring in the doc_processor module and modified the document loading (fab218) (Eric Ma)</li> <li>Replaced 'index' with 'vector_index' in QueryBot class and refactored related methods (cfb284) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.72/#dependencies","title":"Dependencies","text":"<ul> <li>Bumped version: 0.0.71 \u2192 0.0.72 (d37eab) (github-actions)</li> <li>Added \"pre-commit\" to the list of dependencies in pyproject.toml (687645) (Eric Ma)</li> <li>Updated dependencies in environment.yml (7cb9a6) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.72/#other","title":"Other","text":"<ul> <li>Updated the version of the black pre-commit hook and removed the flake8 and isort pre-commit hooks (9fca51) (Eric Ma)</li> <li>Added a comment to clarify that GH Actions is allowed to write to the repository in the release-python-package workflow (bcf534) (Eric Ma)</li> <li>Introduced a new Jupyter notebook 'outlines_models.ipynb' in the 'scratch_notebooks' directory (746273) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.73/","title":"V0.0.73","text":""},{"location":"releases/v0.0.73/#version-0073","title":"Version 0.0.73","text":"<p>This new version includes an update to the commitbot feature, which now uses a more efficient model for generating commit messages.</p>"},{"location":"releases/v0.0.73/#new-features","title":"New Features","text":"<ul> <li>The commitbot has been updated to use the gpt-3.5-turbo-16k-0613 model. This model provides the same quality of commit messages as the previous model but at a fraction of the cost (ce91d6b) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.73/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>No bug fixes in this release.</li> </ul>"},{"location":"releases/v0.0.73/#deprecations","title":"Deprecations","text":"<ul> <li>No deprecations in this release.</li> </ul>"},{"location":"releases/v0.0.74/","title":"V0.0.74","text":""},{"location":"releases/v0.0.74/#version-0074","title":"Version 0.0.74","text":"<p>This new version includes an update to the pip installation in the test workflow and the addition of a new dependency, beartype==0.15.0.</p>"},{"location":"releases/v0.0.74/#new-features","title":"New Features","text":"<ul> <li>Added beartype==0.15.0 to the list of dependencies in pyproject.toml (8c4db1) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.74/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Updated pip installation in the test-pypi-package.yaml workflow to use the <code>python -m pip install</code> command instead of <code>pipx</code> to ensure the correct version of pip is used for installing the <code>llamabot[all]</code> package (2e860a) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.74/#deprecations","title":"Deprecations","text":"<ul> <li>None in this release.</li> </ul>"},{"location":"releases/v0.0.75/","title":"V0.0.75","text":""},{"location":"releases/v0.0.75/#version-0075","title":"Version 0.0.75","text":"<p>This new version includes several enhancements to the CLI module of LlamaBot. The improvements focus on automating the process of writing commit messages and ensuring consistency. The version also includes codebase improvements such as the removal of unnecessary comments.</p>"},{"location":"releases/v0.0.75/#new-features","title":"New Features","text":"<ul> <li>A new command <code>autowrite_commit_message</code> has been added to the <code>git.py</code> file in the <code>llamabot/cli</code> directory. This command automatically generates a commit message based on the diff and writes it to the <code>.git/COMMIT_EDITMSG</code> file. Error handling has also been included in case any exceptions occur during the process. (185613) (Eric Ma)</li> <li>A new command <code>install_commit_message_hook</code> has been added to the Git subcommand for LlamaBot CLI. This command installs a commit message hook that runs the commit message through the bot, automating the process of writing commit messages and ensuring consistency. (d1254e) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.75/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>No bug fixes in this release.</li> </ul>"},{"location":"releases/v0.0.75/#deprecations","title":"Deprecations","text":"<ul> <li>Unnecessary comments in <code>git.py</code> have been removed to improve the codebase. (ecf9c0) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.76/","title":"V0.0.76","text":""},{"location":"releases/v0.0.76/#version-0076","title":"Version 0.0.76","text":"<p>This new version includes several enhancements to the CLI module and the Llamabot model. It also includes a bug fix for the autowrite_commit_message function.</p>"},{"location":"releases/v0.0.76/#new-features","title":"New Features","text":"<ul> <li>Help messages for subcommands have been added to the CLI module. This will provide users with more information on how to use each command. (f4de87) (Eric Ma)</li> <li>The model_chat_token_budgets in Llamabot have been updated. New models have been added to the dictionary and token budgets for existing models have been updated. (52522b) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.76/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>The autowrite_commit_message function in the CLI module has been fixed. Print statements have been replaced with echo for consistent output and error messages are now written to stderr instead of stdout. (a66ead) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.76/#deprecations","title":"Deprecations","text":"<ul> <li>The unused 'apps' subcommand has been removed from the CLI module. This subcommand was not being used and has been safely removed. (0ea7b3) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.77/","title":"V0.0.77","text":""},{"location":"releases/v0.0.77/#version-0077","title":"Version 0.0.77","text":"<p>This new version introduces several enhancements to the release workflow, including the addition of release notes generation and the configuration of the OPENAI_API_KEY. It also includes improvements to the llamabot CLI and the documentation.</p>"},{"location":"releases/v0.0.77/#new-features","title":"New Features","text":"<ul> <li>Added fetch-depth parameter to the checkout action in the release-python-package workflow. This allows the action to fetch the entire history of the repository. (c25fe84) (Eric Ma)</li> <li>Upgraded the GitHub Actions checkout step to use version 4 and enabled the fetch-tags option. This ensures that all tags are fetched during the checkout process. (dadcf60) (Eric Ma)</li> <li>Added a new step in the release-python-package workflow to configure the OPENAI_API_KEY using llamabot. This is necessary for the successful generation of release notes. (6c17c10) (Eric Ma)</li> <li>Added OPENAI_API_KEY to environment variables in configure.py. This allows the application to access the OpenAI API key from the environment variables, improving security. (8df3cda) (Eric Ma)</li> <li>Updated the GitHub Actions workflow for releasing a new version of the Python package to include the release notes in the body of the GitHub release. (07150dc) (Eric Ma)</li> <li>Introduced a bot for converting git remote URL to HTTPS URL. This enhances the functionality of the release notes notebook. (85009ad) (Eric Ma)</li> <li>Added release notes generation to the GitHub workflow for releasing the Python package. (3d28e12) (Eric Ma)</li> <li>Introduced a new feature to the llamabot CLI, a command for generating release notes. This automates the process of generating release notes. (df181dd) (Eric Ma)</li> <li>Allowed setting default model by name in the <code>configure.py</code> file of the llamabot CLI. This provides more flexibility in setting the default model. (d223c43) (Eric Ma)</li> <li>Added a new Jupyter notebook 'release-notes.ipynb' in the 'scratch_notebooks' directory. The notebook contains code for generating release notes from git commit logs. (9ab58a5) (Eric Ma)</li> <li>Added the ability to specify the model name via an environment variable. This allows for more flexibility when deploying the bot in different environments. (127b6c9) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.77/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>No bug fixes in this release.</li> </ul>"},{"location":"releases/v0.0.77/#deprecations","title":"Deprecations","text":"<ul> <li>No deprecations in this release.</li> </ul>"},{"location":"releases/v0.0.78/","title":"V0.0.78","text":""},{"location":"releases/v0.0.78/#version-0078","title":"Version 0.0.78","text":"<p>This new version includes several improvements to the release workflow and bug fixes. The release notes handling has been updated and simplified, and several bugs in the GitHub Actions workflow have been fixed.</p>"},{"location":"releases/v0.0.78/#new-features","title":"New Features","text":"<ul> <li>Release notes handling in the GitHub workflow has been updated. The workflow now copies the release notes to a temporary location before creating a release in the GitHub repository. This ensures that the release notes are correctly included in the release (d9ab5b) (Eric Ma)</li> <li>The source of the release notes in the GitHub Actions workflow for releasing a Python package has been changed. Instead of using an environment variable, it now reads from a markdown file in the docs/releases directory. The filename is based on the version number (3958ff) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.78/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>A bug in the GitHub Actions workflow for releasing a Python package has been fixed. The copy command used to copy the release notes was incorrect and has been fixed (7cda28) (Eric Ma)</li> <li>The file path for the release notes in the release-python-package GitHub workflow has been corrected. The version number now correctly includes a 'v' prefix when reading the markdown file (e03626) (Eric Ma)</li> <li>The path for the release notes in the GitHub Actions workflow has been corrected. The previous path was causing issues in the workflow execution. The path has been updated to correctly point to the release notes file (75978b) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.78/#deprecations","title":"Deprecations","text":"<ul> <li>The step of copying release notes to a temporary location has been removed and the original file is directly referenced in the release action. This simplifies the workflow and reduces unnecessary operations (eb2aef) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.79/","title":"V0.0.79","text":""},{"location":"releases/v0.0.79/#version-0079","title":"Version 0.0.79","text":"<p>This version introduces a new prompt decorator and tests, improves the release workflow, fixes bugs in the GitHub Actions workflow, and removes the dependency on the 'outlines' package.</p>"},{"location":"releases/v0.0.79/#new-features","title":"New Features","text":"<ul> <li>A new prompt decorator has been added in the scratch_notebooks directory, enhancing the functionality of functions by adding a prompt feature. Tests have been included to ensure the decorator works as expected with different types of function arguments (d023f22) (Eric Ma).</li> <li>Tests for blogging prompts in the prompt_library directory have been added. These tests validate the output of different blogging prompt functions (d023f22) (Eric Ma).</li> <li>The release notes handling in the GitHub workflow has been updated. The workflow now copies the release notes to a temporary location before creating a release in the GitHub repository (3884962) (Eric Ma).</li> <li>The source of the release notes in the GitHub Actions workflow for releasing a Python package has been changed. It now reads from a markdown file in the docs/releases directory (3884962) (Eric Ma).</li> <li>The file path for the release notes in the release-python-package GitHub workflow has been corrected. The version number now correctly includes a 'v' prefix when reading the markdown file (3884962) (Eric Ma).</li> <li>The path for the release notes in the GitHub Actions workflow has been corrected. The previous path was causing issues in the workflow execution. The path has been updated to correctly point to the release notes file (3884962) (Eric Ma).</li> </ul>"},{"location":"releases/v0.0.79/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>The file path for the release notes in the release-python-package GitHub workflow was incorrect and has been fixed (3884962) (Eric Ma).</li> </ul>"},{"location":"releases/v0.0.79/#deprecations","title":"Deprecations","text":"<ul> <li>The step of copying release notes to a temporary location has been removed and the original file is directly referenced in the release action. This simplifies the workflow and reduces unnecessary operations (3884962) (Eric Ma).</li> <li>The 'outlines' package was removed from the dependencies in the environment.yml and pyproject.toml files (af23aae) (Eric Ma).</li> </ul>"},{"location":"releases/v0.0.79/#refactors","title":"Refactors","text":"<ul> <li>The use of the <code>outlines</code> package has been replaced with a custom <code>prompt_manager</code> module across multiple files in the <code>llamabot</code> project. The <code>prompt_manager</code> provides a <code>prompt</code> decorator that turns Python functions into Jinja2-templated prompts, similar to the functionality provided by <code>outlines</code>. This refactor removes the dependency on the <code>outlines</code> package, simplifying the project's dependencies and potentially improving maintainability (dbe78e4) (Eric Ma).</li> </ul>"},{"location":"releases/v0.0.8/","title":"V0.0.8","text":""},{"location":"releases/v0.0.8/#version-008","title":"Version 0.0.8","text":"<p>This new version 0.0.8 of Llamabot introduces enhanced functionality and improved documentation.</p>"},{"location":"releases/v0.0.8/#new-features","title":"New Features","text":"<ul> <li>The application now exposes more arguments, providing users with greater flexibility and control. (f42815) (Eric Ma)</li> <li>Additional docstrings have been added, improving the documentation and making the code easier to understand and use. (f42815) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.8/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>No bug fixes in this release.</li> </ul>"},{"location":"releases/v0.0.8/#deprecations","title":"Deprecations","text":"<ul> <li>No deprecations in this release.</li> </ul>"},{"location":"releases/v0.0.80/","title":"V0.0.80","text":""},{"location":"releases/v0.0.80/#version-0080","title":"Version 0.0.80","text":"<p>This version includes several improvements to the ChatBot, QueryBot, and SimpleBot classes, including new parameters for additional configuration options and improved code readability. It also simplifies the pip install command used in the release-python-package GitHub workflow and removes unnecessary clutter from the codebase.</p>"},{"location":"releases/v0.0.80/#new-features","title":"New Features","text":"<ul> <li>Added <code>streaming</code> and <code>verbose</code> parameters to the <code>ChatBot</code> class initialization method, providing more flexibility in controlling the chat history streaming and verbosity during the bot initialization (a69c0f) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.80/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Simplified the pip install command used in the release-python-package GitHub workflow. The previous command attempted to install all optional dependencies, which is not necessary for writing release notes. The new command only installs the package itself (2dffac) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.80/#refactors","title":"Refactors","text":"<ul> <li>Updated parameter names and descriptions in ChatBot, QueryBot, and SimpleBot for consistency and clarity. Added 'streaming' and 'verbose' parameters to SimpleBot for additional configuration options. Improved code readability by breaking up long lines and comments (6c0b37) (Eric Ma)</li> <li>Removed a large block of commented out code from the prompt_manager.py file, improving readability and reducing clutter in the codebase (7f4b0a) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.80/#other","title":"Other","text":"<ul> <li>Bumped version from 0.0.79 to 0.0.80 (385221) (github-actions)</li> </ul>"},{"location":"releases/v0.0.81/","title":"V0.0.81","text":""},{"location":"releases/v0.0.81/#version-0081","title":"Version 0.0.81","text":"<p>This new version introduces a significant enhancement to the QueryBot class, providing more control over the printing of debug messages.</p>"},{"location":"releases/v0.0.81/#new-features","title":"New Features","text":"<ul> <li>Added a 'verbose' parameter to the QueryBot class to control the printing of debug messages (eee3e9) (Eric Ma)</li> <li>Updated the initialization of the LangChain model to use the new 'verbose' parameter instead of a hardcoded value (eee3e9) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.81/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>No bug fixes in this release.</li> </ul>"},{"location":"releases/v0.0.81/#deprecations","title":"Deprecations","text":"<ul> <li>No deprecations in this release.</li> </ul>"},{"location":"releases/v0.0.82/","title":"V0.0.82","text":""},{"location":"releases/v0.0.82/#version-0082","title":"Version 0.0.82","text":"<p>This new version primarily focuses on improving code readability and maintainability. It also introduces a new feature to handle different numbers of tags in the git log when writing release notes.</p>"},{"location":"releases/v0.0.82/#new-features","title":"New Features","text":"<ul> <li>Added conditions to handle different numbers of tags in git log (645a36) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.82/#improvements","title":"Improvements","text":"<ul> <li>Reformatted code in multiple files for better readability (871316) (Eric Ma)</li> <li>Added newline at the end of the release notes file (871316) (Eric Ma)</li> <li>Improved handling of cases with no tags or only one tag in the git repository (871316) (Eric Ma)</li> <li>Removed unnecessary comments from <code>llamabot/panel_utils.py</code> and <code>tests/cli/test_cli_utils.py</code> (871316) (Eric Ma)</li> <li>Reformatted docstrings for better readability in multiple test files (871316) (Eric Ma)</li> <li>Updated docstrings for test functions to be more descriptive in <code>tests/test_file_finder.py</code> and <code>tests/test_recorder.py</code> (871316) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.82/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>No bug fixes in this release.</li> </ul>"},{"location":"releases/v0.0.82/#deprecations","title":"Deprecations","text":"<ul> <li>No deprecations in this release.</li> </ul>"},{"location":"releases/v0.0.83/","title":"V0.0.83","text":""},{"location":"releases/v0.0.83/#version-0083","title":"Version 0.0.83","text":"<p>This new version introduces more flexibility and control over the token budget and chunk sizes used in the chatbot. It also includes a new attribute to store the model name used by the bot and a bug fix to ensure multiple document paths are handled correctly.</p>"},{"location":"releases/v0.0.83/#new-features","title":"New Features","text":"<ul> <li>Added support for <code>response_tokens</code> and <code>history_tokens</code> parameters in the <code>QueryBot</code> class. These parameters allow the user to specify the number of tokens to use for the response and history in the chatbot. Also, a <code>chunk_sizes</code> parameter has been added to the <code>make_or_load_vector_index</code> function to specify a list of chunk sizes to use for the LlamaIndex TokenTextSplitter (a1de812) (Eric Ma)</li> <li>Introduced a new attribute 'model_name' to both QueryBot and SimpleBot classes. This attribute will be used to store the name of the model used by the bot (d5d684) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.83/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Modified the <code>doc_paths</code> parameter in the chat function of the llamabot/cli/doc.py file to receive a list of doc_paths, ensuring that the function can handle multiple document paths correctly (c763327) (Eric Ma)</li> <li>Changed the variable name in the chat function from <code>doc_path</code> to <code>doc_paths</code> for better clarity and consistency (11111e) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.83/#deprecations","title":"Deprecations","text":"<ul> <li>No deprecations in this release.</li> </ul>"},{"location":"releases/v0.0.84/","title":"V0.0.84","text":""},{"location":"releases/v0.0.84/#version-0084","title":"Version 0.0.84","text":"<p>This new version introduces enhancements to the QueryBot class, adds a notebook for evaluating multiscale embeddings, and updates the funding configuration.</p>"},{"location":"releases/v0.0.84/#new-features","title":"New Features","text":"<ul> <li>A new notebook for evaluating multiscale embeddings has been added. This notebook, \"zotero_multiscale.ipynb\", provides an in-depth look at the effectiveness of multiscale embeddings compared to single-scale embeddings in LlamaBot's QueryBot class. It includes an explanation of multiscale embeddings, the motivation behind using them, and the implementation details. It also includes code to load a document from a Zotero library, create instances of QueryBot with different chunk sizes, and test their performance on different prompts. (24f9b6) (Eric Ma)</li> <li>The default chunk_sizes parameter in the QueryBot class has been updated to [2000]. This change ensures that the LlamaIndex TokenTextSplitter uses a chunk size of 2000 tokens by default. (f9d7f6) (Eric Ma)</li> <li>The GitHub funding platform in FUNDING.yml has been updated to use an array instead of a single string to support multiple contributors. (da221f) (Eric Ma)</li> <li>A new funding configuration file has been added to the project. This file includes supported funding model platforms such as GitHub and Patreon. (68c974) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.84/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>None in this release.</li> </ul>"},{"location":"releases/v0.0.84/#deprecations","title":"Deprecations","text":"<ul> <li>None in this release.</li> </ul>"},{"location":"releases/v0.0.85/","title":"V0.0.85","text":""},{"location":"releases/v0.0.85/#version-0085","title":"Version 0.0.85","text":"<p>This version introduces several enhancements and refactors to the Llamabot project. The changes include improvements to the codebase's flexibility and maintainability, updates to the documentation, and the addition of new features.</p>"},{"location":"releases/v0.0.85/#new-features","title":"New Features","text":"<ul> <li>Added a new parameter <code>model_name</code> to the <code>chat</code> function in <code>zotero.py</code>, allowing users to specify the language model to use. (c03a13f) (Eric Ma)</li> <li>Introduced a new Jupyter notebook 'ollama.ipynb' demonstrating the implementation of a simple chatbot named 'ollama' using the 'llamabot' library. (c4919b2) (Eric Ma)</li> <li>Added a new <code>.vscode/extensions.json</code> file with a list of recommended extensions for Visual Studio Code. (964bafa) (Eric Ma)</li> <li>Added a new file <code>model_dispatcher.py</code> in the <code>llamabot/bot</code> directory, which contains a function <code>create_model</code> that dispatches and creates the right model based on the model name. (3dee9ea) (Eric Ma)</li> <li>Updated <code>simplebot.py</code> to use the <code>create_model</code> function from <code>model_dispatcher.py</code> instead of directly creating the model. (3dee9ea) (Eric Ma)</li> <li>Added a prompt to the <code>default_model</code> function in <code>configure.py</code> that informs the user to run <code>llamabot configure default-model</code> to set the default model. (b7a50e5) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.85/#refactors","title":"Refactors","text":"<ul> <li>Replaced the hardcoded model name \"codellama\" with the default language model from the config file in <code>simplebot.py</code>. (bfb47a2) (Eric Ma)</li> <li>Moved model token constants to a new file <code>model_tokens.py</code> for better organization and maintainability. (f2a1f46) (Eric Ma)</li> <li>Refactored <code>QueryBot</code> class in <code>querybot.py</code> to use <code>create_model</code> function from <code>model_dispatcher.py</code> for model creation. (f2a1f46) (Eric Ma)</li> <li>Simplified model creation and token budget calculation in <code>chatbot.py</code>. (491ab6f) (Eric Ma)</li> <li>Removed an unnecessary echo message that was instructing the user to set the default model in the <code>default_model</code> function of <code>configure.py</code>. (d3c3751) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.85/#documentation","title":"Documentation","text":"<ul> <li>Added instructions on how to specify a model when using the <code>chat</code> command in <code>zotero.md</code>. (9b07f17) (Eric Ma)</li> <li>Introduced a new tutorial file <code>ollama.md</code> providing a comprehensive guide on how to run a chatbot using <code>llamabot</code> and <code>Ollama</code>. (9b07f17) (Eric Ma)</li> <li>Added a newline at the end of the release notes for versions v0.0.82, v0.0.83, and v0.0.84. (0001e76) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.85/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>No bug fixes in this release.</li> </ul>"},{"location":"releases/v0.0.85/#deprecations","title":"Deprecations","text":"<ul> <li>No deprecations in this release.</li> </ul>"},{"location":"releases/v0.0.86/","title":"V0.0.86","text":""},{"location":"releases/v0.0.86/#version-0086","title":"Version 0.0.86","text":"<p>This version includes several enhancements and updates to the codebase, including the addition of new tutorials, refactoring of the code, and updates to the Python version used in the GitHub Actions workflow.</p>"},{"location":"releases/v0.0.86/#new-features","title":"New Features","text":"<ul> <li>Added a tutorial for building a QueryBot chat interface with file upload functionality. This tutorial guides users on how to build a chat interface using the QueryBot and Panel libraries. (4b5799a) (Eric Ma)</li> <li>Introduced a new tutorial in the documentation that guides users on how to create a simple chat interface using the <code>SimpleBot</code> class from the <code>llamabot</code> library and the <code>Panel</code> library. (efaef316) (Eric Ma)</li> <li>Introduced a new Jupyter notebook 'panel-chat.ipynb' in the 'scratch_notebooks' directory. The notebook includes code for setting up a chat interface using the Panel library, and integrating it with a chatbot for interactive responses. (ba5d8009) (Eric Ma)</li> <li>Introduced a new Jupyter notebook 'zotero-panel.ipynb' in the 'scratch_notebooks' directory. The notebook contains code for creating a Zotero panel with interactive widgets for configuring Zotero API key, library ID, and library type. (8f477ec6) (Eric Ma)</li> <li>Introduced a new instance of SimpleBot named 'feynman' to the ollama notebook. The bot is tasked with explaining complex concepts, specifically in this case, the challenge of enzyme function annotation and the introduction of a machine learning algorithm named CLEAN. (7f844dca) (Eric Ma)</li> <li>Added \".html\": \"UnstructuredReader\" to EXTENSION_LOADER_MAPPING in doc_processor.py to enable processing of .html files. (45d6485c) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.86/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Updated the python version used in the GitHub workflow for code style checks to 3.11. (d10e7e18) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.86/#refactor","title":"Refactor","text":"<ul> <li>Removed unused imports from <code>querybot.py</code> and updated <code>make_or_load_vector_index</code> function to take <code>service_context</code> as a parameter instead of creating it within the function. (935e3dad) (Eric Ma)</li> <li>Removed the unused @validate_call decorator from the call method in querybot.py. (3f7e8c0b) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.86/#documentation","title":"Documentation","text":"<ul> <li>Added instructions to the documentation on how to use local Ollama models with LlamaBot. It includes a Python code snippet demonstrating how to specify the <code>model_name</code> keyword argument when creating a <code>SimpleBot</code> instance. (57f12809) (Eric Ma)</li> <li>Updated the documentation for LlamaBot. It introduces two options for getting access to language models: using local models with Ollama or using the OpenAI API. (fc42049c) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.86/#chore","title":"Chore","text":"<ul> <li>Updated the versions of pre-commit hooks for pre-commit-hooks, black, and ruff-pre-commit. It also replaces the darglint hook with pydoclint for better documentation linting. (9cc49022) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.87/","title":"V0.0.87","text":""},{"location":"releases/v0.0.87/#version-0087","title":"Version 0.0.87","text":"<p>This new version introduces several enhancements and features to improve the flexibility and maintainability of the code. The major highlight of this release is the dynamic scraping of Ollama model names, which allows the code to adapt to changes in the Ollama model library. Additionally, the codebase has been updated to Python 3.10, and new models have been added to the llama_model_keywords list.</p>"},{"location":"releases/v0.0.87/#new-features","title":"New Features","text":"<ul> <li>Dynamically scrape Ollama model names from the Ollama website. If the website cannot be reached, a static list of model names is used as a fallback. The function is cached using lru_cache to improve performance. (1f7e27) (Eric Ma)</li> <li>Added a function to automatically update the list of Ollama models. A new Python script has been added to the hooks in the pre-commit configuration file. This script scrapes the Ollama AI library webpage to get the latest model names and writes them to a text file. (f22007) (Eric Ma)</li> <li>Added the content.code.copy feature to the theme configuration in mkdocs.yaml. This feature allows users to easily copy code snippets from the documentation. (594d16) (Eric Ma)</li> <li>Added beautifulsoup4, lxml, and requests to the environment.yml file. These packages are necessary for the automatic scraping of ollama models. (2737a9) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.87/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>The method ollama_model_keywords() in model_dispatcher.py has been refactored. The dynamic scraping of model names from the Ollama website has been removed. Instead, the model names are now read from a static text file distributed with the package. This change simplifies the code and removes the dependency on the BeautifulSoup and requests libraries. (73d25) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.87/#deprecations","title":"Deprecations","text":"<ul> <li>The 'Commit release notes' step has been separated from the 'Write release notes' step in the release-python-package workflow. The 'pre-commit' package installation has been moved to the 'Commit release notes' step. (4613a) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.87/#other-changes","title":"Other Changes","text":"<ul> <li>The target Python version in the Black configuration has been updated from Python 3.9 to Python 3.10. (cfadb3) (Eric Ma)</li> <li>Some of the existing models have been reordered and new ones have been added to the llama_model_keywords list in the model_dispatcher module. (22ade) (Eric Ma)</li> <li>A newline has been added at the end of the v0.0.86 release notes file. This change is in line with the standard file formatting conventions. (c22810) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.88/","title":"V0.0.88","text":""},{"location":"releases/v0.0.88/#version-0088","title":"Version 0.0.88","text":"<p>This new version brings updates to the ollama model names and sorting method, updates to dependencies, and a temporary fix to the openai version. It also includes enhancements to the model name handling in llamabot.</p>"},{"location":"releases/v0.0.88/#new-features","title":"New Features","text":"<ul> <li>Updated ollama model names and implemented a new sorting method. The models are now sorted by newest. (a19004) (Eric Ma)</li> <li>Enhanced model name handling in llamabot. The model names in ollama_model_names.txt have been reordered for better organization, and additional code cells have been added to ollama.ipynb for testing and demonstrating the use of PromptRecorder and SimpleBot. (57389f) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.88/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Temporarily limited the version of openai dependency to &lt;=0.28.1 in pyproject.toml. This is due to an issue with OpenAI's update breaking a lot of LangChain. (1d881a) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.88/#dependency-updates","title":"Dependency Updates","text":"<ul> <li>Updated langchain and llama_index dependencies in pyproject.toml. The langchain version has been set to 0.0.330 and llama_index version set to 0.8.62. This ensures three-way compatibility with openai, langchain, and llama-index until langchain is upgraded to work with the openai Python API without error. (e3cf0d) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.89/","title":"V0.0.89","text":""},{"location":"releases/v0.0.89/#version-0089","title":"Version 0.0.89","text":"<p>This version includes several refactoring changes, new features, and documentation updates. The main focus of this release was to improve the code organization and efficiency, and to update the usage of the OpenAI API.</p>"},{"location":"releases/v0.0.89/#new-features","title":"New Features","text":"<ul> <li>Added a new test for the ImageBot class in the llamabot library. The test checks the behavior of the call method when it is invoked outside of a Jupyter notebook and no save path is provided. (0e23857) (Eric Ma)</li> <li>Introduced a new Jupyter notebook under the docs/examples directory. The notebook demonstrates how to use the ImageBot API to generate images from text using the OpenAI API. (8779040) (Eric Ma)</li> <li>Added ImageBot class to bot module for generating images based on prompts. (7174058) (Eric Ma)</li> <li>Increased the default token budget from 2048 to 4096 and added token budget for the new \"mistral\" model. (7f13698) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.89/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Fixed the cache-downloads-key in the pr-tests.yaml workflow file. The key now includes a hash of the 'environment.yml' file to ensure cache is updated when the environment changes. (1c12ff5) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.89/#refactors","title":"Refactors","text":"<ul> <li>Moved the initialization of the OpenAI client into the <code>default_model</code> function. (bd50b90) (Eric Ma)</li> <li>Removed the direct access to the environment variable for the OpenAI API key in the client initialization. (7cb3d09) (Eric Ma)</li> <li>Changed the way model list attributes are accessed in the configure.py file of the llamabot CLI. (4deb93f) (Eric Ma)</li> <li>Extracted the filename generation logic, which was previously inside the ImageBot class, to a separate function named filename_bot. (aec4f3c) (Eric Ma)</li> <li>Removed direct assignment of OpenAI API key in init.py and replaced direct model list retrieval from OpenAI with client's model list method. (66fbcec) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.89/#documentation","title":"Documentation","text":"<ul> <li>Updated the docstring for the filename_bot function in the imagebot.py file. The updated docstring now includes parameter and return value descriptions. (c5dd51d) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.89/#dependencies","title":"Dependencies","text":"<ul> <li>Updated the micromamba version from '1.4.5-0' to '1.5.1-2' in the pr-tests.yaml workflow. (6341f35) (Eric Ma)</li> <li>Updated dependencies versions including llama_index and langchain in environment.yml and pyproject.toml. (e9229cc) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.89/#tests","title":"Tests","text":"<ul> <li>Removed the deadline for the test_codebot_instance function in the python_prompt_library test suite to prevent potential timeout issues. (4a30e96) (Eric Ma)</li> <li>Removed the deadline for the simple bot initialization test to prevent false negatives due to time constraints. (16ee108) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.9/","title":"V0.0.9","text":""},{"location":"releases/v0.0.9/#009","title":"0.0.9","text":"<p>This new version includes several enhancements and new features, including the addition of a chatbot test, the integration of pytest-cov into the conda environment, and the successful implementation of streaming with SimpleBot. The chatbot UI prototype is now operational, and the code has been refactored for better organization and efficiency.</p>"},{"location":"releases/v0.0.9/#new-features","title":"New Features","text":"<ul> <li>Added a test for the chatbot functionality (0cc812) (Eric Ma)</li> <li>Integrated pytest-cov into the conda environment for better code coverage during testing (592297) (Eric Ma)</li> <li>Confirmed that streaming works with SimpleBot, enhancing real-time communication capabilities (049c23) (Eric Ma)</li> <li>Refactored panel markdown callback handler into panel_utils for better code organization (400bd0) (Eric Ma)</li> <li>Developed a rudimentary prototype of the chatbot UI, paving the way for user interaction (0e0bd5) (Eric Ma)</li> <li>Updated the simplebot panel example, providing a more comprehensive demonstration of the bot's capabilities (8515cf) (Eric Ma)</li> <li>Refactored bot.py into individual .py files for better code management and readability (5e97ed) (Eric Ma)</li> <li>Switched to Python version 3.10, taking advantage of the latest features and improvements in the language (f4c28f) (Eric Ma)</li> <li>Ensured the presence of typer-cli, enhancing command line interface functionality (856fbc) (Eric Ma)</li> <li>Added typer to optional dependencies, providing more flexibility in package installation (2e853e) (Eric Ma)</li> </ul>"},{"location":"releases/v0.0.9/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>No bug fixes in this release.</li> </ul>"},{"location":"releases/v0.0.9/#deprecations","title":"Deprecations","text":"<ul> <li>No deprecations in this release.</li> </ul>"},{"location":"releases/v0.1.0/","title":"V0.1.0","text":""},{"location":"releases/v0.1.0/#version-010","title":"Version 0.1.0","text":"<p>This release includes several new features, bug fixes, and improvements to the codebase.</p>"},{"location":"releases/v0.1.0/#new-features","title":"New Features","text":"<ul> <li>Update default language model to Mistral and remove OpenAI API key warning (e74954b) (Eric Ma): The default language model used by the <code>SimpleBot</code> class has been updated to Mistral, which is a more cost-effective option compared to the previously used gpt-3.5-turbo-16k-0613 model. The OpenAI API key warning has also been removed, as the Mistral model does not require an API key.</li> <li>Add API key support for QABot and SimpleBot (b5f8253) (Eric Ma): This commit adds support for providing API keys to the QABot and SimpleBot classes, allowing for secure access to external services. This enhancement improves the security and flexibility of the bot's functionality.</li> <li>Update default language model environment variable (4bfd362) (Eric Ma): The default language model environment variable has been updated from <code>OPENAI_DEFAULT_MODEL</code> to <code>DEFAULT_LANGUAGE_MODEL</code> to align with the changes in the codebase.</li> <li>Update default language model to gpt-3.5-turbo-1106 (c8f0893) (Eric Ma): The default language model used by the commitbot has been updated to \"gpt-3.5-turbo-1106\" for improved performance and cost efficiency.</li> <li>Add logging for API key usage (3be39ad) (Eric Ma): Logging has been added to SimpleBot to log the usage of the API key for debugging and monitoring purposes.</li> <li>Add model_name parameter to SimpleBot instance (6a78332) (Eric Ma): A new parameter, model_name, has been added to the SimpleBot instance in the llamabot/cli/git.py file. The model_name is set to \"mistral/mistral-medium\". This change allows for more flexibility and customization when using the SimpleBot.</li> <li>Add new model name to ollama_model_names.txt (3110dc9) (Eric Ma): 'megadolphin' has been added to the list of model names in ollama_model_names.txt.</li> <li>Add new model name and refactor test_docstore (17352b8) (Eric Ma): 'llama-pro' has been added to ollama_model_names.txt and the test_docstore function has been refactored to remove unused imports and the make_fake_document function.</li> <li>Add Knowledge Graph bot (963cd63) (Eric Ma): A new feature has been added to the codebase, the Knowledge Graph bot (KGBot). The KGBot takes in a chunk of text and returns a JSON of triplets. It is tested with mistral-medium and uses the default language model. The bot is called with a query and returns a JSON of triplets.</li> <li>Add QABot class to llamabot (21197c1) (Eric Ma): A new class, DocQABot, has been added to the qabot.py file. This bot is designed to use pre-computed questions and answers to generate a response. It includes methods for adding documents for the bot to query and for calling the QABot. This enhancement will improve the bot's ability to generate responses based on the provided documents.</li> <li>Add DocumentStore class for LlamaBot (117baf7) (Eric Ma): A new feature has been added to the codebase, a DocumentStore class for LlamaBot. This class wraps around ChromaDB and provides methods to append and retrieve documents from the store. The DocumentStore class is defined in the newly created file llamabot/components/docstore.py.</li> <li>Add top-level API for llamabot's components (b2cf9f0) (Eric Ma): A new file, __init__.py, has been added which serves as the top-level API for llamabot's components.</li> </ul>"},{"location":"releases/v0.1.0/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Fix logging of API key (932beec) (Eric Ma): The commit fixes the logging of the API key in the SimpleBot class to display the complete key instead of just the first 5 characters. This change improves the clarity and security of the logging information.</li> <li>Fix environment variable retrieval in write_release_notes function (c627b18) (Eric Ma): This commit fixes an issue where the environment variable was not being retrieved correctly in the write_release_notes function.</li> <li>Fix stream parameter not being passed to bot function (185f2bc) (Eric Ma): This commit fixes an issue where the stream parameter was not being passed to the bot function in the cli/git module.</li> </ul>"},{"location":"releases/v0.1.0/#deprecations","title":"Deprecations","text":"<ul> <li>None in this release.</li> </ul>"},{"location":"releases/v0.1.1/","title":"V0.1.1","text":""},{"location":"releases/v0.1.1/#version-011","title":"Version 0.1.1","text":"<p>This release includes several improvements and bug fixes to enhance the overall functionality and stability of the project.</p>"},{"location":"releases/v0.1.1/#new-features","title":"New Features","text":"<ul> <li>Bumped version number to 0.1.1 (1ac7b6f, github-actions)</li> <li>Added python-slugify to project dependencies for better string processing capabilities (330152, Eric Ma)</li> <li>Removed unnecessary logger import and usage in SimpleBot (37182cb, Eric Ma)</li> <li>Streamlined the querybot notebook and updated the repository URL (bc17da7, Eric Ma)</li> <li>Enhanced the querybot notebook with utility functions and integrated chromadb (8a74c73, Eric Ma)</li> <li>Added python-slugify dependency to the environment.yml (f5e2dea, Eric Ma)</li> <li>Implemented a new 'repo' subcommand in the CLI module for repository interactions (58fe450, Eric Ma)</li> <li>Added progress bar and deduplication to document processing (1e76998, Eric Ma)</li> <li>Slugified collection names for document storage (4d8dfa2, Eric Ma)</li> <li>Optimized document loading and splitting in doc_processor (6731b97, Eric Ma)</li> <li>Improved API key storage and usage documentation (c1bd6d9, Eric Ma)</li> <li>Updated default model to gpt-4 in git.py (3817430, Eric Ma)</li> <li>Added support for document collections in LlamaBot (009890c, Eric Ma)</li> <li>Improved file search algorithm in file_finder (87d079c, Eric Ma)</li> <li>Added support for configuring multiple API keys (d00c14d, Eric Ma)</li> <li>Updated QueryBot parameters and model names in pdf.ipynb (c83d834, Eric Ma)</li> <li>Added support for configuring multiple API providers (230e816, Eric Ma)</li> </ul>"},{"location":"releases/v0.1.1/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Fixed assertion for split_document function (61e0688, Eric Ma)</li> <li>Ensured non-negative chunk_size parameter in doc_processor (7f9d17b, Eric Ma)</li> <li>Adjusted assertions for split_document_with_overlap (7237647, Eric Ma)</li> <li>Fixed adding documents only when document_paths is not empty (0808ced, Eric Ma)</li> <li>Updated the QueryBot constructor to support optional document_paths (72e6c02, Eric Ma)</li> <li>Removed unnecessary newline characters and updated python version in imagebot.ipynb (2d415c8, Eric Ma)</li> <li>Updated the chatbot to use the Mistral model instead of GPT-4 (51773db, Eric Ma)</li> <li>Added support for LiteLLM models in LLaMaBot documentation (249b3e5, Eric Ma)</li> </ul>"},{"location":"releases/v0.1.1/#deprecations","title":"Deprecations","text":"<ul> <li>Removed simple_chatbot.ipynb from the repository (59f1d4e, Eric Ma)</li> <li>Removed scratch notebook from examples (b4f0e94, Eric Ma)</li> <li>Updated deprecations section in v0.1.0 release notes (776e98f, Eric Ma)</li> </ul>"},{"location":"releases/v0.1.2/","title":"V0.1.2","text":"<p>Here are the release notes based on the provided commit log:</p>"},{"location":"releases/v0.1.2/#version-012","title":"Version 0.1.2","text":"<p>This release includes new model names for llamabot and an update to its dependencies.</p>"},{"location":"releases/v0.1.2/#new-features","title":"New Features","text":"<ul> <li>Added 'qwen' and 'tinydolphin' to the list of llamabot model names and updated dependencies to include 'pydantic' (21c1492) (Eric Ma)</li> <li>Bumped version number from 0.1.1 to 0.1.2 (76b9b4) (github-actions)</li> </ul>"},{"location":"releases/v0.1.2/#bug-fixes","title":"Bug Fixes","text":"<p>No bug fixes were included in this release.</p>"},{"location":"releases/v0.1.2/#deprecations","title":"Deprecations","text":"<p>No deprecations were included in this release.</p> <p>Note: The commit <code>cd04ed38</code> is not included in the release notes as it only added release notes for version 0.1.1.</p>"},{"location":"releases/v0.2.0/","title":"V0.2.0","text":""},{"location":"releases/v0.2.0/#version-020","title":"Version 0.2.0","text":"<p>This release includes several improvements and new features for the LlamaBot project.</p>"},{"location":"releases/v0.2.0/#new-features","title":"New Features","text":"<ul> <li>API Server: Merged pull request #28, which introduces an API server for the LlamaBot project. (4ea160a, Eric Ma)</li> <li>Mock Response and API Key Support: Added <code>api_key</code> and <code>mock_response</code> parameters to the SimpleBot constructor for OpenAI API key usage and testing with predefined responses. (2f6d1d9, Eric Ma)</li> <li>Streaming Response Test: Implemented a new test case to verify that SimpleBot can stream responses correctly. (5ddb804, Eric Ma)</li> <li>Delta Content Printing: The SimpleBot class now prints the delta content to the console after processing each message for better readability. (d657b4a, Eric Ma)</li> <li>ChatBot UI Jupyter Notebook: Created a new Jupyter notebook for ChatBot UI development, including the setup of necessary classes and functions. (bb4397a, Eric Ma)</li> <li>ChatUIMixin: Introduced a new ChatUIMixin class for easier integration of chat functionalities in LlamaBot components. (4209b18, Eric Ma)</li> <li>Streamlined Message Handling and Typing: Simplified the message construction and typing in the SimpleBot class for improved readability and maintainability. (65e026c, Eric Ma)</li> <li>Streaming Response for Chat Messages: Implemented streaming response functionality in the ChatBot class for better real-time interactivity. (1ebc356, Eric Ma)</li> <li>Improved Response Streaming: Extracted streaming logic into a separate method and ensured consistent yielding of AIMessage instances in the SimpleBot class. (08636a7, Eric Ma)</li> <li>Toggleable Streaming Responses: Added a <code>stream</code> parameter to the generate_response method in the SimpleBot class to control streaming behavior. (565aed7, Eric Ma)</li> <li>Streaming Response Capability: Implemented a new stream_response method in the SimpleBot class for streaming responses incrementally. (2a8254c, Eric Ma)</li> <li>Response Generation Extraction: Simplified the generate_response method in the SimpleBot class by extracting the response generation logic into a new _make_response function. (0ad9a1e, Eric Ma)</li> <li>API Key Instructions: Added instructions for setting API keys for other providers in the documentation. (55ec13e, Eric Ma)</li> <li>Standardized LlamaBot Naming Convention: Corrected the casing of 'LLaMaBot' to 'LlamaBot' throughout the index.md documentation and separated API provider configuration instructions into subsections for OpenAI and Mistral. (7fd2e13, Eric Ma)</li> <li>New Model Names and CLI Options Refactoring: Added 'stablelm2' and 'duckdb-nsql' to the list of available models and refactored command-line interface arguments in serve.py to use Typer options instead of arguments. (e6a2122, Eric Ma)</li> <li>FastAPI Endpoint for QueryBot: Implemented APIMixin to allow QueryBot to serve FastAPI endpoints and added a <code>serve</code> command to the CLI for starting a FastAPI server with QueryBot. (5edd84b, Eric Ma)</li> <li>Improved System Prompt for QueryBot: Modified the system prompt in QueryBot to be more specific about the source of knowledge and clarified the response behavior when the repository does not contain the answer. (5f7ce51, Eric Ma)</li> <li>LlamaBot CLI Usage Guide: Added a comprehensive guide for the LlamaBot CLI in the documentation, including installation instructions, key commands, and usage examples. (9f0b1c8, Eric Ma)</li> </ul>"},{"location":"releases/v0.2.0/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>ImageBot Import Path Update: Changed the import path of AIMessage from langchain.schema to llamabot.components.messages to reflect the new module structure. (27904d0, Eric Ma)</li> <li>Error Handling for Image URL Retrieval: Added an exception raise in the ImageBot.generate_image method to handle cases where no image URL is found in the response. (27904d0, Eric Ma)</li> <li>Disabled Streaming in SimpleBot Tests: Passed <code>stream=False</code> when creating a SimpleBot instance in tests to ensure consistent behavior without relying on streaming features. (e559114, Eric Ma)</li> <li>Ensured Non-Empty Strings in Bot Tests: Modified tests to generate non-empty strings for system_prompt and human_message using hypothesis strategies. (e8fed0a, Eric Ma)</li> </ul>"},{"location":"releases/v0.2.0/#deprecations","title":"Deprecations","text":"<ul> <li>Removed Unused Panel App Creation Code: Removed the <code>create_panel_app</code> function and its related imports from python.py as they are no longer used. (4469b35, Eric Ma)</li> <li>Removed PanelMarkdownCallbackHandler Class: Removed the PanelMarkdownCallbackHandler class as it is no longer required in the llamabot project. (b7ef263, Eric Ma)</li> <li>Removed Unused pytest Import and Obsolete Test: Removed an unused import of pytest in test_simplebot.py and deleted the test_simple_bot_stream_response function, which is no longer needed due to changes in the SimpleBot streaming response logic. (ed0756b, Eric Ma)</li> <li>Removed model_dispatcher Module: The model_dispatcher.py module has been removed as part of a refactoring effort. This change simplifies the llamabot architecture by delegating model dispatch responsibilities to a new system or removing the need for such functionality entirely. (0887618, Eric Ma)</li> <li>Removed api_key Command from configure.py: The api_key command was deprecated and has been removed to simplify configuration. Users should now set API keys directly via environment variables. (2752d7e, Eric Ma)</li> </ul>"},{"location":"releases/v0.2.1/","title":"V0.2.1","text":""},{"location":"releases/v0.2.1/#version-021","title":"Version 0.2.1","text":"<p>This release includes improvements to the Zotero integration, QueryBot initialization, and the removal of Ollama response content.</p>"},{"location":"releases/v0.2.1/#new-features","title":"New Features","text":"<ul> <li>Add a space in the mock to test the strip works (cced1c9) (Aidan Brewis)</li> <li>Strip the message content from Ollama responses (2c37454) (Aidan Brewis)</li> <li>Update QueryBot initialization and import paths for better readability (f44c98d) (Eric Ma)</li> </ul>"},{"location":"releases/v0.2.1/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Sanitize collection names using slugify to ensure URL-friendliness (9e7d717) (Eric Ma)</li> <li>Adjust pydantic dependency location for proper package resolution (eef70a0) (Eric Ma)</li> </ul>"},{"location":"releases/v0.2.1/#deprecations","title":"Deprecations","text":"<ul> <li>None in this release</li> </ul> <p>Note: The release notes for version 0.2.0 have been added in commit 3331d44.</p>"},{"location":"releases/v0.2.2/","title":"V0.2.2","text":""},{"location":"releases/v0.2.2/#version-022","title":"Version 0.2.2","text":"<p>This release includes several updates and improvements to the project.</p>"},{"location":"releases/v0.2.2/#new-features","title":"New Features","text":"<ul> <li>Added support for passing keyword arguments to the <code>simple</code> and <code>querybot</code> functions. (d88862b) (Rena Lu)</li> <li>Updated the import statement for <code>llama_index</code> to improve code readability. (6f48ccd) (Rena Lu)</li> <li>Updated the <code>llama_index</code> requirement to the latest version. (4bc1078) (Rena Lu)</li> <li>Added a newline at the end of the v0.2.1 release notes document to maintain consistency and proper formatting in markdown files. (48ee571) (Eric Ma)</li> </ul>"},{"location":"releases/v0.2.2/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Removed a test print statement that was accidentally left in the code. (9b85753) (Rena Lu)</li> </ul>"},{"location":"releases/v0.2.2/#deprecations","title":"Deprecations","text":"<ul> <li>None in this release.</li> </ul> <p>Note: A code style update was also made in this release, but it does not introduce any new features or bug fixes. (e3f6211) (Rena Lu)</p>"},{"location":"releases/v0.2.3/","title":"V0.2.3","text":""},{"location":"releases/v0.2.3/#version-023","title":"Version 0.2.3","text":"<p>This release includes several enhancements to the ChatBot and QueryBot functionalities, as well as improvements to testing and streaming capabilities.</p>"},{"location":"releases/v0.2.3/#new-features","title":"New Features","text":"<ul> <li>Bump version to 0.2.3 (d61ee4c) (github-actions)</li> <li>Enhance ChatBot functionality and testing: Add <code>stream_target</code> parameter, update test cases, remove deprecated methods, and introduce new tests (17428e8) (Eric Ma)</li> <li>Add unit test for QueryBot initialization using Hypothesis for property-based testing (2aa9461) (Eric Ma)</li> <li>Streamline stdout streaming in QueryBot and remove unnecessary constructor parameter (2f39593) (Eric Ma)</li> <li>Enhance SimpleBot tests with stream API scenarios (0ea04b8) (Eric Ma)</li> <li>Remove redundant test_chatbot_call and update test_chatbot_repr (3ec0aa8) (Eric Ma)</li> <li>Simplify mocking in chatbot repr test (244dad9) (Eric Ma)</li> <li>Remove debug print statement and streamline commit message echo in SimpleBot (f16d7a3) (Eric Ma)</li> <li>Correct dictionary access and message concatenation in SimpleBot (79d2929) (Eric Ma)</li> <li>Allow passing additional kwargs to completion function in ChatBot (4058693) (Eric Ma)</li> <li>Enhance streaming capabilities and add type hints in ChatBot (c11aace) (Eric Ma)</li> <li>Remove deprecated Jupyter notebook example for streaming (d6693a3) (Eric Ma)</li> <li>Replace 'stream' parameter with 'stream_target' for more flexible output options (1211115) (Eric Ma)</li> <li>Enhance SimpleBot streaming capabilities and update notebook examples (ab8c359) (Eric Ma)</li> </ul>"},{"location":"releases/v0.2.3/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Fix ChatBot response mocking in unit test (7c02d18) (Eric Ma)</li> <li>Correct dictionary access and message concatenation in SimpleBot (79d2929) (Eric Ma)</li> <li>Replace pdfminer with pdfminer.six for better Python 3 support (79908b1) (Eric Ma)</li> <li>Replace pdfreader with pdfminer for improved PDF processing (7910e3e) (Eric Ma)</li> </ul>"},{"location":"releases/v0.2.3/#deprecations","title":"Deprecations","text":"<ul> <li>Remove 'api' stream_target from ChatBot and change the expected return type for consumers of the ChatBot class (c11aace) (Eric Ma)</li> <li>Replace 'stream' boolean parameter with 'stream_target' in ChatBot and SimpleBot constructors (1211115) (Eric Ma)</li> </ul> <p>Please note that some breaking changes have been introduced in this release. Make sure to update your code accordingly. For more details, refer to the individual commit messages.</p>"},{"location":"releases/v0.2.4/","title":"V0.2.4","text":""},{"location":"releases/v0.2.4/#version-024","title":"Version 0.2.4","text":"<p>This release includes improvements to the autorecord function, enhanced chat command, and updates to Python kernel versions.</p>"},{"location":"releases/v0.2.4/#new-features","title":"New Features","text":"<ul> <li>Autorecord function has been streamlined to record only the last message content, reducing data processing and potential performance issues (268590, Eric Ma)</li> <li>The chat command in the CLI now includes a timestamped session name for better traceability and organization of chat sessions (268590, Eric Ma)</li> </ul>"},{"location":"releases/v0.2.4/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>The Python kernel version in sembr notebook has been updated to 3.11.7 to ensure compatibility with the latest libraries and features (0ad4701, Eric Ma)</li> </ul>"},{"location":"releases/v0.2.4/#deprecations","title":"Deprecations","text":"<ul> <li>No deprecations in this release</li> </ul> <p>Note: The commit 9153c5d is a refactoring commit that improves the readability and maintenance of the notebook code, but it does not introduce any new features or bug fixes. The commit b120061 and 31b1056 are related to version bumping and release notes, respectively. The merge commit ae66c86 is not associated with any new features, bug fixes, or deprecations.</p>"},{"location":"releases/v0.2.5/","title":"V0.2.5","text":"<p>Here are the release notes based on the provided commit log:</p>"},{"location":"releases/v0.2.5/#version-025","title":"Version 0.2.5","text":"<p>This release includes a small fix to the <code>plaintext_loader</code> function in the <code>doc_processor</code> module. The file open mode was changed from \"r\" to \"r+\" to allow for additional operations on the file if needed in the future.</p>"},{"location":"releases/v0.2.5/#new-features","title":"New Features","text":"<p>There are no new features in this release.</p>"},{"location":"releases/v0.2.5/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>The file open mode in <code>plaintext_loader</code> function was changed from \"r\" (read-only) to \"r+\" (read and write). This allows for additional operations on the file if needed in the future. (8251fdc) (Eric Ma)</li> </ul>"},{"location":"releases/v0.2.5/#deprecations","title":"Deprecations","text":"<p>There are no deprecations in this release.</p> <p>Note: The commit <code>48bb8c4</code> is related to version bump and does not introduce any new features or bug fixes. The commit <code>faa971d</code> is related to adding release notes and does not introduce any new features or bug fixes. Therefore, they are not included in the release notes.</p>"},{"location":"releases/v0.3.1/","title":"V0.3.1","text":""},{"location":"releases/v0.3.1/#version-031","title":"Version 0.3.1","text":"<p>This release includes several new features and improvements to enhance the functionality and performance of the project.</p>"},{"location":"releases/v0.3.1/#new-features","title":"New Features","text":"<ul> <li>Bumped version to 0.3.0, introducing new features and improvements (7a0bcbe, Eric Ma)</li> <li>Streamlined API key configuration for release notes generation by utilizing environment variables directly (48c9231, Eric Ma)</li> <li>Added reset call to querybot test to maintain test isolation and consistency (5d28f7e, Eric Ma)</li> <li>Enhanced <code>test_querybot</code> with stream target and input validations to improve test coverage and robustness (54a8a5c, Eric Ma)</li> <li>Updated the underlying model in llamabot/prompt_library/git.py from <code>mistral/mistral-medium</code> to <code>gpt-4-0125-preview</code> to improve response quality and accuracy (603ad73, Eric Ma)</li> <li>Added support for different LLM models, initial message, and Panel integration to the <code>chat</code> command (8fac319, Eric Ma)</li> <li>Added ChatUIMixin to QueryBot and updated initialization and usage for more flexible handling of user input and output (a662e8b, Eric Ma)</li> <li>Added support for initial message and serving the chat interface to ChatUIMixin (d546a9c, Eric Ma)</li> <li>Added BM25 search algorithm to DocumentStore for more flexible and accurate document retrieval (c265c1a, Eric Ma)</li> <li>Added rank-bm25 library for BM25 ranking to improve search result accuracy (0eee328, Eric Ma)</li> <li>Added rank-bm25 library as a dependency for advanced search functionality (29cdb0d, Eric Ma)</li> <li>Updated commitbot model to mistral/mistral-medium for cost savings (00dc294, Eric Ma)</li> <li>Added new Jupyter notebook for parsing Zotero library with Ollama Mistral model (ae383cb, Eric Ma)</li> <li>Updated model name to mistral-medium in commitbot() function of git.py (a5f918f, Eric Ma)</li> <li>Updated transformer model to \"mistralai/Mistral-7B-v0.1\" for improved performance and accuracy (87208bf, Eric Ma)</li> <li>Added FastAPI example with async endpoint (fe20f55, Eric Ma)</li> <li>Ensured save_filename is a Path object before saving chat logs (0cb480d, Eric Ma)</li> <li>Added interactive JavaScript and HTML outputs to Jupyter notebook example (6ee552f, Eric Ma)</li> <li>Switched to micromamba for environment setup in docs (547b20e, Eric Ma)</li> <li>Copied README to docs/index.md during docs build process (6ce70ae, Eric Ma)</li> </ul>"},{"location":"releases/v0.3.1/#bug-fixes","title":"Bug Fixes","text":"<p>There are no bug fixes in this release.</p>"},{"location":"releases/v0.3.1/#deprecations","title":"Deprecations","text":"<p>There are no deprecations in this release.</p>"},{"location":"releases/v0.4.0/","title":"V0.4.0","text":""},{"location":"releases/v0.4.0/#version-040","title":"Version 0.4.0","text":"<p>This release includes several enhancements and improvements to the document store, query bot, and CLI functionality. Additionally, LanceDB has been integrated as a new document store option, and the project dependencies have been updated.</p>"},{"location":"releases/v0.4.0/#new-features","title":"New Features","text":"<ul> <li>Bump version to 0.4.0 (3278cc4) (github-actions)</li> <li>Switch QueryBot to use LanceDB instead of ChromaDB (144534e) (Eric Ma)</li> <li>Add initial Dockerfile for doc_chat deployment (fb3e873) (Eric Ma)</li> <li>Add post-document addition hook and enhance query flexibility (04d6cb6) (Eric Ma)</li> <li>Remove BM25DocStore integration (c2072de) (Eric Ma)</li> <li>Add tantivy to project dependencies (64434bb) (Eric Ma)</li> <li>Add notebook to demonstrate URL markdown issue (846d2b2) (Eric Ma)</li> <li>Prevent document duplication in LanceDBDocStore (6d88525) (Eric Ma)</li> <li>Allow custom initial message in chat function (84e3fd2) (Eric Ma)</li> <li>Enhance bot's system prompt for clarity (6d71a36) (Eric Ma)</li> <li>Enhance logging and simplify document retrieval logic in QueryBot (701669e) (Eric Ma)</li> <li>Update default model to gpt-4-0125-preview (2cebeaa) (Eric Ma)</li> <li>Switch DocumentStore to LanceDBDocStore for question and document storage (688b0fe) (Eric Ma)</li> <li>Remove DocumentStore alias and enhance test coverage (7103b84) (Eric Ma)</li> <li>Add initial Jupyter notebook for LanceDB integration (476d031) (Eric Ma)</li> <li>Add chromadb to project dependencies (baa83f2) (Eric Ma)</li> <li>Ensure chat loop only runs in non-serve mode (53ab092) (Eric Ma)</li> <li>Introduce abstract document store and LanceDB integration (5d9d9c0) (Eric Ma)</li> <li>Integrate LanceDBDocStore and BM25DocStore for document retrieval (f625e57) (Eric Ma)</li> <li>Add lancedb to project dependencies (c8a4699) (Eric Ma)</li> <li>Add sentence-transformers and remove chromadb (ce7c610) (Eric Ma)</li> </ul>"},{"location":"releases/v0.4.0/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Remove deprecated reproduce_failure decorator (4e6c007) (Eric Ma)</li> <li>Handle empty document retrieval gracefully (8c12d93) (Eric Ma)</li> <li>Remove redundant reset call in test_querybot (e5e4bc9) (Eric Ma)</li> <li>Ensure proper reset of stores in querybot tests (151a41d) (Eric Ma)</li> </ul>"},{"location":"releases/v0.4.0/#deprecations","title":"Deprecations","text":"<ul> <li>Remove scratch notebook docstore_lancedb (666dbf6) (Eric Ma)</li> <li>Remove obsolete cache prototype notebook (6d88525) (Eric Ma)</li> <li>Remove DocumentStore alias (7103b84) (Eric Ma)</li> <li>Remove chromadb from dependencies (ce7c610) (Eric Ma)</li> </ul>"},{"location":"releases/v0.4.1/","title":"V0.4.1","text":""},{"location":"releases/v0.4.1/#version-041","title":"Version 0.4.1","text":"<p>This release includes several improvements to the CLI tool's performance, test coverage, and code maintainability.</p>"},{"location":"releases/v0.4.1/#new-features","title":"New Features","text":"<ul> <li>Expanded model names list and increased default query results: Added <code>command-r</code> and <code>mxbai-embed-large</code> to the model names list, and increased the default number of query results from 10 to 20 for better performance and more relevant search results. (1389534, Eric Ma)</li> </ul>"},{"location":"releases/v0.4.1/#improvements","title":"Improvements","text":"<ul> <li>Improved CLI tool execution time test: Introduced a new test case to measure the execution time of the llamabot CLI tool and ensured it does not exceed a predefined threshold (2 seconds) to maintain performance expectations. (09f776e, Eric Ma)</li> <li>Adjusted CLI tool execution time threshold: Increased the execution time assertion from 2.0 seconds to 3.0 seconds to accommodate changes in the CLI tool's performance characteristics and ensure reliable tests under varying execution conditions. (ca0d353, Eric Ma)</li> <li>Simplified <code>test_call_in_jupyter</code> with patching: Replaced <code>mocker</code> usage with <code>unittest.mock.patch</code> for consistency and clarity, utilized <code>MagicMock</code> directly for mocking responses, and streamlined the test by removing redundant setup and assertions. (ee29c25, Eric Ma)</li> <li>Optimized import statements: Moved imports to function scope in <code>imagebot.py</code> and <code>docstore.py</code> to improve import efficiency and potentially reduce the initial load time of the modules. (d4e5920, Eric Ma)</li> <li>Streamlined embedding and schema definition: Replaced <code>Optional</code> type import with <code>Callable</code>, removed <code>DocstoreEntry</code> class from global scope, integrated its definition within <code>LanceDBDocStore</code> constructor, and simplified embedding function retrieval. (7621520, Eric Ma)</li> </ul>"},{"location":"releases/v0.4.1/#code-maintenance-and-optimization","title":"Code Maintenance and Optimization","text":"<ul> <li>Bumped version to 0.4.1: Updated the version number to 0.4.1 using GitHub Actions. (6b1df0c, github-actions)</li> <li>Merged pull request #50: Incorporated changes from the <code>improve-cli-timing</code> branch. (e24911a, Eric Ma)</li> <li>Optimized imports and removed debug logs: Moved <code>openai.OpenAI</code> import to <code>ImageBot</code> constructor, removed unused <code>loguru.logger</code> imports and related debug log statements, and encapsulated <code>lancedb.embeddings.get_registry</code> import within <code>DocstoreEntry</code> constructor. (f158ddd, Eric Ma)</li> <li>Optimized imports and dynamic loading: Removed unused imports, implemented dynamic import loading for <code>panel</code>, <code>pandas</code>, <code>chromadb</code>, and <code>lancedb</code>, and adjusted the scope of import statements to function-level where applicable. (2339555, Eric Ma)</li> <li>Ensured newline at end of v0.4.0 release notes: Added a newline at the end of the v0.4.0 release notes file to ensure compliance with POSIX standards and improve compatibility with various text processing tools. (b9bd9c5, Eric Ma)</li> </ul>"},{"location":"releases/v0.4.1/#deprecations","title":"Deprecations","text":"<ul> <li>None in this release</li> </ul>"},{"location":"tutorials/chatbot/","title":"ChatBot Tutorial","text":"<p>Note</p> <p>This tutorial was written by GPT4 and edited by a human.</p> <p>In this tutorial, we will learn how to use the <code>ChatBot</code> class to create a simple chatbot that can interact with users. The chatbot is built using the OpenAI GPT-4 model and can be used in a Panel app.</p>"},{"location":"tutorials/chatbot/#getting-started","title":"Getting Started","text":"<p>First, let's import the <code>ChatBot</code> class:</p> <pre><code>from llamabot import ChatBot\n</code></pre> <p>Now, let's create a new instance of the <code>ChatBot</code> class. We need to provide a system prompt, which will be used to prime the chatbot. Optionally, we can also set the temperature and model name:</p> <pre><code>system_prompt = \"Hello, I am a chatbot. How can I help you today?\"\nchatbot = ChatBot(system_prompt, temperature=0.0, model_name=\"gpt-4\")\n</code></pre>"},{"location":"tutorials/chatbot/#interacting-with-the-chatbot","title":"Interacting with the ChatBot","text":"<p>To interact with the chatbot, we can simply call the chatbot instance with a human message:</p> <pre><code>human_message = \"What is the capital of France?\"\nresponse = chatbot(human_message)\nprint(response.content)\n</code></pre> <p>The chatbot will return an <code>AIMessage</code> object containing the response to the human message, primed by the system prompt.</p>"},{"location":"tutorials/chatbot/#chat-history","title":"Chat History","text":"<p>The chatbot automatically manages the chat history. To view the chat history, we can use the <code>__repr__</code> method:</p> <pre><code>print(chatbot)\n</code></pre> <p>This will return a string representation of the chat history, with each message prefixed by its type (System, Human, or AI).</p>"},{"location":"tutorials/chatbot/#creating-a-panel-app","title":"Creating a Panel App","text":"<p>The <code>ChatBot</code> class also provides a <code>panel</code> method to create a Panel app that wraps the chatbot. This allows users to interact with the chatbot through a web interface.</p> <p>To create a Panel app, simply call the <code>panel</code> method on the chatbot instance:</p> <pre><code>app = chatbot.panel(show=False)\n</code></pre> <p>By default, the app will be shown in a new browser window. If you want to return the app directly, set the <code>show</code> parameter to <code>False</code>.</p> <p>You can customize the appearance of the app by providing additional parameters, such as <code>site</code>, <code>title</code>, and <code>width</code>:</p> <pre><code>app = chatbot.panel(show=False, site=\"My ChatBot\", title=\"My ChatBot\", width=768)\n</code></pre> <p>To run the app, you can either call the <code>show</code> method on the app or use the Panel <code>serve</code> function:</p> <pre><code>app.show()\n</code></pre> <p>or</p> <pre><code>import panel as pn\npn.serve(app)\n</code></pre> <p>Now you have a fully functional chatbot that can interact with users through a web interface!</p>"},{"location":"tutorials/chatbot/#conclusion","title":"Conclusion","text":"<p>In this tutorial, we learned how to use the <code>ChatBot</code> class to create a simple chatbot that can interact with users. We also learned how to create a Panel app to provide a web interface for the chatbot. With this knowledge, you can now create your own chatbots and customize them to suit your needs. Happy chatting!</p>"},{"location":"tutorials/ollama/","title":"How to Run Llamabot with Ollama","text":""},{"location":"tutorials/ollama/#overview","title":"Overview","text":"<p>In this guide, you'll learn how to run a chatbot using <code>llamabot</code> and <code>Ollama</code>. We'll cover how to install Ollama, start its server, and finally, run the chatbot within a Python session.</p>"},{"location":"tutorials/ollama/#installation-setup","title":"Installation &amp; Setup","text":""},{"location":"tutorials/ollama/#install-ollama","title":"Install Ollama","text":"<ol> <li>macOS Users: Download here</li> <li>Linux &amp; WSL2 Users: Run <code>curl https://ollama.ai/install.sh | sh</code> in your terminal</li> <li>Windows Users: Support coming soon.</li> </ol> <p>For more detailed instructions, refer to Ollama's official site.</p>"},{"location":"tutorials/ollama/#running-ollama-server","title":"Running Ollama Server","text":"<ol> <li>Open your terminal and start the Ollama server with your chosen model.</li> </ol> <pre><code>ollama run &lt;model_name&gt;\n</code></pre> <p>Example:</p> <pre><code>ollama run vicuna\n</code></pre> <p>For a list of available models, visit Ollama's Model Library.</p> <p>Note: Ensure you have adequate RAM for the model you are running.</p>"},{"location":"tutorials/ollama/#running-llamabot-in-python","title":"Running Llamabot in Python","text":"<ol> <li>Open a Python session and import the <code>SimpleBot</code> class from the <code>llamabot</code> library.</li> </ol> <pre><code>from llamabot import SimpleBot  # you can also use QueryBot or ChatBot\n\nbot = SimpleBot(\"You are a conversation expert\", model_name=\"vicuna:7b-16k\")\n</code></pre> <p>Note: <code>vicuna:7b-16k</code> includes tags from the vicuna model page.</p> <p>And there you have it! You're now ready to run your own chatbot with Ollama and Llamabot.</p>"},{"location":"tutorials/querybot/","title":"QueryBot Tutorial","text":"<p>Note</p> <p>This tutorial was written by GPT4 and edited by a human.</p> <p>In this tutorial, we will learn how to use the <code>QueryBot</code> class to create a chatbot that can query documents using GPT-4. The <code>QueryBot</code> class allows us to index documents and use GPT-4 to generate responses based on the indexed documents.</p>"},{"location":"tutorials/querybot/#initializing-querybot","title":"Initializing QueryBot","text":"<p>To create a new instance of <code>QueryBot</code>, we need to provide a system message, a list of document paths, or a saved index path. The system message is used to instruct the chatbot on how to behave. The document paths are used to index the documents, and the saved index path is used to load a pre-built index.</p> <p>Here's an example of how to initialize a <code>QueryBot</code>:</p> <pre><code>from pathlib import Path\nfrom llamabot import QueryBot\n\nsystem_message = \"You are a helpful assistant that can answer questions based on the provided documents.\"\ndoc_paths = [Path(\"document1.txt\"), Path(\"document2.txt\")]\n\nquery_bot = QueryBot(system_message=system_message, doc_paths=doc_paths)\n</code></pre>"},{"location":"tutorials/querybot/#querying-the-index","title":"Querying the Index","text":"<p>To query the index, we can call the <code>QueryBot</code> instance with a query string. The <code>QueryBot</code> will return the top <code>similarity_top_k</code> documents from the index and use them to generate a response using GPT-4.</p> <p>Here's an example of how to query the index:</p> <pre><code>query = \"What is the main idea of document1?\"\nresponse = query_bot(query)\nprint(response.content)\n</code></pre>"},{"location":"tutorials/querybot/#saving-and-loading-the-index","title":"Saving and Loading the Index","text":"<p>We can save the index to disk using the <code>save</code> method and load it later using the <code>__init__</code> method with the <code>saved_index_path</code> parameter.</p> <p>Here's an example of how to save and load the index:</p> <pre><code># Save the index\nquery_bot.save(\"index.json\")\n\n# Load the index\nloaded_query_bot = QueryBot(system_message=system_message, saved_index_path=\"index.json\")\n</code></pre>"},{"location":"tutorials/querybot/#inserting-documents-into-the-index","title":"Inserting Documents into the Index","text":"<p>We can insert new documents into the index using the <code>insert</code> method. This method takes a file path as an argument and inserts the document into the index.</p> <p>Here's an example of how to insert a document into the index:</p> <pre><code>query_bot.insert(Path(\"new_document.txt\"))\n</code></pre>"},{"location":"tutorials/querybot/#conclusion","title":"Conclusion","text":"<p>In this tutorial, we learned how to use the <code>QueryBot</code> class to create a chatbot that can query documents using GPT-4. We covered how to initialize a <code>QueryBot</code>, query the index, save and load the index, and insert new documents into the index. With this knowledge, you can now create your own chatbot that can answer questions based on a set of documents.</p>"},{"location":"tutorials/recording_prompts/","title":"Automatically Record QueryBot Calls with PromptRecorder","text":"<p>Note</p> <p>This tutorial was written by GPT4 and edited by a human.</p> <p>In this tutorial, we will learn how to use the <code>PromptRecorder</code> class to automatically record calls made to the <code>QueryBot</code>. The <code>PromptRecorder</code> class is designed to record prompts and responses, making it a perfect fit for logging interactions with the <code>QueryBot</code>.</p>"},{"location":"tutorials/recording_prompts/#prerequisites","title":"Prerequisites","text":"<p>Before we begin, make sure you have the following Python libraries installed:</p> <ul> <li>pandas</li> <li>panel</li> </ul> <p>You can install them using pip:</p> <pre><code>pip install pandas panel\n</code></pre>"},{"location":"tutorials/recording_prompts/#step-1-import-the-necessary-classes","title":"Step 1: Import the necessary classes","text":"<p>First, we need to import the <code>PromptRecorder</code> and <code>QueryBot</code> classes from their respective source files. You can do this by adding the following lines at the beginning of your script:</p> <pre><code>from prompt_recorder import PromptRecorder, autorecord\nfrom query_bot import QueryBot\n</code></pre>"},{"location":"tutorials/recording_prompts/#step-2-initialize-the-querybot","title":"Step 2: Initialize the QueryBot","text":"<p>Next, we need to create an instance of the <code>QueryBot</code> class. You can do this by providing the necessary parameters, such as the system message, model name, and document paths. For example:</p> <pre><code>system_message = \"You are a helpful assistant that can answer questions based on the provided documents.\"\nmodel_name = \"gpt-4\"\ndoc_paths = [\"document1.txt\", \"document2.txt\"]\n\nquery_bot = QueryBot(system_message, model_name=model_name, doc_paths=doc_paths)\n</code></pre>"},{"location":"tutorials/recording_prompts/#step-3-use-the-promptrecorder-context-manager","title":"Step 3: Use the PromptRecorder context manager","text":"<p>Now that we have an instance of the <code>QueryBot</code>, we can use the <code>PromptRecorder</code> context manager to automatically record the prompts and responses. To do this, simply wrap your interactions with the <code>QueryBot</code> inside a <code>with</code> statement, like this:</p> <pre><code>with PromptRecorder() as recorder:\n    # Interact with the QueryBot here\n</code></pre>"},{"location":"tutorials/recording_prompts/#step-4-interact-with-the-querybot","title":"Step 4: Interact with the QueryBot","text":"<p>Inside the <code>with</code> statement, you can now interact with the <code>QueryBot</code> by calling it with your queries. For example:</p> <pre><code>with PromptRecorder() as recorder:\n    query = \"What is the main idea of document1?\"\n    response = query_bot(query)\n    print(response.content)\n\n    query = \"How does document2 support the main idea?\"\n    response = query_bot(query)\n    print(response.content)\n</code></pre> <p>The <code>PromptRecorder</code> will automatically record the prompts and responses for each interaction with the <code>QueryBot</code>.</p>"},{"location":"tutorials/recording_prompts/#step-5-access-the-recorded-data","title":"Step 5: Access the recorded data","text":"<p>After you have finished interacting with the <code>QueryBot</code>, you can access the recorded data using the <code>PromptRecorder</code> instance. For example, you can print the recorded data as a pandas DataFrame:</p> <pre><code>print(recorder.dataframe())\n</code></pre> <p>Or, you can display the recorded data as an interactive panel:</p> <pre><code>recorder.panel().show()\n</code></pre>"},{"location":"tutorials/recording_prompts/#complete-example","title":"Complete Example","text":"<p>Here's the complete example that demonstrates how to use the <code>PromptRecorder</code> to automatically record <code>QueryBot</code> calls:</p> <pre><code>from prompt_recorder import PromptRecorder, autorecord\nfrom query_bot import QueryBot\n\nsystem_message = \"You are a helpful assistant that can answer questions based on the provided documents.\"\nmodel_name = \"gpt-4\"\ndoc_paths = [\"document1.txt\", \"document2.txt\"]\n\nquery_bot = QueryBot(system_message, model_name=model_name, doc_paths=doc_paths)\n\nwith PromptRecorder() as recorder:\n    query = \"What is the main idea of document1?\"\n    response = query_bot(query)\n    print(response.content)\n\n    query = \"How does document2 support the main idea?\"\n    response = query_bot(query)\n    print(response.content)\n\nprint(recorder.dataframe())\nrecorder.panel().show()\n</code></pre> <p>That's it! You now know how to use the <code>PromptRecorder</code> class to automatically record calls made to the <code>QueryBot</code>. This can be a useful tool for logging and analyzing interactions with your chatbot.</p>"},{"location":"tutorials/simplebot/","title":"SimpleBot Tutorial","text":"<p>Note</p> <p>This tutorial was written by GPT4 and edited by a human.</p> <p>In this tutorial, we will learn how to use the <code>SimpleBot</code> class, a Python implementation of a chatbot that interacts with OpenAI's GPT-4 model. The <code>SimpleBot</code> class is designed to be simple and easy to use, allowing you to create a chatbot that can respond to human messages based on a given system prompt.</p>"},{"location":"tutorials/simplebot/#getting-started","title":"Getting Started","text":"<p>First, let's import the <code>SimpleBot</code> class:</p> <pre><code>from llamabot import SimpleBot\n</code></pre>"},{"location":"tutorials/simplebot/#initializing-the-simplebot","title":"Initializing the SimpleBot","text":"<p>To create a new instance of <code>SimpleBot</code>, you need to provide a system prompt. The system prompt is used to prime the GPT-4 model, giving it context for generating responses. You can also optionally set the <code>temperature</code> and <code>model_name</code> parameters.</p> <pre><code>system_prompt = \"You are an AI assistant that helps users with their questions.\"\nbot = SimpleBot(system_prompt)\n</code></pre>"},{"location":"tutorials/simplebot/#interacting-with-the-simplebot","title":"Interacting with the SimpleBot","text":"<p>To interact with the <code>SimpleBot</code>, simply call the instance with a human message as a parameter. The bot will return an <code>AIMessage</code> object containing the generated response.</p> <pre><code>human_message = \"What is the capital of France?\"\nresponse = bot(human_message)\nprint(response.content)\n</code></pre>"},{"location":"tutorials/simplebot/#using-the-panel-app","title":"Using the Panel App","text":"<p><code>SimpleBot</code> also comes with a built-in Panel app that provides a graphical user interface for interacting with the chatbot. To create the app, call the <code>panel()</code> method on your <code>SimpleBot</code> instance:</p> <pre><code>app = bot.panel()\n</code></pre> <p>You can customize the appearance of the app by providing optional parameters such as <code>input_text_label</code>, <code>output_text_label</code>, <code>submit_button_label</code>, <code>site_name</code>, and <code>title</code>.</p> <p>To display the app in your browser, call the <code>show()</code> method on the app:</p> <pre><code>app.show()\n</code></pre>"},{"location":"tutorials/simplebot/#example","title":"Example","text":"<p>Here's a complete example of how to create and interact with a <code>SimpleBot</code>:</p> <pre><code>from simple_bot import SimpleBot\n\n# Initialize the SimpleBot\nsystem_prompt = \"You are an AI assistant that helps users with their questions.\"\nbot = SimpleBot(system_prompt)\n\n# Interact with the SimpleBot\nhuman_message = \"What is the capital of France?\"\nresponse = bot(human_message)\nprint(response.content)\n\n# Create and display the Panel app\napp = bot.panel()\napp.show()\n</code></pre>"},{"location":"tutorials/simplebot/#conclusion","title":"Conclusion","text":"<p>In this tutorial, we learned how to use the <code>SimpleBot</code> class to create a simple chatbot that interacts with OpenAI's GPT-4 model. We also learned how to create a Panel app for a more user-friendly interface. With this knowledge, you can now create your own chatbots and experiment with different system prompts and settings.</p>"},{"location":"tutorials/chat-ui/querybot/","title":"Building a QueryBot Chat Interface with File Upload in Panel","text":"<ul> <li>Building a QueryBot Chat Interface with File Upload in Panel</li> <li>Prerequisites</li> <li>Code Breakdown<ul> <li>Import Necessary Libraries</li> <li>Initialize Panel Extension</li> <li>Set Up Widgets and Global Variables</li> <li>Define the File Upload Function</li> <li>Interact with the Bot and Update Chat Interface</li> <li>Monitor File Uploads</li> <li>Define the Callback Function for Chat Interface</li> <li>Set Up the Chat Interface</li> <li>Combine Widgets and Chat Interface into a Single App</li> </ul> </li> <li>All the code together<ul> <li>The script</li> <li>The terminal command</li> </ul> </li> <li>Conclusion</li> </ul> <p>In this tutorial, we will walk through how to create a chat interface that allows users to upload a PDF file, which the <code>QueryBot</code> from the <code>llamabot</code> library will then summarize. This is all presented in a neat web app using the <code>Panel</code> library.</p>"},{"location":"tutorials/chat-ui/querybot/#prerequisites","title":"Prerequisites","text":"<ul> <li>Familiarity with Python programming.</li> <li>The <code>llamabot</code> and <code>panel</code> libraries installed.</li> </ul>"},{"location":"tutorials/chat-ui/querybot/#code-breakdown","title":"Code Breakdown","text":""},{"location":"tutorials/chat-ui/querybot/#import-necessary-libraries","title":"Import Necessary Libraries","text":"<pre><code>from llamabot import QueryBot\nimport tempfile\nimport panel as pn\nfrom pathlib import Path\n</code></pre> <ul> <li><code>QueryBot</code>: A class from the <code>llamabot</code> library designed to query and extract information from a given document.</li> <li><code>tempfile</code>: A module to generate temporary files and directories.</li> <li><code>panel</code> (aliased as <code>pn</code>): A Python library for creating web-based interactive apps and dashboards.</li> <li><code>Path</code>: A class from the <code>pathlib</code> library for manipulating filesystem paths.</li> </ul>"},{"location":"tutorials/chat-ui/querybot/#initialize-panel-extension","title":"Initialize Panel Extension","text":"<pre><code>pn.extension()\n</code></pre> <p>This initializes Panel's extension, preparing the environment to work with Panel components.</p>"},{"location":"tutorials/chat-ui/querybot/#set-up-widgets-and-global-variables","title":"Set Up Widgets and Global Variables","text":"<pre><code>file_input = pn.widgets.FileInput(mime_type=[\"application/pdf\"])\nspinner = pn.indicators.LoadingSpinner(value=False, width=30, height=30)\nglobal bot\nbot = None\n</code></pre> <ul> <li><code>file_input</code>: A widget that allows users to upload PDF files.</li> <li><code>spinner</code>: A loading spinner indicator to show when the bot is processing.</li> <li><code>bot</code>: A global variable to store the <code>QueryBot</code> instance.</li> </ul>"},{"location":"tutorials/chat-ui/querybot/#define-the-file-upload-function","title":"Define the File Upload Function","text":"<pre><code>def upload_file(event):\n    spinner.value = True\n    raw_contents = event.new\n\n    with tempfile.NamedTemporaryFile(\n        delete=False, suffix=\".pdf\", mode=\"wb\"\n    ) as temp_file:\n        temp_file.write(raw_contents)\n        global bot\n        bot = QueryBot(\"You are Richard Feynman\", doc_paths=[Path(temp_file.name)])\n    ...\n</code></pre> <p>This function is triggered when a file is uploaded:</p> <ul> <li>It sets the spinner to active.</li> <li>Retrieves the raw contents of the uploaded file.</li> <li>Creates a temporary PDF file and writes the uploaded content to it.</li> <li>Initializes the <code>QueryBot</code> instance with the context \"You are Richard Feynman\" and the path to the temporary file.</li> </ul>"},{"location":"tutorials/chat-ui/querybot/#interact-with-the-bot-and-update-chat-interface","title":"Interact with the Bot and Update Chat Interface","text":"<pre><code>    chat_interface.send(\n        \"Please allow me to summarize the paper for you. One moment...\",\n        user=\"System\",\n        respond=False,\n    )\n    response = bot(\"Please summarize this paper for me.\")\n    chat_interface.send(response.content, user=\"System\", respond=False)\n    spinner.value = False\n</code></pre> <p>After initializing the bot:</p> <ul> <li>A system message is sent to inform the user that the bot is working on summarizing.</li> <li>The bot is then asked to summarize the uploaded paper.</li> <li>The bot's response is sent to the chat interface.</li> <li>The spinner is deactivated.</li> </ul>"},{"location":"tutorials/chat-ui/querybot/#monitor-file-uploads","title":"Monitor File Uploads","text":"<pre><code>file_input.param.watch(upload_file, \"value\")\n</code></pre> <p>This line sets up an event listener on the <code>file_input</code> widget. When a file is uploaded (i.e., its value changes), the <code>upload_file</code> function is triggered.</p>"},{"location":"tutorials/chat-ui/querybot/#define-the-callback-function-for-chat-interface","title":"Define the Callback Function for Chat Interface","text":"<pre><code>async def callback(contents: str, user: str, instance: pn.chat.ChatInterface):\n    spinner.value = True\n    global bot\n    response = bot(contents)\n    spinner.value = False\n    yield response.content\n</code></pre> <p>This function is called whenever a user sends a message:</p> <ul> <li>Activates the spinner.</li> <li>Queries the <code>bot</code> with the user's message.</li> <li>Deactivates the spinner.</li> <li>Yields the bot's response.</li> </ul>"},{"location":"tutorials/chat-ui/querybot/#set-up-the-chat-interface","title":"Set Up the Chat Interface","text":"<pre><code>chat_interface = pn.chat.ChatInterface(\n    callback=callback,\n    callback_user=\"QueryBot\",\n    show_clear=False,\n)\nchat_interface.send(\n    \"Send a message to get a reply from the bot!\",\n    user=\"System\",\n    respond=False,\n)\n</code></pre> <p>This sets up the chat interface and sends an initial message prompting the user to interact.</p>"},{"location":"tutorials/chat-ui/querybot/#combine-widgets-and-chat-interface-into-a-single-app","title":"Combine Widgets and Chat Interface into a Single App","text":"<pre><code>app = pn.Column(pn.Row(file_input, spinner), chat_interface)\napp.servable()\n</code></pre> <p>The file upload widget, spinner, and chat interface are arranged in a layout. The <code>app</code> is made servable, marking it as the main component when the app runs.</p>"},{"location":"tutorials/chat-ui/querybot/#all-the-code-together","title":"All the code together","text":""},{"location":"tutorials/chat-ui/querybot/#the-script","title":"The script","text":"<pre><code># chat_interface.py\nfrom llamabot import QueryBot\nimport tempfile\nimport panel as pn\nfrom pathlib import Path\n\npn.extension()\n\nfile_input = pn.widgets.FileInput(mime_type=[\"application/pdf\"])\nspinner = pn.indicators.LoadingSpinner(value=False, width=30, height=30)\nglobal bot\nbot = None\n\n\ndef upload_file(event):\n    spinner.value = True\n    raw_contents = event.new\n\n    with tempfile.NamedTemporaryFile(\n        delete=False, suffix=\".pdf\", mode=\"wb\"\n    ) as temp_file:\n        temp_file.write(raw_contents)\n        global bot\n        bot = QueryBot(\"You are Richard Feynman\", doc_paths=[Path(temp_file.name)])\n\n    chat_interface.send(\n        \"Please allow me to summarize the paper for you. One moment...\",\n        user=\"System\",\n        respond=False,\n    )\n    response = bot(\"Please summarize this paper for me.\")\n    chat_interface.send(response.content, user=\"System\", respond=False)\n    spinner.value = False\n\n\nfile_input.param.watch(upload_file, \"value\")\n\n\nasync def callback(contents: str, user: str, instance: pn.chat.ChatInterface):\n    spinner.value = True\n    global bot\n    response = bot(contents)\n    spinner.value = False\n    yield response.content\n\n\nchat_interface = pn.chat.ChatInterface(\n    callback=callback,\n    callback_user=\"QueryBot\",\n    show_clear=False,\n)\nchat_interface.send(\n    \"Send a message to get a reply from the bot!\",\n    user=\"System\",\n    respond=False,\n)\n\napp = pn.Column(pn.Row(file_input, spinner), chat_interface)\napp.show()\n</code></pre>"},{"location":"tutorials/chat-ui/querybot/#the-terminal-command","title":"The terminal command","text":"<pre><code>panel serve chat_interface.py\n</code></pre>"},{"location":"tutorials/chat-ui/querybot/#conclusion","title":"Conclusion","text":"<p>By integrating the <code>QueryBot</code> and <code>Panel</code> libraries, we've built a dynamic chat interface that can summarize uploaded PDF files. This tutorial serves as a foundation to develop more sophisticated chatbot applications with file processing capabilities. Happy coding!</p>"},{"location":"tutorials/chat-ui/simplebot-and-chatbot/","title":"Create a Chat Interface with SimpleBot and Panel","text":"<ul> <li>Create a Chat Interface with SimpleBot and Panel</li> <li>Prerequisites</li> <li>Code Breakdown<ul> <li>Import Necessary Libraries</li> <li>Initialize Panel Extension</li> <li>Create a SimpleBot Instance</li> <li>Define the Callback Function</li> <li>Create the Chat Interface</li> <li>Send an Initial Message</li> <li>Make the Chat Interface Servable</li> <li>Serve up the Panel app</li> </ul> </li> <li>All the code together<ul> <li>The python script</li> <li>The terminal command</li> </ul> </li> <li>Conclusion</li> </ul> <p>In this tutorial, we will explore how to set up a simple chat interface using the <code>SimpleBot</code> class from the <code>llamabot</code> library and the <code>Panel</code> library. By the end of this tutorial, you'll be able to integrate a bot into a chat interface and see how it interacts.</p>"},{"location":"tutorials/chat-ui/simplebot-and-chatbot/#prerequisites","title":"Prerequisites","text":"<ul> <li>Familiarity with Python programming.</li> <li>The <code>llamabot</code> and <code>panel</code> libraries installed.</li> </ul>"},{"location":"tutorials/chat-ui/simplebot-and-chatbot/#code-breakdown","title":"Code Breakdown","text":""},{"location":"tutorials/chat-ui/simplebot-and-chatbot/#import-necessary-libraries","title":"Import Necessary Libraries","text":"<pre><code>from llamabot import SimpleBot, ChatBot\nimport panel as pn\n</code></pre> <ul> <li><code>SimpleBot</code> and <code>ChatBot</code>: Classes from the <code>llamabot</code> library that allow you to create chatbot instances.</li> <li><code>panel</code> (aliased as <code>pn</code>): A Python library for creating web-based interactive apps and dashboards.</li> </ul>"},{"location":"tutorials/chat-ui/simplebot-and-chatbot/#initialize-panel-extension","title":"Initialize Panel Extension","text":"<pre><code>pn.extension()\n</code></pre> <p>Before using Panel's functionality, you need to initialize its extension with <code>pn.extension()</code>. This prepares your Python environment to work with Panel components.</p>"},{"location":"tutorials/chat-ui/simplebot-and-chatbot/#create-a-simplebot-instance","title":"Create a SimpleBot Instance","text":"<pre><code>bot = SimpleBot(\"You are Richard Feynman.\")\n</code></pre> <p>Here, we're creating an instance of the <code>SimpleBot</code> class. The string argument, \"You are Richard Feynman.\", serves as a context or persona for the bot. Essentially, this bot will behave as if it's Richard Feynman.</p>"},{"location":"tutorials/chat-ui/simplebot-and-chatbot/#define-the-callback-function","title":"Define the Callback Function","text":"<pre><code>async def callback(contents: str, user: str, instance: pn.chat.ChatInterface):\n    response = bot(contents)\n    yield response.content\n</code></pre> <ul> <li>This asynchronous function will be called whenever a user sends a message to the chat interface.</li> <li>It accepts three parameters:</li> <li><code>contents</code>: The message sent by the user.</li> <li><code>user</code>: The name of the user sending the message.</li> <li><code>instance</code>: The chat interface instance.</li> <li>Inside the function, the message <code>contents</code> is passed to the bot, and the bot's response is yielded.</li> </ul>"},{"location":"tutorials/chat-ui/simplebot-and-chatbot/#create-the-chat-interface","title":"Create the Chat Interface","text":"<pre><code>chat_interface = pn.chat.ChatInterface(\n    callback=callback, callback_user=\"Feynman Bot\", show_clear=False\n)\n</code></pre> <ul> <li>We're creating an instance of <code>ChatInterface</code> from Panel's chat module.</li> <li>The <code>callback</code> parameter is set to the previously defined <code>callback</code> function. This tells the chat interface to use our function to handle messages.</li> <li><code>callback_user</code> is the name that will be displayed for the bot's messages.</li> <li><code>show_clear=False</code> means the chat interface won't have a clear button to erase the chat history.</li> </ul>"},{"location":"tutorials/chat-ui/simplebot-and-chatbot/#send-an-initial-message","title":"Send an Initial Message","text":"<pre><code>chat_interface.send(\n    \"Send a message to get a reply from the bot!\",\n    user=\"System\",\n    respond=False,\n)\n</code></pre> <ul> <li>This sends an initial message to the chat interface to prompt users to interact with the bot.</li> <li>The message is sent from the \"System\" user and does not expect a reply (<code>respond=False</code>).</li> </ul>"},{"location":"tutorials/chat-ui/simplebot-and-chatbot/#make-the-chat-interface-servable","title":"Make the Chat Interface Servable","text":"<pre><code>chat_interface.servable()\n</code></pre> <p>By calling <code>.servable()</code> on the chat interface, you're telling Panel to treat this interface as the main component when you run the app.</p>"},{"location":"tutorials/chat-ui/simplebot-and-chatbot/#serve-up-the-panel-app","title":"Serve up the Panel app","text":"<p>Now, you can serve up the app typing</p> <pre><code>panel serve chat_interface.py\n</code></pre> <p>in your terminal. This will open up a new browser window with the chat interface.</p>"},{"location":"tutorials/chat-ui/simplebot-and-chatbot/#all-the-code-together","title":"All the code together","text":""},{"location":"tutorials/chat-ui/simplebot-and-chatbot/#the-python-script","title":"The python script","text":"<pre><code># chat_interface.py\nfrom llamabot import SimpleBot, ChatBot\nimport panel as pn\n\npn.extension()\n\nbot = SimpleBot(\"You are Richard Feynman.\") # can be ChatBot as well\n\n\nasync def callback(contents: str, user: str, instance: pn.chat.ChatInterface):\n    response = bot(contents)\n    yield response.content\n\n\nchat_interface = pn.chat.ChatInterface(\n    callback=callback, callback_user=\"Feynman Bot\", show_clear=False\n)\nchat_interface.send(\n    \"Send a message to get a reply from the bot!\",\n    user=\"System\",\n    respond=False,\n)\nchat_interface.servable()\n</code></pre>"},{"location":"tutorials/chat-ui/simplebot-and-chatbot/#the-terminal-command","title":"The terminal command","text":"<pre><code>panel serve chat_interface.py\n</code></pre>"},{"location":"tutorials/chat-ui/simplebot-and-chatbot/#conclusion","title":"Conclusion","text":"<p>With just a few lines of code, you can create a chat interface and integrate it with a bot using the <code>llamabot</code> and <code>Panel</code> libraries. This setup provides a foundational step towards creating more interactive and dynamic chatbot applications. Happy coding!</p>"}]}